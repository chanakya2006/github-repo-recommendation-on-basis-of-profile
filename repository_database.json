{
  "repositories": [
    {
      "owner": "parulsri1616",
      "name": "rock_paper_sci",
      "url": "https://github.com/parulsri1616/rock_paper_sci",
      "description": "",
      "readme_content": "rock_paper_sci",
      "languages": {},
      "topics": [],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:30.818093"
    },
    {
      "owner": "parulsri1616",
      "name": "Guessing-game_Python",
      "url": "https://github.com/parulsri1616/Guessing-game_Python",
      "description": "",
      "readme_content": "Its a simple guessing game using python.",
      "languages": {
        "python": 1,
        "Python": 1
      },
      "topics": [
        "Python"
      ],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:31.535341"
    },
    {
      "owner": "parulsri1616",
      "name": "Heartb___",
      "url": "https://github.com/parulsri1616/Heartb___",
      "description": "",
      "readme_content": "",
      "languages": {},
      "topics": [],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:32.151817"
    },
    {
      "owner": "sinaptik-ai",
      "name": "pandas-ai",
      "url": "https://github.com/sinaptik-ai/pandas-ai",
      "description": "Chat with your database or your datalake (SQL, CSV, parquet). PandasAI makes data analysis conversational using LLMs and RAG.",
      "readme_content": "PandaAI is a Python platform that makes it easy to ask questions to your data in natural language. It helps non-technical users to interact with their data in a more natural way, and it helps technical users to save time, and effort when working with data.\nğŸ”§ Getting started\nYou can find the full documentation for PandaAI here.\nYou can either decide to use PandaAI in your Jupyter notebooks, Streamlit apps, or use the client and server architecture from the repo.\nâ˜ï¸ Using the platform\nThe library can be used alongside our powerful data platform, making end-to-end conversational data analytics possible with as little as a few lines of code.\nLoad your data, save them as a dataframe, and push them to the platform\nimport pandasai as pai\n\npai.api_key.set(\"your-pai-api-key\")\n\nfile = pai.read_csv(\"./filepath.csv\")\n\ndataset = pai.create(path=\"your-organization/dataset-name\",\n    df=file,\n    name=\"dataset-name\",\n    description=\"dataset-description\")\n\ndataset.push()\nYour team can now access and query this data using natural language through the platform.\n\nğŸ“š Using the library\nPython Requirements\nPython version 3.8+ <3.12\nğŸ“¦ Installation\nYou can install the PandaAI library using pip or poetry.\nWith pip:\npip install \"pandasai>=3.0.0b2\"\nWith poetry:\npoetry add \"pandasai>=3.0.0b2\"\nğŸ’» Usage\nAsk questions\nimport pandasai as pai\n\n# Sample DataFrame\ndf = pai.DataFrame({\n    \"country\": [\"United States\", \"United Kingdom\", \"France\", \"Germany\", \"Italy\", \"Spain\", \"Canada\", \"Australia\", \"Japan\", \"China\"],\n    \"revenue\": [5000, 3200, 2900, 4100, 2300, 2100, 2500, 2600, 4500, 7000]\n})\n\n# By default, unless you choose a different LLM, it will use BambooLLM.\n# You can get your free API key signing up at https://app.pandabi.ai (you can also configure it in your .env file)\npai.api_key.set(\"your-pai-api-key\")\n\ndf.chat('Which are the top 5 countries by sales?')\nChina, United States, Japan, Germany, Australia\n\n\nOr you can ask more complex questions:\ndf.chat(\n    \"What is the total sales for the top 3 countries by sales?\"\n)\nThe total sales for the top 3 countries by sales is 16500.\n\nVisualize charts\nYou can also ask PandaAI to generate charts for you:\ndf.chat(\n    \"Plot the histogram of countries showing for each one the gd. Use different colors for each bar\",\n)\n\nMultiple DataFrames\nYou can also pass in multiple dataframes to PandaAI and ask questions relating them.\nimport pandasai as pai\n\nemployees_data = {\n    'EmployeeID': [1, 2, 3, 4, 5],\n    'Name': ['John', 'Emma', 'Liam', 'Olivia', 'William'],\n    'Department': ['HR', 'Sales', 'IT', 'Marketing', 'Finance']\n}\n\nsalaries_data = {\n    'EmployeeID': [1, 2, 3, 4, 5],\n    'Salary': [5000, 6000, 4500, 7000, 5500]\n}\n\nemployees_df = pai.DataFrame(employees_data)\nsalaries_df = pai.DataFrame(salaries_data)\n\n# By default, unless you choose a different LLM, it will use BambooLLM.\n# You can get your free API key signing up at https://app.pandabi.ai (you can also configure it in your .env file)\npai.api_key.set(\"your-pai-api-key\")\n\npai.chat(\"Who gets paid the most?\", employees_df, salaries_df)\nOlivia gets paid the most.\n\nDocker Sandbox\nYou can run PandaAI in a Docker sandbox, providing a secure, isolated environment to execute code safely and mitigate the risk of malicious attacks.\nPython Requirements\npip install \"pandasai-docker\"\nUsage\nimport pandasai as pai\nfrom pandasai_docker import DockerSandbox\n\n# Initialize the sandbox\nsandbox = DockerSandbox()\nsandbox.start()\n\nemployees_data = {\n    'EmployeeID': [1, 2, 3, 4, 5],\n    'Name': ['John', 'Emma', 'Liam', 'Olivia', 'William'],\n    'Department': ['HR', 'Sales', 'IT', 'Marketing', 'Finance']\n}\n\nsalaries_data = {\n    'EmployeeID': [1, 2, 3, 4, 5],\n    'Salary': [5000, 6000, 4500, 7000, 5500]\n}\n\nemployees_df = pai.DataFrame(employees_data)\nsalaries_df = pai.DataFrame(salaries_data)\n\n# By default, unless you choose a different LLM, it will use BambooLLM.\n# You can get your free API key signing up at https://app.pandabi.ai (you can also configure it in your .env file)\npai.api_key.set(\"your-pai-api-key\")\n\npai.chat(\"Who gets paid the most?\", employees_df, salaries_df, sandbox=sandbox)\n\n# Don't forget to stop the sandbox when done\nsandbox.stop()\nOlivia gets paid the most.\n\nYou can find more examples in the examples directory.\nğŸ“œ License\nPandaAI is available under the MIT expat license, except for the pandasai/ee directory of this repository, which has its license here.\nIf you are interested in managed PandaAI Cloud or self-hosted Enterprise Offering, contact us.\nResources\n\nBeta Notice\nRelease v3 is currently in beta. The following documentation and examples reflect the features and functionality in progress and may change before the final release.\n\n\nDocs for comprehensive documentation\nExamples for example notebooks\nDiscord for discussion with the community and PandaAI team\n\nğŸ¤ Contributing\nContributions are welcome! Please check the outstanding issues and feel free to open a pull request.\nFor more information, please check out the contributing guidelines.\nThank you!",
      "languages": {
        "python": 1,
        "Python": 1
      },
      "topics": [
        "Python",
        "Docker"
      ],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:34.381190"
    },
    {
      "owner": "harry0703",
      "name": "MoneyPrinterTurbo",
      "url": "https://github.com/harry0703/MoneyPrinterTurbo",
      "description": "åˆ©ç”¨AIå¤§æ¨¡å‹ï¼Œä¸€é”®ç”Ÿæˆé«˜æ¸…çŸ­è§†é¢‘ Generate short videos with one click using AI LLM.",
      "readme_content": "MoneyPrinterTurbo ğŸ’¸\n\n\n\n\n\n\n\nç®€ä½“ä¸­æ–‡ | English\n\n\n\n\nåªéœ€æä¾›ä¸€ä¸ªè§†é¢‘ ä¸»é¢˜ æˆ– å…³é”®è¯ ï¼Œå°±å¯ä»¥å…¨è‡ªåŠ¨ç”Ÿæˆè§†é¢‘æ–‡æ¡ˆã€è§†é¢‘ç´ æã€è§†é¢‘å­—å¹•ã€è§†é¢‘èƒŒæ™¯éŸ³ä¹ï¼Œç„¶ååˆæˆä¸€ä¸ªé«˜æ¸…çš„çŸ­è§†é¢‘ã€‚\n\nWebç•Œé¢\n\nAPIç•Œé¢\n\n\nç‰¹åˆ«æ„Ÿè°¢ ğŸ™\nç”±äºè¯¥é¡¹ç›®çš„ éƒ¨ç½² å’Œ ä½¿ç”¨ï¼Œå¯¹äºä¸€äº›å°ç™½ç”¨æˆ·æ¥è¯´ï¼Œè¿˜æ˜¯ æœ‰ä¸€å®šçš„é—¨æ§›ï¼Œåœ¨æ­¤ç‰¹åˆ«æ„Ÿè°¢\nå½•å’–ï¼ˆAIæ™ºèƒ½ å¤šåª’ä½“æœåŠ¡å¹³å°ï¼‰ ç½‘ç«™åŸºäºè¯¥é¡¹ç›®ï¼Œæä¾›çš„å…è´¹AIè§†é¢‘ç”Ÿæˆå™¨æœåŠ¡ï¼Œå¯ä»¥ä¸ç”¨éƒ¨ç½²ï¼Œç›´æ¥åœ¨çº¿ä½¿ç”¨ï¼Œéå¸¸æ–¹ä¾¿ã€‚\n\nä¸­æ–‡ç‰ˆï¼šhttps://reccloud.cn\nè‹±æ–‡ç‰ˆï¼šhttps://reccloud.com\n\n\næ„Ÿè°¢èµåŠ© ğŸ™\næ„Ÿè°¢ä½ç³– https://picwish.cn å¯¹è¯¥é¡¹ç›®çš„æ”¯æŒå’ŒèµåŠ©ï¼Œä½¿å¾—è¯¥é¡¹ç›®èƒ½å¤ŸæŒç»­çš„æ›´æ–°å’Œç»´æŠ¤ã€‚\nä½ç³–ä¸“æ³¨äºå›¾åƒå¤„ç†é¢†åŸŸï¼Œæä¾›ä¸°å¯Œçš„å›¾åƒå¤„ç†å·¥å…·ï¼Œå°†å¤æ‚æ“ä½œæè‡´ç®€åŒ–ï¼ŒçœŸæ­£å®ç°è®©å›¾åƒå¤„ç†æ›´ç®€å•ã€‚\n\nåŠŸèƒ½ç‰¹æ€§ ğŸ¯\n\n å®Œæ•´çš„ MVCæ¶æ„ï¼Œä»£ç  ç»“æ„æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤ï¼Œæ”¯æŒ API å’Œ Webç•Œé¢\n æ”¯æŒè§†é¢‘æ–‡æ¡ˆ AIè‡ªåŠ¨ç”Ÿæˆï¼Œä¹Ÿå¯ä»¥è‡ªå®šä¹‰æ–‡æ¡ˆ\n æ”¯æŒå¤šç§ é«˜æ¸…è§†é¢‘ å°ºå¯¸\n\n ç«–å± 9:16ï¼Œ1080x1920\n æ¨ªå± 16:9ï¼Œ1920x1080\n\n\n æ”¯æŒ æ‰¹é‡è§†é¢‘ç”Ÿæˆï¼Œå¯ä»¥ä¸€æ¬¡ç”Ÿæˆå¤šä¸ªè§†é¢‘ï¼Œç„¶åé€‰æ‹©ä¸€ä¸ªæœ€æ»¡æ„çš„\n æ”¯æŒ è§†é¢‘ç‰‡æ®µæ—¶é•¿ è®¾ç½®ï¼Œæ–¹ä¾¿è°ƒèŠ‚ç´ æåˆ‡æ¢é¢‘ç‡\n æ”¯æŒ ä¸­æ–‡ å’Œ è‹±æ–‡ è§†é¢‘æ–‡æ¡ˆ\n æ”¯æŒ å¤šç§è¯­éŸ³ åˆæˆï¼Œå¯ å®æ—¶è¯•å¬ æ•ˆæœ\n æ”¯æŒ å­—å¹•ç”Ÿæˆï¼Œå¯ä»¥è°ƒæ•´ å­—ä½“ã€ä½ç½®ã€é¢œè‰²ã€å¤§å°ï¼ŒåŒæ—¶æ”¯æŒå­—å¹•æè¾¹è®¾ç½®\n æ”¯æŒ èƒŒæ™¯éŸ³ä¹ï¼Œéšæœºæˆ–è€…æŒ‡å®šéŸ³ä¹æ–‡ä»¶ï¼Œå¯è®¾ç½®èƒŒæ™¯éŸ³ä¹éŸ³é‡\n è§†é¢‘ç´ ææ¥æº é«˜æ¸…ï¼Œè€Œä¸” æ— ç‰ˆæƒï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨è‡ªå·±çš„ æœ¬åœ°ç´ æ\n æ”¯æŒ OpenAIã€Moonshotã€Azureã€gpt4freeã€one-apiã€é€šä¹‰åƒé—®ã€Google Geminiã€Ollamaã€\nDeepSeekã€ æ–‡å¿ƒä¸€è¨€ ç­‰å¤šç§æ¨¡å‹æ¥å…¥\n\nä¸­å›½ç”¨æˆ·å»ºè®®ä½¿ç”¨ DeepSeek æˆ– Moonshot ä½œä¸ºå¤§æ¨¡å‹æä¾›å•†ï¼ˆå›½å†…å¯ç›´æ¥è®¿é—®ï¼Œä¸éœ€è¦VPNã€‚æ³¨å†Œå°±é€é¢åº¦ï¼ŒåŸºæœ¬å¤Ÿç”¨ï¼‰\n\n\n\nåæœŸè®¡åˆ’ ğŸ“…\n\n GPT-SoVITS é…éŸ³æ”¯æŒ\n ä¼˜åŒ–è¯­éŸ³åˆæˆï¼Œåˆ©ç”¨å¤§æ¨¡å‹ï¼Œä½¿å…¶åˆæˆçš„å£°éŸ³ï¼Œæ›´åŠ è‡ªç„¶ï¼Œæƒ…ç»ªæ›´åŠ ä¸°å¯Œ\n å¢åŠ è§†é¢‘è½¬åœºæ•ˆæœï¼Œä½¿å…¶çœ‹èµ·æ¥æ›´åŠ çš„æµç•…\n å¢åŠ æ›´å¤šè§†é¢‘ç´ ææ¥æºï¼Œä¼˜åŒ–è§†é¢‘ç´ æå’Œæ–‡æ¡ˆçš„åŒ¹é…åº¦\n å¢åŠ è§†é¢‘é•¿åº¦é€‰é¡¹ï¼šçŸ­ã€ä¸­ã€é•¿\n æ”¯æŒæ›´å¤šçš„è¯­éŸ³åˆæˆæœåŠ¡å•†ï¼Œæ¯”å¦‚ OpenAI TTS\n è‡ªåŠ¨ä¸Šä¼ åˆ°YouTubeå¹³å°\n\nè§†é¢‘æ¼”ç¤º ğŸ“º\nç«–å± 9:16\n\n\n\nâ–¶ï¸ ã€Šå¦‚ä½•å¢åŠ ç”Ÿæ´»çš„ä¹è¶£ã€‹\nâ–¶ï¸ ã€Šé‡‘é’±çš„ä½œç”¨ã€‹æ›´çœŸå®çš„åˆæˆå£°éŸ³\nâ–¶ï¸ ã€Šç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä»€ä¹ˆã€‹\n\n\n\n\n\n\n\n\n\ndemo-portrait-1.mp4\n\n\n\n\n\n\n\n\n\n\n\ndefault.mp4\n\n\n\n\n\n\n\n\n\n\n\ndemo-portrait-2.mp4\n\n\n\n\n\n\n\n\n\næ¨ªå± 16:9\n\n\n\nâ–¶ï¸ã€Šç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä»€ä¹ˆã€‹\nâ–¶ï¸ã€Šä¸ºä»€ä¹ˆè¦è¿åŠ¨ã€‹\n\n\n\n\n\n\n\n\n\ndemo-landscape.mp4\n\n\n\n\n\n\n\n\n\n\n\ndemo-landscape-2.mp4\n\n\n\n\n\n\n\n\n\né…ç½®è¦æ±‚ ğŸ“¦\n\nå»ºè®®æœ€ä½ CPU 4æ ¸æˆ–ä»¥ä¸Šï¼Œå†…å­˜ 8G æˆ–ä»¥ä¸Šï¼Œæ˜¾å¡éå¿…é¡»\nWindows 10 æˆ– MacOS 11.0 ä»¥ä¸Šç³»ç»Ÿ\n\nå¿«é€Ÿå¼€å§‹ ğŸš€\nä¸‹è½½ä¸€é”®å¯åŠ¨åŒ…ï¼Œè§£å‹ç›´æ¥ä½¿ç”¨ï¼ˆè·¯å¾„ä¸è¦æœ‰ ä¸­æ–‡ã€ç‰¹æ®Šå­—ç¬¦ã€ç©ºæ ¼ï¼‰\nWindows\n\nç™¾åº¦ç½‘ç›˜ï¼ˆ1.2.1 æœ€æ–°ç‰ˆæœ¬ï¼‰: https://pan.baidu.com/s/1pSNjxTYiVENulTLm6zieMQ?pwd=g36q æå–ç : g36q\n\nä¸‹è½½åï¼Œå»ºè®®å…ˆåŒå‡»æ‰§è¡Œ update.bat æ›´æ–°åˆ°æœ€æ–°ä»£ç ï¼Œç„¶ååŒå‡» start.bat å¯åŠ¨\nå¯åŠ¨åï¼Œä¼šè‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼ˆå¦‚æœæ‰“å¼€æ˜¯ç©ºç™½ï¼Œå»ºè®®æ¢æˆ Chrome æˆ–è€… Edge æ‰“å¼€ï¼‰\nå…¶ä»–ç³»ç»Ÿ\nè¿˜æ²¡æœ‰åˆ¶ä½œä¸€é”®å¯åŠ¨åŒ…ï¼Œçœ‹ä¸‹é¢çš„ å®‰è£…éƒ¨ç½² éƒ¨åˆ†ï¼Œå»ºè®®ä½¿ç”¨ docker éƒ¨ç½²ï¼Œæ›´åŠ æ–¹ä¾¿ã€‚\nå®‰è£…éƒ¨ç½² ğŸ“¥\nå‰ææ¡ä»¶\n\nå°½é‡ä¸è¦ä½¿ç”¨ ä¸­æ–‡è·¯å¾„ï¼Œé¿å…å‡ºç°ä¸€äº›æ— æ³•é¢„æ–™çš„é—®é¢˜\nè¯·ç¡®ä¿ä½ çš„ ç½‘ç»œ æ˜¯æ­£å¸¸çš„ï¼ŒVPNéœ€è¦æ‰“å¼€å…¨å±€æµé‡æ¨¡å¼\n\nâ‘  å…‹éš†ä»£ç \ngit clone https://github.com/harry0703/MoneyPrinterTurbo.git\nâ‘¡ ä¿®æ”¹é…ç½®æ–‡ä»¶\n\nå°† config.example.toml æ–‡ä»¶å¤åˆ¶ä¸€ä»½ï¼Œå‘½åä¸º config.toml\næŒ‰ç…§ config.toml æ–‡ä»¶ä¸­çš„è¯´æ˜ï¼Œé…ç½®å¥½ pexels_api_keys å’Œ llm_providerï¼Œå¹¶æ ¹æ® llm_provider å¯¹åº”çš„æœåŠ¡å•†ï¼Œé…ç½®ç›¸å…³çš„\nAPI Key\n\nDockeréƒ¨ç½² ğŸ³\nâ‘  å¯åŠ¨Docker\nå¦‚æœæœªå®‰è£… Dockerï¼Œè¯·å…ˆå®‰è£… https://www.docker.com/products/docker-desktop/\nå¦‚æœæ˜¯Windowsç³»ç»Ÿï¼Œè¯·å‚è€ƒå¾®è½¯çš„æ–‡æ¡£ï¼š\n\nhttps://learn.microsoft.com/zh-cn/windows/wsl/install\nhttps://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers\n\ncd MoneyPrinterTurbo\ndocker-compose up\n\næ³¨æ„ï¼šæœ€æ–°ç‰ˆçš„dockerå®‰è£…æ—¶ä¼šè‡ªåŠ¨ä»¥æ’ä»¶çš„å½¢å¼å®‰è£…docker composeï¼Œå¯åŠ¨å‘½ä»¤è°ƒæ•´ä¸ºdocker compose up\n\nâ‘¡ è®¿é—®Webç•Œé¢\næ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® http://0.0.0.0:8501\nâ‘¢ è®¿é—®APIæ–‡æ¡£\næ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® http://0.0.0.0:8080/docs æˆ–è€… http://0.0.0.0:8080/redoc\næ‰‹åŠ¨éƒ¨ç½² ğŸ“¦\n\nè§†é¢‘æ•™ç¨‹\n\n\nå®Œæ•´çš„ä½¿ç”¨æ¼”ç¤ºï¼šhttps://v.douyin.com/iFhnwsKY/\nå¦‚ä½•åœ¨Windowsä¸Šéƒ¨ç½²ï¼šhttps://v.douyin.com/iFyjoW3M\n\nâ‘  åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ\nå»ºè®®ä½¿ç”¨ conda åˆ›å»º python è™šæ‹Ÿç¯å¢ƒ\ngit clone https://github.com/harry0703/MoneyPrinterTurbo.git\ncd MoneyPrinterTurbo\nconda create -n MoneyPrinterTurbo python=3.11\nconda activate MoneyPrinterTurbo\npip install -r requirements.txt\nâ‘¡ å®‰è£…å¥½ ImageMagick\n\n\nWindows:\n\nä¸‹è½½ https://imagemagick.org/script/download.php é€‰æ‹©Windowsç‰ˆæœ¬ï¼Œåˆ‡è®°ä¸€å®šè¦é€‰æ‹© é™æ€åº“ ç‰ˆæœ¬ï¼Œæ¯”å¦‚\nImageMagick-7.1.1-32-Q16-x64-static.exe\nå®‰è£…ä¸‹è½½å¥½çš„ ImageMagickï¼Œæ³¨æ„ä¸è¦ä¿®æ”¹å®‰è£…è·¯å¾„\nä¿®æ”¹ é…ç½®æ–‡ä»¶ config.toml ä¸­çš„ imagemagick_path ä¸ºä½ çš„ å®é™…å®‰è£…è·¯å¾„\n\n\n\nMacOS:\nbrew install imagemagick\n\n\nUbuntu\nsudo apt-get install imagemagick\n\n\nCentOS\nsudo yum install ImageMagick\n\n\nâ‘¢ å¯åŠ¨Webç•Œé¢ ğŸŒ\næ³¨æ„éœ€è¦åˆ° MoneyPrinterTurbo é¡¹ç›® æ ¹ç›®å½• ä¸‹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤\nWindows\nconda activate MoneyPrinterTurbo\nwebui.bat\nMacOS or Linux\nconda activate MoneyPrinterTurbo\nsh webui.sh\nå¯åŠ¨åï¼Œä¼šè‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼ˆå¦‚æœæ‰“å¼€æ˜¯ç©ºç™½ï¼Œå»ºè®®æ¢æˆ Chrome æˆ–è€… Edge æ‰“å¼€ï¼‰\nâ‘£ å¯åŠ¨APIæœåŠ¡ ğŸš€\npython main.py\nå¯åŠ¨åï¼Œå¯ä»¥æŸ¥çœ‹ APIæ–‡æ¡£ http://127.0.0.1:8080/docs æˆ–è€… http://127.0.0.1:8080/redoc ç›´æ¥åœ¨çº¿è°ƒè¯•æ¥å£ï¼Œå¿«é€Ÿä½“éªŒã€‚\nè¯­éŸ³åˆæˆ ğŸ—£\næ‰€æœ‰æ”¯æŒçš„å£°éŸ³åˆ—è¡¨ï¼Œå¯ä»¥æŸ¥çœ‹ï¼šå£°éŸ³åˆ—è¡¨\n2024-04-16 v1.1.2 æ–°å¢äº†9ç§Azureçš„è¯­éŸ³åˆæˆå£°éŸ³ï¼Œéœ€è¦é…ç½®API KEYï¼Œè¯¥å£°éŸ³åˆæˆçš„æ›´åŠ çœŸå®ã€‚\nå­—å¹•ç”Ÿæˆ ğŸ“œ\nå½“å‰æ”¯æŒ2ç§å­—å¹•ç”Ÿæˆæ–¹å¼ï¼š\n\nedge: ç”Ÿæˆé€Ÿåº¦å¿«ï¼Œæ€§èƒ½æ›´å¥½ï¼Œå¯¹ç”µè„‘é…ç½®æ²¡æœ‰è¦æ±‚ï¼Œä½†æ˜¯è´¨é‡å¯èƒ½ä¸ç¨³å®š\nwhisper: ç”Ÿæˆé€Ÿåº¦æ…¢ï¼Œæ€§èƒ½è¾ƒå·®ï¼Œå¯¹ç”µè„‘é…ç½®æœ‰ä¸€å®šè¦æ±‚ï¼Œä½†æ˜¯è´¨é‡æ›´å¯é ã€‚\n\nå¯ä»¥ä¿®æ”¹ config.toml é…ç½®æ–‡ä»¶ä¸­çš„ subtitle_provider è¿›è¡Œåˆ‡æ¢\nå»ºè®®ä½¿ç”¨ edge æ¨¡å¼ï¼Œå¦‚æœç”Ÿæˆçš„å­—å¹•è´¨é‡ä¸å¥½ï¼Œå†åˆ‡æ¢åˆ° whisper æ¨¡å¼\n\næ³¨æ„ï¼š\n\n\nwhisper æ¨¡å¼ä¸‹éœ€è¦åˆ° HuggingFace ä¸‹è½½ä¸€ä¸ªæ¨¡å‹æ–‡ä»¶ï¼Œå¤§çº¦ 3GB å·¦å³ï¼Œè¯·ç¡®ä¿ç½‘ç»œé€šç•…\nå¦‚æœç•™ç©ºï¼Œè¡¨ç¤ºä¸ç”Ÿæˆå­—å¹•ã€‚\n\n\nç”±äºå›½å†…æ— æ³•è®¿é—® HuggingFaceï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ä¸‹è½½ whisper-large-v3 çš„æ¨¡å‹æ–‡ä»¶\n\nä¸‹è½½åœ°å€ï¼š\n\nç™¾åº¦ç½‘ç›˜: https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9\nå¤¸å…‹ç½‘ç›˜ï¼šhttps://pan.quark.cn/s/3ee3d991d64b\n\næ¨¡å‹ä¸‹è½½åè§£å‹ï¼Œæ•´ä¸ªç›®å½•æ”¾åˆ° .\\MoneyPrinterTurbo\\models é‡Œé¢ï¼Œ\næœ€ç»ˆçš„æ–‡ä»¶è·¯å¾„åº”è¯¥æ˜¯è¿™æ ·: .\\MoneyPrinterTurbo\\models\\whisper-large-v3\nMoneyPrinterTurbo  \n  â”œâ”€models\n  â”‚   â””â”€whisper-large-v3\n  â”‚          config.json\n  â”‚          model.bin\n  â”‚          preprocessor_config.json\n  â”‚          tokenizer.json\n  â”‚          vocabulary.json\n\nèƒŒæ™¯éŸ³ä¹ ğŸµ\nç”¨äºè§†é¢‘çš„èƒŒæ™¯éŸ³ä¹ï¼Œä½äºé¡¹ç›®çš„ resource/songs ç›®å½•ä¸‹ã€‚\n\nå½“å‰é¡¹ç›®é‡Œé¢æ”¾äº†ä¸€äº›é»˜è®¤çš„éŸ³ä¹ï¼Œæ¥è‡ªäº YouTube è§†é¢‘ï¼Œå¦‚æœ‰ä¾µæƒï¼Œè¯·åˆ é™¤ã€‚\n\nå­—å¹•å­—ä½“ ğŸ…°\nç”¨äºè§†é¢‘å­—å¹•çš„æ¸²æŸ“ï¼Œä½äºé¡¹ç›®çš„ resource/fonts ç›®å½•ä¸‹ï¼Œä½ ä¹Ÿå¯ä»¥æ”¾è¿›å»è‡ªå·±çš„å­—ä½“ã€‚\nå¸¸è§é—®é¢˜ ğŸ¤”\nâ“å¦‚ä½•ä½¿ç”¨å…è´¹çš„OpenAI GPT-3.5æ¨¡å‹?\nOpenAIå®£å¸ƒChatGPTé‡Œé¢3.5å·²ç»å…è´¹äº†ï¼Œæœ‰å¼€å‘è€…å°†å…¶å°è£…æˆäº†APIï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨\nç¡®ä¿ä½ å®‰è£…å’Œå¯åŠ¨äº†dockeræœåŠ¡ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨dockeræœåŠ¡\ndocker run -p 3040:3040 missuo/freegpt35\nå¯åŠ¨æˆåŠŸåï¼Œä¿®æ”¹ config.toml ä¸­çš„é…ç½®\n\nllm_provider è®¾ç½®ä¸º openai\nopenai_api_key éšä¾¿å¡«å†™ä¸€ä¸ªå³å¯ï¼Œæ¯”å¦‚ '123456'\nopenai_base_url æ”¹ä¸º http://localhost:3040/v1/\nopenai_model_name æ”¹ä¸º gpt-3.5-turbo\n\n\næ³¨æ„ï¼šè¯¥æ–¹å¼ç¨³å®šæ€§è¾ƒå·®\n\nâ“AttributeError: 'str' object has no attribute 'choices'`\nè¿™ä¸ªé—®é¢˜æ˜¯ç”±äºå¤§æ¨¡å‹æ²¡æœ‰è¿”å›æ­£ç¡®çš„å›å¤å¯¼è‡´çš„ã€‚\nå¤§æ¦‚ç‡æ˜¯ç½‘ç»œåŸå› ï¼Œ ä½¿ç”¨ VPNï¼Œæˆ–è€…è®¾ç½® openai_base_url ä¸ºä½ çš„ä»£ç† ï¼Œåº”è¯¥å°±å¯ä»¥è§£å†³äº†ã€‚\nåŒæ—¶å»ºè®®ä½¿ç”¨ Moonshot æˆ– DeepSeek ä½œä¸ºå¤§æ¨¡å‹æä¾›å•†ï¼Œè¿™ä¸¤ä¸ªæœåŠ¡å•†åœ¨å›½å†…è®¿é—®é€Ÿåº¦æ›´å¿«ï¼Œæ›´åŠ ç¨³å®šã€‚\nâ“RuntimeError: No ffmpeg exe could be found\né€šå¸¸æƒ…å†µä¸‹ï¼Œffmpeg ä¼šè¢«è‡ªåŠ¨ä¸‹è½½ï¼Œå¹¶ä¸”ä¼šè¢«è‡ªåŠ¨æ£€æµ‹åˆ°ã€‚\nä½†æ˜¯å¦‚æœä½ çš„ç¯å¢ƒæœ‰é—®é¢˜ï¼Œæ— æ³•è‡ªåŠ¨ä¸‹è½½ï¼Œå¯èƒ½ä¼šé‡åˆ°å¦‚ä¸‹é”™è¯¯ï¼š\nRuntimeError: No ffmpeg exe could be found.\nInstall ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.\n\næ­¤æ—¶ä½ å¯ä»¥ä» https://www.gyan.dev/ffmpeg/builds/ ä¸‹è½½ffmpegï¼Œè§£å‹åï¼Œè®¾ç½® ffmpeg_path ä¸ºä½ çš„å®é™…å®‰è£…è·¯å¾„å³å¯ã€‚\n[app]\n# è¯·æ ¹æ®ä½ çš„å®é™…è·¯å¾„è®¾ç½®ï¼Œæ³¨æ„ Windows è·¯å¾„åˆ†éš”ç¬¦ä¸º \\\\\nffmpeg_path = \"C:\\\\Users\\\\harry\\\\Downloads\\\\ffmpeg.exe\"\nâ“ImageMagickçš„å®‰å…¨ç­–ç•¥é˜»æ­¢äº†ä¸ä¸´æ—¶æ–‡ä»¶@/tmp/tmpur5hyyto.txtç›¸å…³çš„æ“ä½œ\nå¯ä»¥åœ¨ImageMagickçš„é…ç½®æ–‡ä»¶policy.xmlä¸­æ‰¾åˆ°è¿™äº›ç­–ç•¥ã€‚\nè¿™ä¸ªæ–‡ä»¶é€šå¸¸ä½äº /etc/ImageMagick-X/ æˆ– ImageMagick å®‰è£…ç›®å½•çš„ç±»ä¼¼ä½ç½®ã€‚\nä¿®æ”¹åŒ…å«pattern=\"@\"çš„æ¡ç›®ï¼Œå°†rights=\"none\"æ›´æ”¹ä¸ºrights=\"read|write\"ä»¥å…è®¸å¯¹æ–‡ä»¶çš„è¯»å†™æ“ä½œã€‚\nâ“OSError: [Errno 24] Too many open files\nè¿™ä¸ªé—®é¢˜æ˜¯ç”±äºç³»ç»Ÿæ‰“å¼€æ–‡ä»¶æ•°é™åˆ¶å¯¼è‡´çš„ï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ç³»ç»Ÿçš„æ–‡ä»¶æ‰“å¼€æ•°é™åˆ¶æ¥è§£å†³ã€‚\næŸ¥çœ‹å½“å‰é™åˆ¶\nulimit -n\nå¦‚æœè¿‡ä½ï¼Œå¯ä»¥è°ƒé«˜ä¸€äº›ï¼Œæ¯”å¦‚\nulimit -n 10240\nâ“Whisper æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œå‡ºç°å¦‚ä¸‹é”™è¯¯\nLocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and\noutgoing trafic has been disabled.\nTo enablerepo look-ups and downloads online, pass 'local files only=False' as input.\næˆ–è€…\nAn error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub:\nAn error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the\nspecified revision on the local disk. Please check your internet connection and try again.\nTrying to load the model directly from the local cache, if it exists.\nè§£å†³æ–¹æ³•ï¼šç‚¹å‡»æŸ¥çœ‹å¦‚ä½•ä»ç½‘ç›˜æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹\nåé¦ˆå»ºè®® ğŸ“¢\n\nå¯ä»¥æäº¤ issue\næˆ–è€… pull requestã€‚\n\nå‚è€ƒé¡¹ç›® ğŸ“š\nè¯¥é¡¹ç›®åŸºäº https://github.com/FujiwaraChoki/MoneyPrinter é‡æ„è€Œæ¥ï¼Œåšäº†å¤§é‡çš„ä¼˜åŒ–ï¼Œå¢åŠ äº†æ›´å¤šçš„åŠŸèƒ½ã€‚\næ„Ÿè°¢åŸä½œè€…çš„å¼€æºç²¾ç¥ã€‚\nè®¸å¯è¯ ğŸ“\nç‚¹å‡»æŸ¥çœ‹ LICENSE æ–‡ä»¶\nStar History",
      "languages": {
        "php": 1,
        "R": 1,
        "python": 1,
        "PHP": 1,
        "Python": 1
      },
      "topics": [
        "Azure",
        "R",
        "Docker",
        "PHP",
        "Python"
      ],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:35.014254"
    },
    {
      "owner": "jingyaogong",
      "name": "minimind",
      "url": "https://github.com/jingyaogong/minimind",
      "description": "ğŸš€ğŸš€ ã€Œå¤§æ¨¡å‹ã€2å°æ—¶å®Œå…¨ä»0è®­ç»ƒ26Mçš„å°å‚æ•°GPTï¼ğŸŒ Train a 26M-parameter GPT from scratch in just 2h!",
      "readme_content": "\"å¤§é“è‡³ç®€\"\n\n\nä¸­æ–‡ | English\n\n\næ­¤å¼€æºé¡¹ç›®æ—¨åœ¨å®Œå…¨ä»0å¼€å§‹ï¼Œä»…ç”¨3å—é’±æˆæœ¬ + 2å°æ—¶ï¼å³å¯è®­ç»ƒå‡ºä»…ä¸º25.8Mçš„è¶…å°è¯­è¨€æ¨¡å‹MiniMindã€‚\n\nMiniMindç³»åˆ—æå…¶è½»é‡ï¼Œæœ€å°ç‰ˆæœ¬ä½“ç§¯æ˜¯ GPT-3 çš„ $\\frac{1}{7000}$ï¼ŒåŠ›æ±‚åšåˆ°æœ€æ™®é€šçš„ä¸ªäººGPUä¹Ÿå¯å¿«é€Ÿè®­ç»ƒã€‚\né¡¹ç›®åŒæ—¶å¼€æºäº†å¤§æ¨¡å‹çš„æç®€ç»“æ„-åŒ…å«æ‹“å±•å…±äº«æ··åˆä¸“å®¶(MoE)ã€æ•°æ®é›†æ¸…æ´—ã€é¢„è®­ç»ƒ(Pretrain)ã€ç›‘ç£å¾®è°ƒ(SFT)ã€LoRAå¾®è°ƒï¼Œ\nç›´æ¥åå¥½å¼ºåŒ–å­¦ä¹ (DPO)ç®—æ³•ã€æ¨¡å‹è’¸é¦ç®—æ³•ç­‰å…¨è¿‡ç¨‹ä»£ç ã€‚\n\nMiniMindåŒæ—¶æ‹“å±•äº†è§†è§‰å¤šæ¨¡æ€çš„VLM: MiniMind-Vã€‚\né¡¹ç›®æ‰€æœ‰æ ¸å¿ƒç®—æ³•ä»£ç å‡ä»0ä½¿ç”¨PyTorchåŸç”Ÿé‡æ„ï¼ä¸ä¾èµ–ç¬¬ä¸‰æ–¹åº“æä¾›çš„æŠ½è±¡æ¥å£ã€‚\nè¿™ä¸ä»…æ˜¯å¤§è¯­è¨€æ¨¡å‹çš„å…¨é˜¶æ®µå¼€æºå¤ç°ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå…¥é—¨LLMçš„æ•™ç¨‹ã€‚\nå¸Œæœ›æ­¤é¡¹ç›®èƒ½ä¸ºæ‰€æœ‰äººæä¾›ä¸€ä¸ªæŠ›ç –å¼•ç‰çš„ç¤ºä¾‹ï¼Œä¸€èµ·æ„Ÿå—åˆ›é€ çš„ä¹è¶£ï¼æ¨åŠ¨æ›´å¹¿æ³›AIç¤¾åŒºçš„è¿›æ­¥ï¼\n\n\nä¸ºé˜²æ­¢è¯¯è§£ï¼Œâ€œ2å°æ—¶â€ åŸºäºNVIDIA 3090ç¡¬ä»¶è®¾å¤‡ï¼ˆå•å¡ï¼‰æµ‹è¯•ï¼Œâ€œ3å—é’±â€\næŒ‡GPUæœåŠ¡å™¨ç§Ÿç”¨æˆæœ¬ï¼Œå…·ä½“è§„æ ¼è¯¦æƒ…è§ä¸‹æ–‡ã€‚\n\n\n\n\nğŸ”—ğŸ“æ¨ç†æ¨¡å‹ | ğŸ”—ğŸ¤–å¸¸è§„æ¨¡å‹ | ğŸ”—ğŸï¸è§†é¢‘ä»‹ç»\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nğŸ“Œ Introduction\nå¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Model, LLMï¼‰çš„å‡ºç°å¼•å‘äº†å…¨ä¸–ç•Œå¯¹AIçš„ç©ºå‰å…³æ³¨ã€‚\næ— è®ºæ˜¯ChatGPTã€DeepSeekè¿˜æ˜¯Qwenï¼Œéƒ½ä»¥å…¶æƒŠè‰³çš„æ•ˆæœä»¤äººå¹ä¸ºè§‚æ­¢ã€‚\nç„¶è€Œï¼ŒåŠ¨è¾„æ•°ç™¾äº¿å‚æ•°çš„åºå¤§è§„æ¨¡ï¼Œä½¿å¾—å®ƒä»¬å¯¹ä¸ªäººè®¾å¤‡è€Œè¨€ä¸ä»…éš¾ä»¥è®­ç»ƒï¼Œç”šè‡³è¿éƒ¨ç½²éƒ½æ˜¾å¾—é¥ä¸å¯åŠã€‚\næ‰“å¼€å¤§æ¨¡å‹çš„â€œé»‘ç›’å­â€ï¼Œæ¢ç´¢å…¶å†…éƒ¨è¿ä½œæœºåˆ¶ï¼Œå¤šä¹ˆä»¤äººå¿ƒæ½®æ¾æ¹ƒï¼\né—æ†¾çš„æ˜¯ï¼Œ99%çš„æ¢ç´¢åªèƒ½æ­¢æ­¥äºä½¿ç”¨LoRAç­‰æŠ€æœ¯å¯¹ç°æœ‰å¤§æ¨¡å‹è¿›è¡Œå°‘é‡å¾®è°ƒï¼Œå­¦ä¹ ä¸€äº›æ–°æŒ‡ä»¤æˆ–ä»»åŠ¡ã€‚\nè¿™å°±å¥½æ¯”æ•™ç‰›é¡¿å¦‚ä½•ä½¿ç”¨21ä¸–çºªçš„æ™ºèƒ½æ‰‹æœºâ€”â€”è™½ç„¶æœ‰è¶£ï¼Œå´å®Œå…¨åç¦»äº†ç†è§£ç‰©ç†æœ¬è´¨çš„åˆè¡·ã€‚\nä¸æ­¤åŒæ—¶ï¼Œç¬¬ä¸‰æ–¹çš„å¤§æ¨¡å‹æ¡†æ¶å’Œå·¥å…·åº“ï¼Œå¦‚transformers+trlï¼Œå‡ ä¹åªæš´éœ²äº†é«˜åº¦æŠ½è±¡çš„æ¥å£ã€‚\né€šè¿‡çŸ­çŸ­10è¡Œä»£ç ï¼Œå°±èƒ½å®Œæˆâ€œåŠ è½½æ¨¡å‹+åŠ è½½æ•°æ®é›†+æ¨ç†+å¼ºåŒ–å­¦ä¹ â€çš„å…¨æµç¨‹è®­ç»ƒã€‚\nè¿™ç§é«˜æ•ˆçš„å°è£…å›ºç„¶ä¾¿åˆ©ï¼Œä½†ä¹Ÿåƒä¸€æ¶é«˜é€Ÿé£èˆ¹ï¼Œå°†æˆ‘ä»¬ä¸åº•å±‚å®ç°éš”ç¦»å¼€æ¥ï¼Œé˜»ç¢äº†æ·±å…¥æ¢ç©¶LLMæ ¸å¿ƒä»£ç çš„æœºä¼šã€‚\nç„¶è€Œï¼Œâ€œç”¨ä¹é«˜æ‹¼å‡ºä¸€æ¶é£æœºï¼Œè¿œæ¯”ååœ¨å¤´ç­‰èˆ±é‡Œé£è¡Œæ›´è®©äººå…´å¥‹ï¼â€ã€‚\næ›´ç³Ÿç³•çš„æ˜¯ï¼Œäº’è”ç½‘ä¸Šå……æ–¥ç€å¤§é‡ä»˜è´¹è¯¾ç¨‹å’Œè¥é”€å·ï¼Œä»¥æ¼æ´ç™¾å‡ºã€ä¸€çŸ¥åŠè§£çš„å†…å®¹æ¨é”€AIæ•™ç¨‹ã€‚\næ­£å› å¦‚æ­¤ï¼Œæœ¬é¡¹ç›®åˆè¡·æ˜¯æ‹‰ä½LLMçš„å­¦ä¹ é—¨æ§›ï¼Œè®©æ¯ä¸ªäººéƒ½èƒ½ä»ç†è§£æ¯ä¸€è¡Œä»£ç å¼€å§‹ï¼Œ\nä»é›¶å¼€å§‹äº²æ‰‹è®­ç»ƒä¸€ä¸ªæå°çš„è¯­è¨€æ¨¡å‹ã€‚æ˜¯çš„ï¼Œä»é›¶å¼€å§‹è®­ç»ƒï¼Œè€Œä¸æ˜¯ä»…ä»…è¿›è¡Œæ¨ç†ï¼\næœ€ä½åªéœ€3å—é’±ä¸åˆ°çš„æœåŠ¡å™¨æˆæœ¬ï¼Œå°±èƒ½äº²èº«ä½“éªŒä»0åˆ°1æ„å»ºä¸€ä¸ªè¯­è¨€æ¨¡å‹çš„å…¨è¿‡ç¨‹ã€‚\nä¸€èµ·æ„Ÿå—åˆ›é€ çš„ä¹è¶£å§ï¼\nNoteï¼ˆæˆªè‡³2025-02-07ï¼‰MiniMindç³»åˆ—å·²å®Œæˆå¤šä¸ªå‹å·æ¨¡å‹çš„é¢„è®­ç»ƒï¼Œæœ€å°ä»…éœ€25.8Mï¼ˆ0.02Bï¼‰ï¼Œå³å¯å…·å¤‡æµç•…å¯¹è¯èƒ½åŠ›ï¼\n\n\nModels List\n\n\n\næ¨¡å‹ (å¤§å°)\næ¨ç†å ç”¨ (çº¦)\nRelease\n\n\n\n\nMiniMind2-small (26M)\n0.5 GB\n2025.02.06\n\n\nMiniMind2-MoE (145M)\n1.0 GB\n2025.02.06\n\n\nMiniMind2 (104M)\n1.0 GB\n2025.02.06\n\n\nminimind-v1-small (26M)\n0.5 GB\n2024.08.28\n\n\nminimind-v1-moe (4Ã—26M)\n1.0 GB\n2024.09.17\n\n\nminimind-v1 (108M)\n1.0 GB\n2024.09.01\n\n\n\n\né¡¹ç›®åŒ…å«\n\nMiniMind-LLMç»“æ„çš„å…¨éƒ¨ä»£ç ï¼ˆDense+MoEæ¨¡å‹ï¼‰ã€‚\nåŒ…å«Tokenizeråˆ†è¯å™¨è¯¦ç»†è®­ç»ƒä»£ç ã€‚\nåŒ…å«Pretrainã€SFTã€LoRAã€RLHF-DPOã€æ¨¡å‹è’¸é¦çš„å…¨è¿‡ç¨‹è®­ç»ƒä»£ç ã€‚\næ”¶é›†ã€è’¸é¦ã€æ•´ç†å¹¶æ¸…æ´—å»é‡æ‰€æœ‰é˜¶æ®µçš„é«˜è´¨é‡æ•°æ®é›†ï¼Œä¸”å…¨éƒ¨å¼€æºã€‚\nä»0å®ç°é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒã€LoRAã€DPOå¼ºåŒ–å­¦ä¹ ï¼Œç™½ç›’æ¨¡å‹è’¸é¦ã€‚å…³é”®ç®—æ³•å‡ ä¹ä¸ä¾èµ–ç¬¬ä¸‰æ–¹å°è£…çš„æ¡†æ¶ï¼Œä¸”å…¨éƒ¨å¼€æºã€‚\nåŒæ—¶å…¼å®¹transformersã€trlã€peftç­‰ç¬¬ä¸‰æ–¹ä¸»æµæ¡†æ¶ã€‚\nè®­ç»ƒæ”¯æŒå•æœºå•å¡ã€å•æœºå¤šå¡(DDPã€DeepSpeed)è®­ç»ƒï¼Œæ”¯æŒwandbå¯è§†åŒ–è®­ç»ƒæµç¨‹ã€‚æ”¯æŒåŠ¨æ€å¯åœè®­ç»ƒã€‚\nåœ¨ç¬¬ä¸‰æ–¹æµ‹è¯„æ¦œï¼ˆC-Evalã€C-MMLUã€OpenBookQAç­‰ï¼‰è¿›è¡Œæ¨¡å‹æµ‹è¯•ã€‚\nå®ç°Openai-Apiåè®®çš„æç®€æœåŠ¡ç«¯ï¼Œä¾¿äºé›†æˆåˆ°ç¬¬ä¸‰æ–¹ChatUIä½¿ç”¨ï¼ˆFastGPTã€Open-WebUIç­‰ï¼‰ã€‚\nåŸºäºstreamlitå®ç°æœ€ç®€èŠå¤©WebUIå‰ç«¯ã€‚\nå¤ç°(è’¸é¦/RL)å¤§å‹æ¨ç†æ¨¡å‹DeepSeek-R1çš„MiniMind-Reasonæ¨¡å‹ï¼Œæ•°æ®+æ¨¡å‹å…¨éƒ¨å¼€æºï¼\n\nå¸Œæœ›æ­¤å¼€æºé¡¹ç›®å¯ä»¥å¸®åŠ©LLMåˆå­¦è€…å¿«é€Ÿå…¥é—¨ï¼\nğŸ‘‰æ›´æ–°æ—¥å¿—\n\n 2025-02-09 (newest ğŸ‰ğŸ‰ğŸ‰) \n\nè¿æ¥å‘å¸ƒä»¥æ¥é‡å¤§æ›´æ–°ï¼ŒRelease MiniMind2 Seriesã€‚\nä»£ç å‡ ä¹å…¨éƒ¨é‡æ„ï¼Œä½¿ç”¨æ›´ç®€æ´æ˜äº†çš„ç»Ÿä¸€ç»“æ„ã€‚\nå¦‚æœ‰æ—§ä»£ç çš„å…¼å®¹æ€§éœ€è¦ï¼Œå¯è®¿é—®ğŸ”—æ—§ä»“åº“å†…å®¹ğŸ”—ã€‚\nå…å»æ•°æ®é¢„å¤„ç†æ­¥éª¤ã€‚ç»Ÿä¸€æ•°æ®é›†æ ¼å¼ï¼Œæ›´æ¢ä¸ºjsonlæ ¼å¼æœç»æ•°æ®é›†ä¸‹è½½æ··ä¹±çš„é—®é¢˜ã€‚\nMiniMind2ç³»åˆ—æ•ˆæœç›¸æ¯”MiniMind-V1æ˜¾è‘—æå‡ã€‚\nå°é—®é¢˜ï¼š{kv-cacheå†™æ³•æ›´æ ‡å‡†ã€MoEçš„è´Ÿè½½å‡è¡¡lossè¢«è€ƒè™‘ç­‰ç­‰}\næä¾›æ¨¡å‹è¿ç§»åˆ°ç§æœ‰æ•°æ®é›†çš„è®­ç»ƒæ–¹æ¡ˆï¼ˆåŒ»ç–—æ¨¡å‹ã€è‡ªæˆ‘è®¤çŸ¥æ ·ä¾‹ï¼‰ã€‚\nç²¾ç®€é¢„è®­ç»ƒæ•°æ®é›†ï¼Œå¹¶å¤§å¹…æå‡é¢„è®­ç»ƒæ•°æ®è´¨é‡ï¼Œå¤§å¹…ç¼©çŸ­ä¸ªäººå¿«é€Ÿè®­ç»ƒæ‰€éœ€æ—¶é—´ï¼Œå•å¡3090å³å¯2å°æ—¶å¤ç°ï¼\næ›´æ–°ï¼šLoRAå¾®è°ƒè„±ç¦»peftåŒ…è£…ï¼Œä»0å®ç°LoRAè¿‡ç¨‹ï¼›DPOç®—æ³•ä»0ä½¿ç”¨PyTorchåŸç”Ÿå®ç°ï¼›æ¨¡å‹ç™½ç›’è’¸é¦åŸç”Ÿå®ç°ã€‚\nMiniMind2-DeepSeek-R1ç³»åˆ—è’¸é¦æ¨¡å‹è¯ç”Ÿï¼\nMiniMind2å…·å¤‡ä¸€å®šçš„è‹±æ–‡èƒ½åŠ›ï¼\næ›´æ–°MiniMind2ä¸ç¬¬ä¸‰æ–¹æ¨¡å‹çš„åŸºäºæ›´å¤šå¤§æ¨¡å‹æ¦œå•æµ‹è¯•æ€§èƒ½çš„ç»“æœã€‚\n\n\n\n 2024-10-05 \n\nä¸ºMiniMindæ‹“å±•äº†å¤šæ¨¡æ€èƒ½åŠ›ä¹‹---è§†è§‰\nç§»æ­¥å­ªç”Ÿé¡¹ç›®minimind-væŸ¥çœ‹è¯¦æƒ…ï¼\n\n\n\n 2024-09-27 \n\n09-27æ›´æ–°pretrainæ•°æ®é›†çš„é¢„å¤„ç†æ–¹å¼ï¼Œä¸ºäº†ä¿è¯æ–‡æœ¬å®Œæ•´æ€§ï¼Œæ”¾å¼ƒé¢„å¤„ç†æˆ.binè®­ç»ƒçš„å½¢å¼ï¼ˆè½»å¾®ç‰ºç‰²è®­ç»ƒé€Ÿåº¦ï¼‰ã€‚\nç›®å‰pretrainé¢„å¤„ç†åçš„æ–‡ä»¶å‘½åä¸ºï¼špretrain_data.csvã€‚\nåˆ é™¤äº†ä¸€äº›å†—ä½™çš„ä»£ç ã€‚\n\n\n\n 2024-09-17 \n\næ›´æ–°minimind-v1-moeæ¨¡å‹\nä¸ºäº†é˜²æ­¢æ­§ä¹‰ï¼Œä¸å†ä½¿ç”¨mistral_tokenizeråˆ†è¯ï¼Œå…¨éƒ¨é‡‡ç”¨è‡ªå®šä¹‰çš„minimind_tokenizerä½œä¸ºåˆ†è¯å™¨ã€‚\n\n\n\n 2024-09-01 \n\næ›´æ–°minimind-v1 (108M)æ¨¡å‹ï¼Œé‡‡ç”¨minimind_tokenizerï¼Œé¢„è®­ç»ƒè½®æ¬¡3 + SFTè½®æ¬¡10ï¼Œæ›´å……åˆ†è®­ç»ƒï¼Œæ€§èƒ½æ›´å¼ºã€‚\né¡¹ç›®å·²éƒ¨ç½²è‡³ModelScopeåˆ›ç©ºé—´ï¼Œå¯ä»¥åœ¨æ­¤ç½‘ç«™ä¸Šä½“éªŒï¼š\nğŸ”—ModelScopeåœ¨çº¿ä½“éªŒğŸ”—\n\n\n\n 2024-08-27 \n\né¡¹ç›®é¦–æ¬¡å¼€æº\n\n\nğŸ“Œ å¿«é€Ÿå¼€å§‹\n\nåˆ†äº«æœ¬äººçš„è½¯ç¡¬ä»¶é…ç½®ï¼ˆä»…ä¾›å‚è€ƒï¼‰\n\nCPU: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz\nRAM: 128 GB\nGPU: NVIDIA GeForce RTX 3090(24GB) * 8\nUbuntu==20.04\nCUDA==12.2\nPython==3.10.16\nrequirements.txt\n\n\nç¬¬0æ­¥\ngit clone https://github.com/jingyaogong/minimind.git\nâ…  æµ‹è¯•å·²æœ‰æ¨¡å‹æ•ˆæœ\n1.ç¯å¢ƒå‡†å¤‡\npip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n2.ä¸‹è½½æ¨¡å‹\ngit clone https://huggingface.co/jingyaogong/MiniMind2\n3.å‘½ä»¤è¡Œé—®ç­”\n# load=0: load from pytorch model, load=1: load from transformers-hf model\npython eval_model.py --load 1 --model_mode 2\n4.æˆ–å¯åŠ¨WebUI\n# å¯èƒ½éœ€è¦`python>=3.10` å®‰è£… `pip install streamlit`\n# cd scripts\nstreamlit run web_demo.py\nâ…¡ ä»0å¼€å§‹è‡ªå·±è®­ç»ƒ\n1.ç¯å¢ƒå‡†å¤‡\npip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n\næ³¨ï¼šæå‰æµ‹è¯•Torchæ˜¯å¦å¯ç”¨cuda\nimport torch\nprint(torch.cuda.is_available())\nå¦‚æœä¸å¯ç”¨ï¼Œè¯·è‡ªè¡Œå»torch_stable\nä¸‹è½½whlæ–‡ä»¶å®‰è£…ã€‚å‚è€ƒé“¾æ¥\n\n2.æ•°æ®ä¸‹è½½\nä»ä¸‹æ–‡æä¾›çš„æ•°æ®é›†ä¸‹è½½é“¾æ¥\nä¸‹è½½éœ€è¦çš„æ•°æ®æ–‡ä»¶ï¼ˆåˆ›å»º./datasetç›®å½•ï¼‰å¹¶æ”¾åˆ°./datasetä¸‹\n\næ³¨ï¼šæ•°æ®é›†é¡»çŸ¥\né»˜è®¤æ¨èä¸‹è½½pretrain_hq.jsonl + sft_mini_512.jsonlæœ€å¿«é€Ÿåº¦å¤ç°ZeroèŠå¤©æ¨¡å‹ã€‚\næ•°æ®æ–‡ä»¶å¯è‡ªç”±é€‰æ‹©ï¼Œä¸‹æ–‡æä¾›äº†å¤šç§æ­é…æ–¹æ¡ˆï¼Œå¯æ ¹æ®è‡ªå·±æ‰‹å¤´çš„è®­ç»ƒéœ€æ±‚å’ŒGPUèµ„æºè¿›è¡Œé€‚å½“ç»„åˆã€‚\n\n3.å¼€å§‹è®­ç»ƒ\n3.1 é¢„è®­ç»ƒï¼ˆå­¦çŸ¥è¯†ï¼‰\npython train_pretrain.py\n\næ‰§è¡Œé¢„è®­ç»ƒï¼Œå¾—åˆ° pretrain_*.pth ä½œä¸ºé¢„è®­ç»ƒçš„è¾“å‡ºæƒé‡ï¼ˆå…¶ä¸­*ä¸ºæ¨¡å‹çš„dimensionï¼Œé»˜è®¤ä¸º512ï¼‰\n\n3.2 ç›‘ç£å¾®è°ƒï¼ˆå­¦å¯¹è¯æ–¹å¼ï¼‰\npython train_full_sft.py\n\næ‰§è¡Œç›‘ç£å¾®è°ƒï¼Œå¾—åˆ° full_sft_*.pth ä½œä¸ºæŒ‡ä»¤å¾®è°ƒçš„è¾“å‡ºæƒé‡ï¼ˆå…¶ä¸­fullå³ä¸ºå…¨å‚æ•°å¾®è°ƒï¼‰\n\n\næ³¨ï¼šè®­ç»ƒé¡»çŸ¥\næ‰€æœ‰è®­ç»ƒè¿‡ç¨‹é»˜è®¤æ¯éš”100æ­¥ä¿å­˜1æ¬¡å‚æ•°åˆ°æ–‡ä»¶./out/***.pthï¼ˆæ¯æ¬¡ä¼šè¦†ç›–æ‰æ—§æƒé‡æ–‡ä»¶ï¼‰ã€‚\nç®€å•èµ·è§ï¼Œæ­¤å¤„åªå†™æ˜ä¸¤ä¸ªé˜¶æ®µè®­ç»ƒè¿‡ç¨‹ã€‚å¦‚éœ€å…¶å®ƒè®­ç»ƒ (LoRA, è’¸é¦, å¼ºåŒ–å­¦ä¹ , å¾®è°ƒæ¨ç†ç­‰) å¯å‚è€ƒä¸‹æ–‡ã€å®éªŒã€‘å°èŠ‚çš„è¯¦ç»†è¯´æ˜ã€‚\n\n\n4.æµ‹è¯•æ¨¡å‹æ•ˆæœ\nç¡®ä¿éœ€è¦æµ‹è¯•çš„æ¨¡å‹*.pthæ–‡ä»¶ä½äº./out/ç›®å½•ä¸‹ã€‚\nä¹Ÿå¯ä»¥ç›´æ¥å»æ­¤å¤„ä¸‹è½½ä½¿ç”¨æˆ‘è®­ç»ƒçš„*.pthæ–‡ä»¶ã€‚\npython eval_model.py --model_mode 1 # é»˜è®¤ä¸º0ï¼šæµ‹è¯•pretrainæ¨¡å‹æ•ˆæœï¼Œè®¾ç½®ä¸º1ï¼šæµ‹è¯•full_sftæ¨¡å‹æ•ˆæœ\n\næ³¨ï¼šæµ‹è¯•é¡»çŸ¥\nå¦‚éœ€è¯¦æƒ…ï¼ŒæŸ¥çœ‹eval_model.pyè„šæœ¬ä»£ç å³å¯ã€‚model_modeåˆ†ä¸º 0: é¢„è®­ç»ƒæ¨¡å‹ï¼Œ1: SFT-Chatæ¨¡å‹ï¼Œ2: RLHF-Chatæ¨¡å‹ï¼Œ3: Reasonæ¨¡å‹\n\n\nTipæ‰€æœ‰è®­ç»ƒè„šæœ¬å‡ä¸ºPytorchåŸç”Ÿæ¡†æ¶ï¼Œå‡æ”¯æŒå¤šå¡åŠ é€Ÿï¼Œå‡è®¾ä½ çš„è®¾å¤‡æœ‰N (Nï¼1) å¼ æ˜¾å¡ï¼š\n\nå•æœºNå¡å¯åŠ¨è®­ç»ƒæ–¹å¼ (DDP, æ”¯æŒå¤šæœºå¤šå¡é›†ç¾¤)\ntorchrun --nproc_per_node N train_xxx.py\n\næ³¨ï¼šå…¶å®ƒé¡»çŸ¥\nå•æœºNå¡å¯åŠ¨è®­ç»ƒ (DeepSpeed)\ndeepspeed --master_port 29500 --num_gpus=N train_xxx.py\nå¯æ ¹æ®éœ€è¦å¼€å¯wandbè®°å½•è®­ç»ƒè¿‡ç¨‹\n# éœ€è¦ç™»å½•: wandb login\ntorchrun --nproc_per_node N train_xxx.py --use_wandb\n# and\npython train_xxx.py --use_wandb\né€šè¿‡æ·»åŠ --use_wandbå‚æ•°ï¼Œå¯ä»¥è®°å½•è®­ç»ƒè¿‡ç¨‹ï¼Œè®­ç»ƒå®Œæˆåï¼Œå¯ä»¥åœ¨wandbç½‘ç«™ä¸ŠæŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ã€‚é€šè¿‡ä¿®æ”¹wandb_project\nå’Œwandb_run_nameå‚æ•°ï¼Œå¯ä»¥æŒ‡å®šé¡¹ç›®åç§°å’Œè¿è¡Œåç§°ã€‚\n\nğŸ“Œ æ•°æ®ä»‹ç»\nâ…  Tokenizer\nåˆ†è¯å™¨å°†å•è¯ä»è‡ªç„¶è¯­è¨€é€šè¿‡â€œè¯å…¸â€æ˜ å°„åˆ°0, 1, 36è¿™æ ·çš„æ•°å­—ï¼Œå¯ä»¥ç†è§£ä¸ºæ•°å­—å°±ä»£è¡¨äº†å•è¯åœ¨â€œè¯å…¸â€ä¸­çš„é¡µç ã€‚\nå¯ä»¥é€‰æ‹©è‡ªå·±æ„é€ è¯è¡¨è®­ç»ƒä¸€ä¸ªâ€œè¯å…¸â€ï¼Œä»£ç å¯è§./scripts/train_tokenizer.pyï¼ˆä»…ä¾›å­¦ä¹ å‚è€ƒï¼Œè‹¥éå¿…è¦æ— éœ€å†è‡ªè¡Œè®­ç»ƒï¼ŒMiniMindå·²è‡ªå¸¦tokenizerï¼‰ã€‚\næˆ–è€…é€‰æ‹©æ¯”è¾ƒå‡ºåçš„å¼€æºå¤§æ¨¡å‹åˆ†è¯å™¨ï¼Œ\næ­£å¦‚åŒç›´æ¥ç”¨æ–°å/ç‰›æ´¥è¯å…¸çš„ä¼˜ç‚¹æ˜¯tokenç¼–ç å‹ç¼©ç‡å¾ˆå¥½ï¼Œç¼ºç‚¹æ˜¯é¡µæ•°å¤ªå¤šï¼ŒåŠ¨è¾„æ•°åä¸‡ä¸ªè¯æ±‡çŸ­è¯­ï¼›\nè‡ªå·±è®­ç»ƒçš„åˆ†è¯å™¨ï¼Œä¼˜ç‚¹æ˜¯è¯è¡¨é•¿åº¦å’Œå†…å®¹éšæ„æ§åˆ¶ï¼Œç¼ºç‚¹æ˜¯å‹ç¼©ç‡å¾ˆä½ï¼ˆä¾‹å¦‚\"hello\"ä¹Ÿè®¸ä¼šè¢«æ‹†åˆ†ä¸º\"h e l l o\"\näº”ä¸ªç‹¬ç«‹çš„tokenï¼‰ï¼Œä¸”ç”Ÿåƒ»è¯éš¾ä»¥è¦†ç›–ã€‚\nâ€œè¯å…¸â€çš„é€‰æ‹©å›ºç„¶å¾ˆé‡è¦ï¼ŒLLMçš„è¾“å‡ºæœ¬è´¨ä¸Šæ˜¯SoftMaxåˆ°è¯å…¸Nä¸ªè¯çš„å¤šåˆ†ç±»é—®é¢˜ï¼Œç„¶åé€šè¿‡â€œè¯å…¸â€è§£ç åˆ°è‡ªç„¶è¯­è¨€ã€‚\nå› ä¸ºMiniMindä½“ç§¯éœ€è¦ä¸¥æ ¼æ§åˆ¶ï¼Œä¸ºäº†é¿å…æ¨¡å‹å¤´é‡è„šè½»ï¼ˆè¯åµŒå…¥embeddingå±‚å‚æ•°åœ¨LLMå æ¯”å¤ªé«˜ï¼‰ï¼Œæ‰€ä»¥è¯è¡¨é•¿åº¦çŸ­çŸ­ç›Šå–„ã€‚\n\nTokenizerä»‹ç»\nç¬¬ä¸‰æ–¹å¼ºå¤§çš„å¼€æºæ¨¡å‹ä¾‹å¦‚Yiã€qwenã€chatglmã€mistralã€Llama3çš„tokenizerè¯è¡¨é•¿åº¦å¦‚ä¸‹ï¼š\n\nTokenizeræ¨¡å‹è¯è¡¨å¤§å°æ¥æº\nyi tokenizer64,00001ä¸‡ç‰©ï¼ˆä¸­å›½ï¼‰\nqwen2 tokenizer151,643é˜¿é‡Œäº‘ï¼ˆä¸­å›½ï¼‰\nglm tokenizer151,329æ™ºè°±AIï¼ˆä¸­å›½ï¼‰\nmistral tokenizer32,000Mistral AIï¼ˆæ³•å›½ï¼‰\nllama3 tokenizer128,000Metaï¼ˆç¾å›½ï¼‰\nminimind tokenizer6,400è‡ªå®šä¹‰\n\n\nğŸ‘‰2024-09-17æ›´æ–°ï¼šä¸ºäº†é˜²æ­¢è¿‡å»çš„ç‰ˆæœ¬æ­§ä¹‰&æ§åˆ¶ä½“ç§¯ï¼Œminimindæ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨minimind_tokenizeråˆ†è¯ï¼ŒåºŸå¼ƒæ‰€æœ‰mistral_tokenizerç‰ˆæœ¬ã€‚\n\n# ä¸€äº›è‡ªè¨€è‡ªè¯­\n> å°½ç®¡minimind_tokenizeré•¿åº¦å¾ˆå°ï¼Œç¼–è§£ç æ•ˆç‡å¼±äºqwen2ã€glmç­‰ä¸­æ–‡å‹å¥½å‹åˆ†è¯å™¨ã€‚\n> ä½†minimindæ¨¡å‹é€‰æ‹©äº†è‡ªå·±è®­ç»ƒçš„minimind_tokenizerä½œä¸ºåˆ†è¯å™¨ï¼Œä»¥ä¿æŒæ•´ä½“å‚æ•°è½»é‡ï¼Œé¿å…ç¼–ç å±‚å’Œè®¡ç®—å±‚å æ¯”å¤±è¡¡ï¼Œå¤´é‡è„šè½»ï¼Œå› ä¸ºminimindçš„è¯è¡¨å¤§å°åªæœ‰6400ã€‚\n> ä¸”minimindåœ¨å®é™…æµ‹è¯•ä¸­æ²¡æœ‰å‡ºç°è¿‡ç”Ÿåƒ»è¯æ±‡è§£ç å¤±è´¥çš„æƒ…å†µï¼Œæ•ˆæœè‰¯å¥½ã€‚\n> ç”±äºè‡ªå®šä¹‰è¯è¡¨å‹ç¼©é•¿åº¦åˆ°6400ï¼Œä½¿å¾—LLMæ€»å‚æ•°é‡æœ€ä½åªæœ‰25.8Mã€‚\n> è®­ç»ƒæ•°æ®`tokenizer_train.jsonl`å‡æ¥è‡ªäº`åŒ æ•°å¤§æ¨¡å‹æ•°æ®é›†`ï¼Œè¿™éƒ¨åˆ†æ•°æ®ç›¸å¯¹æ¬¡è¦ï¼Œå¦‚éœ€è®­ç»ƒå¯ä»¥è‡ªç”±é€‰æ‹©ã€‚\n\n\nâ…¡ Pretrainæ•°æ®\nç»å†äº†MiniMind-V1çš„ä½è´¨é‡é¢„è®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´æ¨¡å‹èƒ¡è¨€ä¹±è¯­çš„æ•™è®­ï¼Œ2025-02-05 ä¹‹åå†³å®šä¸å†é‡‡ç”¨å¤§è§„æ¨¡æ— ç›‘ç£çš„æ•°æ®é›†åšé¢„è®­ç»ƒã€‚\nè¿›è€Œå°è¯•æŠŠåŒ æ•°å¤§æ¨¡å‹æ•°æ®é›†çš„ä¸­æ–‡éƒ¨åˆ†æå–å‡ºæ¥ï¼Œ\næ¸…æ´—å‡ºå­—ç¬¦<512é•¿åº¦çš„å¤§çº¦1.6GBçš„è¯­æ–™ç›´æ¥æ‹¼æ¥æˆé¢„è®­ç»ƒæ•°æ® pretrain_hq.jsonlï¼Œhqå³ä¸ºhigh\nqualityï¼ˆå½“ç„¶ä¹Ÿè¿˜ä¸ç®—highï¼Œæå‡æ•°æ®è´¨é‡æ— æ­¢å°½ï¼‰ã€‚\næ–‡ä»¶pretrain_hq.jsonl æ•°æ®æ ¼å¼ä¸º\n{\"text\": \"å¦‚ä½•æ‰èƒ½æ‘†è„±æ‹–å»¶ç—‡ï¼Ÿ æ²»æ„ˆæ‹–å»¶ç—‡å¹¶ä¸å®¹æ˜“ï¼Œä½†ä»¥ä¸‹å»ºè®®å¯èƒ½æœ‰æ‰€å¸®åŠ©...\"}\nâ…¢ SFTæ•°æ®\nåŒ æ•°å¤§æ¨¡å‹SFTæ•°æ®é›†\nâ€œæ˜¯ä¸€ä¸ªå®Œæ•´ã€æ ¼å¼ç»Ÿä¸€ã€å®‰å…¨çš„å¤§æ¨¡å‹è®­ç»ƒå’Œç ”ç©¶èµ„æºã€‚\nä»ç½‘ç»œä¸Šçš„å…¬å¼€æ•°æ®æºæ”¶é›†å¹¶æ•´ç†äº†å¤§é‡å¼€æºæ•°æ®é›†ï¼Œå¯¹å…¶è¿›è¡Œäº†æ ¼å¼ç»Ÿä¸€ï¼Œæ•°æ®æ¸…æ´—ï¼Œ\nåŒ…å«10Mæ¡æ•°æ®çš„ä¸­æ–‡æ•°æ®é›†å’ŒåŒ…å«2Mæ¡æ•°æ®çš„è‹±æ–‡æ•°æ®é›†ã€‚â€\nä»¥ä¸Šæ˜¯å®˜æ–¹ä»‹ç»ï¼Œä¸‹è½½æ–‡ä»¶åçš„æ•°æ®æ€»é‡å¤§çº¦åœ¨4B tokensï¼Œè‚¯å®šæ˜¯é€‚åˆä½œä¸ºä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹çš„SFTæ•°æ®çš„ã€‚\nä½†æ˜¯å®˜æ–¹æä¾›çš„æ•°æ®æ ¼å¼å¾ˆä¹±ï¼Œå…¨éƒ¨ç”¨æ¥sftä»£ä»·å¤ªå¤§ã€‚\næˆ‘å°†æŠŠå®˜æ–¹æ•°æ®é›†è¿›è¡Œäº†äºŒæ¬¡æ¸…æ´—ï¼ŒæŠŠå«æœ‰ç¬¦å·æ±¡æŸ“å’Œå™ªå£°çš„æ¡ç›®å»é™¤ï¼›å¦å¤–ä¾ç„¶åªä¿ç•™äº†æ€»é•¿åº¦<512\nçš„å†…å®¹ï¼Œæ­¤é˜¶æ®µå¸Œæœ›é€šè¿‡å¤§é‡å¯¹è¯è¡¥å……é¢„è®­ç»ƒé˜¶æ®µæ¬ ç¼ºçš„çŸ¥è¯†ã€‚\nå¯¼å‡ºæ–‡ä»¶ä¸ºsft_512.jsonl(~7.5GB)ã€‚\nMagpie-SFTæ•°æ®é›†\næ”¶é›†äº†~1Mæ¡æ¥è‡ªQwen2/2.5çš„é«˜è´¨é‡å¯¹è¯ï¼Œæˆ‘å°†è¿™éƒ¨åˆ†æ•°æ®è¿›ä¸€æ­¥æ¸…æ´—ï¼ŒæŠŠæ€»é•¿åº¦<2048çš„éƒ¨åˆ†å¯¼å‡ºä¸ºsft_2048.jsonl(~9GB)ã€‚\né•¿åº¦<1024çš„éƒ¨åˆ†å¯¼å‡ºä¸ºsft_1024.jsonl(~5.5GB)ï¼Œç”¨å¤§æ¨¡å‹å¯¹è¯æ•°æ®ç›´æ¥è¿›è¡Œsftå°±å±äºâ€œé»‘ç›’è’¸é¦â€çš„èŒƒç•´ã€‚\nè¿›ä¸€æ­¥æ¸…æ´—å‰ä¸¤æ­¥sftçš„æ•°æ®ï¼ˆåªä¿ç•™ä¸­æ–‡å­—ç¬¦å æ¯”é«˜çš„å†…å®¹ï¼‰ï¼Œç­›é€‰é•¿åº¦<512çš„å¯¹è¯ï¼Œå¾—åˆ°sft_mini_512.jsonl(~1.2GB)ã€‚\næ‰€æœ‰sftæ–‡ä»¶ sft_X.jsonl æ•°æ®æ ¼å¼å‡ä¸º\n{\n    \"conversations\": [\n        {\"role\": \"user\", \"content\": \"ä½ å¥½\"},\n        {\"role\": \"assistant\", \"content\": \"ä½ å¥½ï¼\"},\n        {\"role\": \"user\", \"content\": \"å†è§\"},\n        {\"role\": \"assistant\", \"content\": \"å†è§ï¼\"}\n    ]\n}\n\nâ…£ RLHFæ•°æ®\næ¥è‡ªMagpie-DPOæ•°æ®é›†\nå¤§çº¦200kæ¡åå¥½æ•°æ®ï¼ˆå‡æ˜¯è‹±æ–‡ï¼‰ç”Ÿæˆè‡ªLlama3.1-70B/8Bï¼Œå¯ä»¥ç”¨äºè®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œä¼˜åŒ–æ¨¡å‹å›å¤è´¨é‡ï¼Œä½¿å…¶æ›´åŠ ç¬¦åˆäººç±»åå¥½ã€‚\nè¿™é‡Œå°†æ•°æ®æ€»é•¿åº¦<3000çš„å†…å®¹é‡ç»„ä¸ºdpo.jsonl(~0.9GB)ï¼ŒåŒ…å«chosenå’Œrejectedä¸¤ä¸ªå­—æ®µï¼Œchosen\nä¸ºåå¥½çš„å›å¤ï¼Œrejectedä¸ºæ‹’ç»çš„å›å¤ã€‚\næ–‡ä»¶ dpo.jsonl æ•°æ®æ ¼å¼ä¸º\n{\n  \"chosen\": [\n    {\"content\": \"Q\", \"role\": \"user\"}, \n    {\"content\": \"good answer\", \"role\": \"assistant\"}\n  ], \n  \"rejected\": [\n    {\"content\": \"Q\", \"role\": \"user\"}, \n    {\"content\": \"bad answer\", \"role\": \"assistant\"}\n  ]\n}\n\nâ…¤ Reasonæ•°æ®é›†ï¼š\nä¸å¾—ä¸è¯´2025å¹´2æœˆè°èƒ½ç«çš„è¿‡DeepSeek...\nä¹Ÿæ¿€å‘äº†æˆ‘å¯¹RLå¼•å¯¼çš„æ¨ç†æ¨¡å‹çš„æµ“åšå…´è¶£ï¼Œç›®å‰å·²ç»ç”¨Qwen2.5å¤ç°äº†R1-Zeroã€‚\nå¦‚æœæœ‰æ—¶é—´+æ•ˆæœworkï¼ˆä½†99%åŸºæ¨¡èƒ½åŠ›ä¸è¶³ï¼‰æˆ‘ä¼šåœ¨ä¹‹åæ›´æ–°MiniMindåŸºäºRLè®­ç»ƒçš„æ¨ç†æ¨¡å‹è€Œä¸æ˜¯è’¸é¦æ¨¡å‹ã€‚\næ—¶é—´æœ‰é™ï¼Œæœ€å¿«çš„ä½æˆæœ¬æ–¹æ¡ˆä¾ç„¶æ˜¯ç›´æ¥è’¸é¦ï¼ˆé»‘ç›’æ–¹å¼ï¼‰ã€‚\nè€ä¸ä½R1å¤ªç«ï¼ŒçŸ­çŸ­å‡ å¤©å°±å·²ç»å­˜åœ¨ä¸€äº›R1çš„è’¸é¦æ•°æ®é›†R1-Llama-70Bã€R1-Distill-SFTã€\nAlpaca-Distill-R1ã€\ndeepseek_r1_zhç­‰ç­‰ï¼Œçº¯ä¸­æ–‡çš„æ•°æ®å¯èƒ½æ¯”è¾ƒå°‘ã€‚\næœ€ç»ˆæ•´åˆå®ƒä»¬ï¼Œå¯¼å‡ºæ–‡ä»¶ä¸ºr1_mix_1024.jsonlï¼Œæ•°æ®æ ¼å¼å’Œsft_X.jsonlä¸€è‡´ã€‚\nâ…¥ æ›´å¤šæ•°æ®é›†\nç›®å‰å·²ç»æœ‰HqWu-HITCS/Awesome-Chinese-LLM\nåœ¨æ”¶é›†å’Œæ¢³ç†ä¸­æ–‡LLMç›¸å…³çš„å¼€æºæ¨¡å‹ã€åº”ç”¨ã€æ•°æ®é›†åŠæ•™ç¨‹ç­‰èµ„æ–™ï¼Œå¹¶æŒç»­æ›´æ–°è¿™æ–¹é¢çš„æœ€æ–°è¿›å±•ã€‚å…¨é¢ä¸”ä¸“ä¸šï¼ŒRespectï¼\n\nâ…§ æ•°æ®é›†ä¸‹è½½\nNote2025-02-05åï¼Œå¼€æºMiniMindæœ€ç»ˆè®­ç»ƒæ‰€ç”¨çš„æ‰€æœ‰æ•°æ®é›†ï¼Œå› æ­¤æ— éœ€å†è‡ªè¡Œé¢„å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ï¼Œé¿å…é‡å¤æ€§çš„æ•°æ®å¤„ç†å·¥ä½œã€‚\n\nMiniMindè®­ç»ƒæ•°æ®é›† (ModelScope | HuggingFace)\n\næ— éœ€å…¨éƒ¨cloneï¼Œå¯å•ç‹¬ä¸‹è½½æ‰€éœ€çš„æ–‡ä»¶\n\nå°†ä¸‹è½½çš„æ•°æ®é›†æ–‡ä»¶æ”¾åˆ°./dataset/ç›®å½•ä¸‹ï¼ˆâœ¨ä¸ºæ¨èçš„å¿…é¡»é¡¹ï¼‰\n./dataset/\nâ”œâ”€â”€ dpo.jsonl (909MB)\nâ”œâ”€â”€ lora_identity.jsonl (22.8KB)\nâ”œâ”€â”€ lora_medical.jsonl (34MB)\nâ”œâ”€â”€ pretrain_hq.jsonl (1.6GB, âœ¨)\nâ”œâ”€â”€ r1_mix_1024.jsonl (340MB)\nâ”œâ”€â”€ sft_1024.jsonl (5.6GB)\nâ”œâ”€â”€ sft_2048.jsonl (9GB)\nâ”œâ”€â”€ sft_512.jsonl (7.5GB)\nâ”œâ”€â”€ sft_mini_512.jsonl (1.2GB, âœ¨)\nâ””â”€â”€ tokenizer_train.jsonl (1GB)\n\næ³¨ï¼šå„æ•°æ®é›†ç®€ä»‹\n\ndpo.jsonl --RLHFé˜¶æ®µæ•°æ®é›†\nlora_identity.jsonl --è‡ªæˆ‘è®¤çŸ¥æ•°æ®é›†ï¼ˆä¾‹å¦‚ï¼šä½ æ˜¯è°ï¼Ÿæˆ‘æ˜¯minimind...ï¼‰ï¼Œæ¨èç”¨äºloraè®­ç»ƒï¼ˆäº¦å¯ç”¨äºå…¨å‚SFTï¼Œå‹¿è¢«åå­—å±€é™ï¼‰\nlora_medical.jsonl --åŒ»ç–—é—®ç­”æ•°æ®é›†ï¼Œæ¨èç”¨äºloraè®­ç»ƒï¼ˆäº¦å¯ç”¨äºå…¨å‚SFTï¼Œå‹¿è¢«åå­—å±€é™ï¼‰\npretrain_hq.jsonlâœ¨ --é¢„è®­ç»ƒæ•°æ®é›†ï¼Œæ•´åˆè‡ªjiangshuç§‘æŠ€\nr1_mix_1024.jsonl --DeepSeek-R1-1.5Bè’¸é¦æ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º1024ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=1024ï¼‰\nsft_1024.jsonl --æ•´åˆè‡ªQwen2.5è’¸é¦æ•°æ®ï¼ˆæ˜¯sft_2048çš„å­é›†ï¼‰ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º1024ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=1024ï¼‰\nsft_2048.jsonl --æ•´åˆè‡ªQwen2.5è’¸é¦æ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º2048ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=2048ï¼‰\nsft_512.jsonl --æ•´åˆè‡ªåŒ æ•°ç§‘æŠ€SFTæ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º512ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=512ï¼‰\nsft_mini_512.jsonlâœ¨ --æç®€æ•´åˆè‡ªåŒ æ•°ç§‘æŠ€SFTæ•°æ®+Qwen2.5è’¸é¦æ•°æ®ï¼ˆç”¨äºå¿«é€Ÿè®­ç»ƒZeroæ¨¡å‹ï¼‰ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º512ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=512ï¼‰\ntokenizer_train.jsonl --å‡æ¥è‡ªäºåŒ æ•°å¤§æ¨¡å‹æ•°æ®é›†ï¼Œè¿™éƒ¨åˆ†æ•°æ®ç›¸å¯¹æ¬¡è¦ï¼Œï¼ˆä¸æ¨èè‡ªå·±é‡å¤è®­ç»ƒtokenizerï¼Œç†ç”±å¦‚ä¸Šï¼‰å¦‚éœ€è‡ªå·±è®­ç»ƒtokenizerå¯ä»¥è‡ªç”±é€‰æ‹©æ•°æ®é›†ã€‚\n\n\n\n\nè¯´æ˜ & æ¨èè®­ç»ƒæ–¹æ¡ˆ\n\n\nMiniMind2 Serieså‡ç»è¿‡å…±çº¦20GBè¯­æ–™è®­ç»ƒï¼Œå¤§çº¦4B tokensï¼Œå³å¯¹åº”ä¸Šé¢çš„æ•°æ®ç»„åˆè®­ç»ƒç»“æœï¼ˆå¼€é”€ï¼šğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’°ï¼Œæ•ˆæœï¼šğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜Šï¼‰\n\n\næƒ³è¦æœ€å¿«é€Ÿåº¦ä»0å®ç°Zeroæ¨¡å‹ï¼Œæ¨èä½¿ç”¨pretrain_hq.jsonl + sft_mini_512.jsonl çš„æ•°æ®ç»„åˆï¼Œå…·ä½“èŠ±é”€å’Œæ•ˆæœå¯æŸ¥çœ‹ä¸‹æ–‡è¡¨æ ¼ï¼ˆå¼€é”€ï¼šğŸ’°ï¼Œæ•ˆæœï¼šğŸ˜ŠğŸ˜Šï¼‰\n\n\næ¨èå…·å¤‡ä¸€å®šç®—åŠ›èµ„æºæˆ–æ›´åœ¨æ„æ•ˆæœçš„æœ‹å‹å¯ä»¥è€ƒè™‘å‰è€…å®Œæ•´å¤ç°MiniMind2ï¼›ä»…æœ‰å•å¡GPUæˆ–åœ¨ä¹çŸ­æ—¶é—´å¿«é€Ÿå¤ç°çš„æœ‹å‹å¼ºçƒˆæ¨èåè€…ï¼›\n\n\nã€æŠ˜ä¸­æ–¹æ¡ˆã€‘äº¦å¯é€‰æ‹©ä¾‹å¦‚sft_mini_512.jsonlã€sft_1024.jsonlä¸­ç­‰è§„æ¨¡æ•°æ®è¿›è¡Œè‡ªç”±ç»„åˆè®­ç»ƒï¼ˆå¼€é”€ï¼šğŸ’°ğŸ’°ğŸ’°ï¼Œæ•ˆæœï¼šğŸ˜ŠğŸ˜ŠğŸ˜ŠğŸ˜Šï¼‰ã€‚\n\n\n\nğŸ“Œ Model Structure\nMiniMind-Denseï¼ˆå’ŒLlama3.1ä¸€æ ·ï¼‰ä½¿ç”¨äº†Transformerçš„Decoder-Onlyç»“æ„ï¼Œè·ŸGPT-3çš„åŒºåˆ«åœ¨äºï¼š\n\né‡‡ç”¨äº†GPT-3çš„é¢„æ ‡å‡†åŒ–æ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯åœ¨æ¯ä¸ªTransformerå­å±‚çš„è¾“å…¥ä¸Šè¿›è¡Œå½’ä¸€åŒ–ï¼Œè€Œä¸æ˜¯åœ¨è¾“å‡ºä¸Šã€‚å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨çš„æ˜¯RMSNormå½’ä¸€åŒ–å‡½æ•°ã€‚\nç”¨SwiGLUæ¿€æ´»å‡½æ•°æ›¿ä»£äº†ReLUï¼Œè¿™æ ·åšæ˜¯ä¸ºäº†æé«˜æ€§èƒ½ã€‚\nåƒGPT-Neoä¸€æ ·ï¼Œå»æ‰äº†ç»å¯¹ä½ç½®åµŒå…¥ï¼Œæ”¹ç”¨äº†æ—‹è½¬ä½ç½®åµŒå…¥ï¼ˆRoPEï¼‰ï¼Œè¿™æ ·åœ¨å¤„ç†è¶…å‡ºè®­ç»ƒé•¿åº¦çš„æ¨ç†æ—¶æ•ˆæœæ›´å¥½ã€‚\n\n\nMiniMind-MoEæ¨¡å‹ï¼Œå®ƒçš„ç»“æ„åŸºäºLlama3å’ŒDeepseek-V2/3ä¸­çš„MixFFNæ··åˆä¸“å®¶æ¨¡å—ã€‚\n\nDeepSeek-V2åœ¨å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰æ–¹é¢ï¼Œé‡‡ç”¨äº†æ›´ç»†ç²’åº¦çš„ä¸“å®¶åˆ†å‰²å’Œå…±äº«çš„ä¸“å®¶éš”ç¦»æŠ€æœ¯ï¼Œä»¥æé«˜Expertsçš„æ•ˆæœã€‚\n\n\nMiniMindçš„æ•´ä½“ç»“æ„ä¸€è‡´ï¼Œåªæ˜¯åœ¨RoPEè®¡ç®—ã€æ¨ç†å‡½æ•°å’ŒFFNå±‚çš„ä»£ç ä¸Šåšäº†ä¸€äº›å°è°ƒæ•´ã€‚\nå…¶ç»“æ„å¦‚ä¸‹å›¾ï¼ˆé‡ç»˜ç‰ˆï¼‰ï¼š\n\n\nä¿®æ”¹æ¨¡å‹é…ç½®è§./model/LMConfig.pyã€‚\nå‚è€ƒæ¨¡å‹å‚æ•°ç‰ˆæœ¬è§ä¸‹è¡¨ï¼š\n\n\n\nModel Name\nparams\nlen_vocab\nrope_theta\nn_layers\nd_model\nkv_heads\nq_heads\nshare+route\n\n\n\n\nMiniMind2-Small\n26M\n6400\n1e6\n8\n512\n2\n8\n-\n\n\nMiniMind2-MoE\n145M\n6400\n1e6\n8\n640\n2\n8\n1+4\n\n\nMiniMind2\n104M\n6400\n1e6\n16\n768\n2\n8\n-\n\n\nminimind-v1-small\n26M\n6400\n1e4\n8\n512\n8\n16\n-\n\n\nminimind-v1-moe\n4Ã—26M\n6400\n1e4\n8\n512\n8\n16\n1+4\n\n\nminimind-v1\n108M\n6400\n1e4\n16\n768\n8\n16\n-\n\n\n\nğŸ“Œ Experiment\nâ…  è®­ç»ƒå¼€é”€\n\næ—¶é—´å•ä½ï¼šå°æ—¶ (h)ã€‚\næˆæœ¬å•ä½ï¼šäººæ°‘å¸ (ï¿¥)ï¼›7ï¿¥ â‰ˆ 1ç¾å…ƒã€‚\n3090 ç§Ÿå¡å•ä»·ï¼šâ‰ˆ1.3ï¿¥/hï¼ˆå¯è‡ªè¡Œå‚è€ƒå®æ—¶å¸‚ä»·ï¼‰ã€‚\nå‚è€ƒæ ‡å‡†ï¼šè¡¨æ ¼ä»…å®æµ‹ pretrain å’Œ sft_mini_512 ä¸¤ä¸ªæ•°æ®é›†çš„è®­ç»ƒæ—¶é—´ï¼Œå…¶å®ƒè€—æ—¶æ ¹æ®æ•°æ®é›†å¤§å°ä¼°ç®—ï¼ˆå¯èƒ½å­˜åœ¨äº›è®¸å‡ºå…¥ï¼‰ã€‚\n\n\nåŸºäº 3090 ï¼ˆå•å¡ï¼‰æˆæœ¬è®¡ç®—\n\n\n\n\nModel Name\nparams\npretrain\nsft_mini_512\nsft_512\nsft_1024\nsft_2048\nRLHF\n\n\n\n\nMiniMind2-Small\n26M\nâ‰ˆ1.1hâ‰ˆ1.43ï¿¥\nâ‰ˆ1hâ‰ˆ1.3ï¿¥\nâ‰ˆ6hâ‰ˆ7.8ï¿¥\nâ‰ˆ4.58hâ‰ˆ5.95ï¿¥\nâ‰ˆ7.5hâ‰ˆ9.75ï¿¥\nâ‰ˆ1hâ‰ˆ1.3ï¿¥\n\n\nMiniMind2\n104M\nâ‰ˆ3.9hâ‰ˆ5.07ï¿¥\nâ‰ˆ3.3hâ‰ˆ4.29ï¿¥\nâ‰ˆ20hâ‰ˆ26ï¿¥\nâ‰ˆ15hâ‰ˆ19.5ï¿¥\nâ‰ˆ25hâ‰ˆ32.5ï¿¥\nâ‰ˆ3hâ‰ˆ3.9ï¿¥\n\n\n\n\n\nè®­ç»ƒå¼€é”€æ€»ç»“&é¢„æµ‹\n\nMiniMind2-Smallå‚æ•°\n\npretrain_hq+sft_mini_512æ•°æ®é›†\nå•å¡3090 (1 epoch) + 2.1å°æ—¶ + èŠ±è´¹2.73å…ƒäººæ°‘å¸\nå³å¯ä»0è®­ç»ƒå‡ºMiniMind-Zero-0.025Bæ¨¡å‹!!!\n\n\n\nMiniMind2-Smallå‚æ•°\n\npretrain_hq+sft_512+sft_2048+dpoæ•°æ®é›†\nå•å¡3090 (2 epochs) + å¤§çº¦38.16å°æ—¶ + èŠ±è´¹49.61å…ƒäººæ°‘å¸\nå³å¯ä»0è®­ç»ƒå‡ºMiniMind2-Small-0.025Bæ¨¡å‹!!!\n\n\n\nMiniMind2å‚æ•°\n\npretrain_hq+sft_512+sft_2048+dpoæ•°æ®é›†\nå•å¡3090 (2 epochs) + å¤§çº¦122å°æ—¶ + èŠ±è´¹158.6å…ƒäººæ°‘å¸\nå³å¯ä»0è®­ç»ƒå‡ºMiniMind2-0.1Bæ¨¡å‹!!!\n\n\n\nâœ¨åŸºäºå•å¡NVIDIA 3090çš„MiniMind-Zeroä»0è®­ç»ƒä»…éœ€2å°æ—¶ + 3å—é’±ï¼Œå®ç°ChatBotæ•ˆæœï¼\nâœ¨PSï¼šè‹¥é‡‡ç”¨8å¡4090è®­ç»ƒï¼Œæ€»ç”¨æ—¶ç”šè‡³å¯ä»¥å‹ç¼©åˆ°10åˆ†é’Ÿä»¥å†…ï¼ï¼ˆç”±äºæ—¶é—´æ›´çŸ­ï¼ŒèŠ±è´¹åŒæ ·3å…ƒå·¦å³ï¼Œä¸å•å¡æˆæœ¬ç›¸å½“ï¼‰\nâœ¨ä»¥æä½æä½çš„é—¨æ§›ï¼Œå®ç°äººäººå¯ç©çš„å¤§æ¨¡å‹è‡ªç”±ï¼è¿™æ­£æ˜¯MiniMindç³»åˆ—çš„è¯ç”Ÿåˆè¡·ï¼\nâœ¨ä»…ä»·å€¼3å—é’±æˆæœ¬çš„MiniMind-Zeroå¹¶ä¸æ˜¯å™±å¤´ï¼Chatæµ‹è¯•ï¼š\nğŸ‘¶: è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚\nğŸ¤–ï¸: ä½œä¸ºäººå·¥æ™ºèƒ½ï¼Œæˆ‘æ²¡æœ‰å®é™…çš„ç”Ÿæ´»ï¼Œä¹Ÿæ²¡æœ‰è‡ªæˆ‘æ„è¯†ï¼Œæ‰€ä»¥æ²¡æœ‰è‡ªå·±çš„ç”Ÿæ´»ã€‚æˆ‘è¢«è®¾è®¡æˆèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯ã€è¿›è¡Œå¯¹è¯ç­‰ã€‚æˆ‘çš„è®¾è®¡å’ŒåŠŸèƒ½æ˜¯ç”±è®¡ç®—æœºç§‘å­¦ã€æœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½æŠ€æœ¯å’Œç®—æ³•æ‰€æ„å»ºçš„ï¼Œæˆ‘é€šè¿‡ç¼–ç¨‹å’Œç®—æ³•å®ç°ã€‚\n\nğŸ‘¶: æ¨èä¸€äº›æ­å·çš„ç‰¹è‰²ç¾é£Ÿå§ã€‚\nğŸ¤–ï¸: æ­å·æœ‰å¾ˆå¤šç¾å‘³çš„ç‰¹è‰²ç¾é£Ÿï¼Œæ¯”å¦‚é¸¡è‚‰ä¸²ã€é³—é±¼å¤´ã€æ°´ç…®é±¼ã€è±†è…è„‘ç­‰ã€‚è¿™äº›ç¾é£Ÿéƒ½éå¸¸ç¾å‘³ï¼Œæœ‰ç€ç‹¬ç‰¹çš„é£å‘³å’Œå£æ„Ÿï¼Œç»å¯¹æ˜¯å€¼å¾—ä¸€è¯•çš„ç¾é£Ÿã€‚\n\nğŸ‘¶: è¯·ä¸ºæˆ‘è®²è§£â€œå¤§è¯­è¨€æ¨¡å‹â€è¿™ä¸ªæ¦‚å¿µã€‚\nğŸ¤–ï¸: å¤§è¯­è¨€æ¨¡å‹æ˜¯ä¸€ç§äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œå®ƒä½¿ç”¨å¤§é‡çš„æ–‡æœ¬æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ï¼Œç„¶ååœ¨ä¸æ–­çš„è¿­ä»£ä¸­ä¸æ–­ä¼˜åŒ–æ¨¡å‹ã€‚å®ƒçš„ç›®æ ‡æ˜¯æ ¹æ®è¾“å…¥çš„æ•°æ®æ¥ç”Ÿæˆç¬¦åˆç‰¹å®šéœ€æ±‚çš„æ–‡æœ¬ï¼Œè¿™äº›æ–‡æœ¬å¯ä»¥æ˜¯ä»»ä½•ä½ æ„Ÿå…´è¶£çš„ä¸»é¢˜ã€‚\n\nğŸ‘¶: Introduce the history of the United States, please.\nğŸ¤–ï¸: æ‚¨æåˆ°çš„â€œIntrook's the believeations of theument.\" è¿™ä¸ªåå­—æ¥æºäºä¸­å›½å¤ä»£çš„\"groty of of the change.\"\n\næé€Ÿä¸”åˆå…·æ•ˆæœï¼Œç”šè‡³ä»ç„¶å¯ä»¥è¿›ä¸€æ­¥å‹ç¼©è·å–æ›´å°æ›´ä¼˜è´¨çš„è®­ç»ƒæ•°æ®ã€‚\nZeroæ¨¡å‹æƒé‡ä¿å­˜ä¸º full_sft_512_zero.pthï¼ˆè§ä¸‹æ–‡MiniMindæ¨¡å‹æ–‡ä»¶é“¾æ¥ï¼‰ï¼Œå¦‚æœ‰å…´è¶£å¯ä¸‹è½½æ£€éªŒæ­¤æ¨¡å‹æ•ˆæœã€‚\n\nâ…¡ ä¸»è¦è®­ç»ƒæ­¥éª¤\n1. é¢„è®­ç»ƒ(Pretrain):\nLLMé¦–å…ˆè¦å­¦ä¹ çš„å¹¶éç›´æ¥ä¸äººäº¤æµï¼Œè€Œæ˜¯è®©ç½‘ç»œå‚æ•°ä¸­å……æ»¡çŸ¥è¯†çš„å¢¨æ°´ï¼Œâ€œå¢¨æ°´â€ ç†è®ºä¸Šå–çš„è¶Šé¥±è¶Šå¥½ï¼Œäº§ç”Ÿå¤§é‡çš„å¯¹ä¸–ç•Œçš„çŸ¥è¯†ç§¯ç´¯ã€‚\né¢„è®­ç»ƒå°±æ˜¯è®©Modelå…ˆåŸ‹å¤´è‹¦å­¦å¤§é‡åŸºæœ¬çš„çŸ¥è¯†ï¼Œä¾‹å¦‚ä»Wikiç™¾ç§‘ã€æ–°é—»ã€ä¹¦ç±æ•´ç†å¤§è§„æ¨¡çš„é«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚\nè¿™ä¸ªè¿‡ç¨‹æ˜¯â€œæ— ç›‘ç£â€çš„ï¼Œå³äººç±»ä¸éœ€è¦åœ¨è¿‡ç¨‹ä¸­åšä»»ä½•â€œæœ‰ç›‘ç£â€çš„æ ¡æ­£ï¼Œè€Œæ˜¯ç”±æ¨¡å‹è‡ªå·±ä»å¤§é‡æ–‡æœ¬ä¸­æ€»ç»“è§„å¾‹å­¦ä¹ çŸ¥è¯†ç‚¹ã€‚\næ¨¡å‹æ­¤é˜¶æ®µç›®çš„åªæœ‰ä¸€ä¸ªï¼šå­¦ä¼šè¯è¯­æ¥é¾™ã€‚ä¾‹å¦‚æˆ‘ä»¬è¾“å…¥â€œç§¦å§‹çš‡â€å››ä¸ªå­—ï¼Œå®ƒå¯ä»¥æ¥é¾™â€œæ˜¯ä¸­å›½çš„ç¬¬ä¸€ä½çš‡å¸â€ã€‚\ntorchrun --nproc_per_node 1 train_pretrain.py # 1å³ä¸ºå•å¡è®­ç»ƒï¼Œå¯æ ¹æ®ç¡¬ä»¶æƒ…å†µè‡ªè¡Œè°ƒæ•´ (è®¾ç½®>=2)\n# or\npython train_pretrain.py\n\nè®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”100æ­¥ä¿å­˜ä¸º: pretrain_*.pthï¼ˆ*\nä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰\n\n2. æœ‰ç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning):\nç»è¿‡é¢„è®­ç»ƒï¼ŒLLMæ­¤æ—¶å·²ç»æŒæ¡äº†å¤§é‡çŸ¥è¯†ï¼Œç„¶è€Œæ­¤æ—¶å®ƒåªä¼šæ— è„‘åœ°è¯è¯­æ¥é¾™ï¼Œè¿˜ä¸ä¼šä¸äººèŠå¤©ã€‚\nSFTé˜¶æ®µå°±éœ€è¦æŠŠåŠæˆå“LLMæ–½åŠ ä¸€ä¸ªè‡ªå®šä¹‰çš„èŠå¤©æ¨¡æ¿è¿›è¡Œå¾®è°ƒã€‚\nä¾‹å¦‚æ¨¡å‹é‡åˆ°è¿™æ ·çš„æ¨¡æ¿ã€é—®é¢˜->å›ç­”ï¼Œé—®é¢˜->å›ç­”ã€‘åä¸å†æ— è„‘æ¥é¾™ï¼Œè€Œæ˜¯æ„è¯†åˆ°è¿™æ˜¯ä¸€æ®µå®Œæ•´çš„å¯¹è¯ç»“æŸã€‚\nç§°è¿™ä¸ªè¿‡ç¨‹ä¸ºæŒ‡ä»¤å¾®è°ƒï¼Œå°±å¦‚åŒè®©å·²ç»å­¦å¯Œäº”è½¦çš„ã€Œç‰›é¡¿ã€å…ˆç”Ÿé€‚åº”21ä¸–çºªæ™ºèƒ½æ‰‹æœºçš„èŠå¤©ä¹ æƒ¯ï¼Œå­¦ä¹ å±å¹•å·¦ä¾§æ˜¯å¯¹æ–¹æ¶ˆæ¯ï¼Œå³ä¾§æ˜¯æœ¬äººæ¶ˆæ¯è¿™ä¸ªè§„å¾‹ã€‚\nåœ¨è®­ç»ƒæ—¶ï¼ŒMiniMindçš„æŒ‡ä»¤å’Œå›ç­”é•¿åº¦è¢«æˆªæ–­åœ¨512ï¼Œæ˜¯ä¸ºäº†èŠ‚çœæ˜¾å­˜ç©ºé—´ã€‚å°±åƒæˆ‘ä»¬å­¦ä¹ æ—¶ï¼Œä¼šå…ˆä»çŸ­çš„æ–‡ç« å¼€å§‹ï¼Œå½“å­¦ä¼šå†™ä½œ200å­—ä½œæ–‡åï¼Œ800å­—æ–‡ç« ä¹Ÿå¯ä»¥æ‰‹åˆ°æ“’æ¥ã€‚\nåœ¨éœ€è¦é•¿åº¦æ‹“å±•æ—¶ï¼Œåªéœ€è¦å‡†å¤‡å°‘é‡çš„2k/4k/8ké•¿åº¦å¯¹è¯æ•°æ®è¿›è¡Œè¿›ä¸€æ­¥å¾®è°ƒå³å¯ï¼ˆæ­¤æ—¶æœ€å¥½é…åˆRoPE-NTKçš„åŸºå‡†å·®å€¼ï¼‰ã€‚\n\nåœ¨æ¨ç†æ—¶é€šè¿‡è°ƒæ•´RoPEçº¿æ€§å·®å€¼ï¼Œå®ç°å…è®­ç»ƒé•¿åº¦å¤–æ¨åˆ°2048åŠä»¥ä¸Šå°†ä¼šå¾ˆæ–¹ä¾¿ã€‚\n\ntorchrun --nproc_per_node 1 train_full_sft.py\n# or\npython train_full_sft.py\n\nè®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”100æ­¥ä¿å­˜ä¸º: full_sft_*.pthï¼ˆ*\nä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰\n\nâ…¢ å…¶å®ƒè®­ç»ƒæ­¥éª¤\n3. äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ (Reinforcement Learning from Human Feedback, RLHF)\nåœ¨å‰é¢çš„è®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¨¡å‹å·²ç»å…·å¤‡äº†åŸºæœ¬çš„å¯¹è¯èƒ½åŠ›ï¼Œä½†æ˜¯è¿™æ ·çš„èƒ½åŠ›å®Œå…¨åŸºäºå•è¯æ¥é¾™ï¼Œç¼ºå°‘æ­£åæ ·ä¾‹çš„æ¿€åŠ±ã€‚\næ¨¡å‹æ­¤æ—¶å°šæœªçŸ¥ä»€ä¹ˆå›ç­”æ˜¯å¥½çš„ï¼Œä»€ä¹ˆæ˜¯å·®çš„ã€‚æˆ‘ä»¬å¸Œæœ›å®ƒèƒ½å¤Ÿæ›´ç¬¦åˆäººçš„åå¥½ï¼Œé™ä½è®©äººç±»ä¸æ»¡æ„ç­”æ¡ˆçš„äº§ç”Ÿæ¦‚ç‡ã€‚\nè¿™ä¸ªè¿‡ç¨‹å°±åƒæ˜¯è®©æ¨¡å‹å‚åŠ æ–°çš„åŸ¹è®­ï¼Œä»ä¼˜ç§€å‘˜å·¥çš„ä½œä¸ºä¾‹å­ï¼Œæ¶ˆæå‘˜å·¥ä½œä¸ºåä¾‹ï¼Œå­¦ä¹ å¦‚ä½•æ›´å¥½åœ°å›å¤ã€‚\næ­¤å¤„ä½¿ç”¨çš„æ˜¯RLHFç³»åˆ—ä¹‹-ç›´æ¥åå¥½ä¼˜åŒ–(Direct Preference Optimization, DPO)ã€‚\nä¸PPO(Proximal Policy Optimization)è¿™ç§éœ€è¦å¥–åŠ±æ¨¡å‹ã€ä»·å€¼æ¨¡å‹çš„RLç®—æ³•ä¸åŒï¼›\nDPOé€šè¿‡æ¨å¯¼PPOå¥–åŠ±æ¨¡å‹çš„æ˜¾å¼è§£ï¼ŒæŠŠåœ¨çº¿å¥–åŠ±æ¨¡å‹æ¢æˆç¦»çº¿æ•°æ®ï¼ŒRefæ¨¡å‹è¾“å‡ºå¯ä»¥æå‰ä¿å­˜ã€‚\nDPOæ€§èƒ½å‡ ä¹ä¸å˜ï¼Œåªç”¨è·‘ actor_model å’Œ ref_model ä¸¤ä¸ªæ¨¡å‹ï¼Œå¤§å¤§èŠ‚çœæ˜¾å­˜å¼€é”€å’Œå¢åŠ è®­ç»ƒç¨³å®šæ€§ã€‚\n\næ³¨ï¼šRLHFè®­ç»ƒæ­¥éª¤å¹¶éå¿…é¡»ï¼Œæ­¤æ­¥éª¤éš¾ä»¥æå‡æ¨¡å‹â€œæ™ºåŠ›â€è€Œé€šå¸¸ä»…ç”¨äºæå‡æ¨¡å‹çš„â€œç¤¼è²Œâ€ï¼Œæœ‰åˆ©ï¼ˆç¬¦åˆåå¥½ã€å‡å°‘æœ‰å®³å†…å®¹ï¼‰ä¹Ÿæœ‰å¼Šï¼ˆæ ·æœ¬æ”¶é›†æ˜‚è´µã€åé¦ˆåå·®ã€å¤šæ ·æ€§æŸå¤±ï¼‰ã€‚\n\ntorchrun --nproc_per_node 1 train_dpo.py\n# or\npython train_dpo.py\n\nè®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”100æ­¥ä¿å­˜ä¸º: rlhf_*.pthï¼ˆ*\nä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰\n\n4. çŸ¥è¯†è’¸é¦(Knowledge Distillation, KD)\nåœ¨å‰é¢çš„æ‰€æœ‰è®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¨¡å‹å·²ç»å®Œå…¨å…·å¤‡äº†åŸºæœ¬èƒ½åŠ›ï¼Œé€šå¸¸å¯ä»¥å­¦æˆå‡ºå¸ˆäº†ã€‚\nè€ŒçŸ¥è¯†è’¸é¦å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆç‡ï¼Œæ‰€è°“çŸ¥è¯†è’¸é¦ï¼Œå³å­¦ç”Ÿæ¨¡å‹é¢å‘æ•™å¸ˆæ¨¡å‹å­¦ä¹ ã€‚\næ•™å¸ˆæ¨¡å‹é€šå¸¸æ˜¯ç»è¿‡å……åˆ†è®­ç»ƒçš„å¤§æ¨¡å‹ï¼Œå…·æœ‰è¾ƒé«˜çš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚\nå­¦ç”Ÿæ¨¡å‹æ˜¯ä¸€ä¸ªè¾ƒå°çš„æ¨¡å‹ï¼Œç›®æ ‡æ˜¯å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„è¡Œä¸ºï¼Œè€Œä¸æ˜¯ç›´æ¥ä»åŸå§‹æ•°æ®ä¸­å­¦ä¹ ã€‚\nåœ¨SFTå­¦ä¹ ä¸­ï¼Œæ¨¡å‹çš„ç›®æ ‡æ˜¯æ‹Ÿåˆè¯Tokenåˆ†ç±»ç¡¬æ ‡ç­¾ï¼ˆhard labelsï¼‰ï¼Œå³çœŸå®çš„ç±»åˆ«æ ‡ç­¾ï¼ˆå¦‚ 0 æˆ– 6400ï¼‰ã€‚\nåœ¨çŸ¥è¯†è’¸é¦ä¸­ï¼Œæ•™å¸ˆæ¨¡å‹çš„softmaxæ¦‚ç‡åˆ†å¸ƒè¢«ç”¨ä½œè½¯æ ‡ç­¾ï¼ˆsoft labelsï¼‰ã€‚å°æ¨¡å‹ä»…å­¦ä¹ è½¯æ ‡ç­¾ï¼Œå¹¶ä½¿ç”¨KL-Lossæ¥ä¼˜åŒ–æ¨¡å‹çš„å‚æ•°ã€‚\né€šä¿—åœ°è¯´ï¼ŒSFTç›´æ¥å­¦ä¹ è€å¸ˆç»™çš„è§£é¢˜ç­”æ¡ˆã€‚è€ŒKDè¿‡ç¨‹ç›¸å½“äºâ€œæ‰“å¼€â€è€å¸ˆèªæ˜çš„å¤§è„‘ï¼Œå°½å¯èƒ½åœ°æ¨¡ä»¿è€å¸ˆâ€œå¤§è„‘â€æ€è€ƒé—®é¢˜çš„ç¥ç»å…ƒçŠ¶æ€ã€‚\nä¾‹å¦‚ï¼Œå½“è€å¸ˆæ¨¡å‹è®¡ç®—1+1=2è¿™ä¸ªé—®é¢˜çš„æ—¶å€™ï¼Œæœ€åä¸€å±‚ç¥ç»å…ƒaçŠ¶æ€ä¸º0ï¼Œç¥ç»å…ƒbçŠ¶æ€ä¸º100ï¼Œç¥ç»å…ƒcçŠ¶æ€ä¸º-99...\nå­¦ç”Ÿæ¨¡å‹é€šè¿‡å¤§é‡æ•°æ®ï¼Œå­¦ä¹ æ•™å¸ˆæ¨¡å‹å¤§è„‘å†…éƒ¨çš„è¿è½¬è§„å¾‹ã€‚è¿™ä¸ªè¿‡ç¨‹å³ç§°ä¹‹ä¸ºï¼šçŸ¥è¯†è’¸é¦ã€‚\nçŸ¥è¯†è’¸é¦çš„ç›®çš„åªæœ‰ä¸€ä¸ªï¼šè®©å°æ¨¡å‹ä½“ç§¯æ›´å°çš„åŒæ—¶æ•ˆæœæ›´å¥½ã€‚\nç„¶è€Œéšç€LLMè¯ç”Ÿå’Œå‘å±•ï¼Œæ¨¡å‹è’¸é¦ä¸€è¯è¢«å¹¿æ³›æ»¥ç”¨ï¼Œä»è€Œäº§ç”Ÿäº†â€œç™½ç›’/é»‘ç›’â€çŸ¥è¯†è’¸é¦ä¸¤ä¸ªæ´¾åˆ«ã€‚\nGPT-4è¿™ç§é—­æºæ¨¡å‹ï¼Œç”±äºæ— æ³•è·å–å…¶å†…éƒ¨ç»“æ„ï¼Œå› æ­¤åªèƒ½é¢å‘å®ƒæ‰€è¾“å‡ºçš„æ•°æ®å­¦ä¹ ï¼Œè¿™ä¸ªè¿‡ç¨‹ç§°ä¹‹ä¸ºé»‘ç›’è’¸é¦ï¼Œä¹Ÿæ˜¯å¤§æ¨¡å‹æ—¶ä»£æœ€æ™®éçš„åšæ³•ã€‚\né»‘ç›’è’¸é¦ä¸SFTè¿‡ç¨‹å®Œå…¨ä¸€è‡´ï¼Œåªä¸è¿‡æ•°æ®æ˜¯ä»å¤§æ¨¡å‹çš„è¾“å‡ºæ”¶é›†ï¼Œå› æ­¤åªéœ€è¦å‡†å¤‡æ•°æ®å¹¶ä¸”è¿›ä¸€æ­¥FTå³å¯ã€‚\næ³¨æ„æ›´æ”¹è¢«åŠ è½½çš„åŸºç¡€æ¨¡å‹ä¸ºfull_sft_*.pthï¼Œå³åŸºäºå¾®è°ƒæ¨¡å‹åšè¿›ä¸€æ­¥çš„è’¸é¦å­¦ä¹ ã€‚\n./dataset/sft_1024.jsonlä¸./dataset/sft_2048.jsonl å‡æ”¶é›†è‡ªqwen2.5-7/72B-Instructå¤§æ¨¡å‹ï¼Œå¯ç›´æ¥ç”¨äºSFTä»¥è·å–Qwençš„éƒ¨åˆ†è¡Œä¸ºã€‚\n# æ³¨æ„éœ€è¦æ›´æ”¹train_full_sft.pyæ•°æ®é›†è·¯å¾„ï¼Œä»¥åŠmax_seq_len  \ntorchrun --nproc_per_node 1 train_full_sft.py\n# or\npython train_full_sft.py\n\nè®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”100æ­¥åŒæ ·ä¿å­˜ä¸º: full_sft_*.pthï¼ˆ*ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰\n\næ­¤å¤„åº”å½“ç€é‡ä»‹ç»MiniMindå®ç°çš„ç™½ç›’è’¸é¦ä»£ç train_distillation.pyï¼Œç”±äºMiniMindåŒç³»åˆ—æœ¬èº«å¹¶ä¸å­˜åœ¨å¼ºå¤§çš„æ•™å¸ˆæ¨¡å‹ï¼Œå› æ­¤ç™½ç›’è’¸é¦ä»£ç ä»…ä½œä¸ºå­¦ä¹ å‚è€ƒã€‚\ntorchrun --nproc_per_node 1 train_distillation.py\n# or\npython train_distillation.py\n5. LoRA (Low-Rank Adaptation)\nLoRAæ˜¯ä¸€ç§é«˜æ•ˆçš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuning, PEFTï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ä½ç§©åˆ†è§£çš„æ–¹å¼å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚\nç›¸æ¯”äºå…¨å‚æ•°å¾®è°ƒï¼ˆFull Fine-Tuningï¼‰ï¼ŒLoRA åªéœ€è¦æ›´æ–°å°‘é‡çš„å‚æ•°ã€‚\nLoRA çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šåœ¨æ¨¡å‹çš„æƒé‡çŸ©é˜µä¸­å¼•å…¥ä½ç§©åˆ†è§£ï¼Œä»…å¯¹ä½ç§©éƒ¨åˆ†è¿›è¡Œæ›´æ–°ï¼Œè€Œä¿æŒåŸå§‹é¢„è®­ç»ƒæƒé‡ä¸å˜ã€‚\nä»£ç å¯è§./model/model_lora.pyå’Œtrain_lora.pyï¼Œå®Œå…¨ä»0å®ç°LoRAæµç¨‹ï¼Œä¸ä¾èµ–ç¬¬ä¸‰æ–¹åº“çš„å°è£…ã€‚\ntorchrun --nproc_per_node 1 train_lora.py\n# or\npython train_lora.py\n\nè®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”100æ­¥ä¿å­˜ä¸º: lora_xxx_*.pthï¼ˆ*\nä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰\n\néå¸¸å¤šçš„äººå›°æƒ‘ï¼Œå¦‚ä½•ä½¿æ¨¡å‹å­¦ä¼šè‡ªå·±ç§æœ‰é¢†åŸŸçš„çŸ¥è¯†ï¼Ÿå¦‚ä½•å‡†å¤‡æ•°æ®é›†ï¼Ÿå¦‚ä½•è¿ç§»é€šç”¨é¢†åŸŸæ¨¡å‹æ‰“é€ å‚åŸŸæ¨¡å‹ï¼Ÿ\nè¿™é‡Œä¸¾å‡ ä¸ªä¾‹å­ï¼Œå¯¹äºé€šç”¨æ¨¡å‹ï¼ŒåŒ»å­¦é¢†åŸŸçŸ¥è¯†æ¬ ç¼ºï¼Œå¯ä»¥å°è¯•åœ¨åŸæœ‰æ¨¡å‹åŸºç¡€ä¸ŠåŠ å…¥é¢†åŸŸçŸ¥è¯†ï¼Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚\nåŒæ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¸å¸Œæœ›å­¦ä¼šé¢†åŸŸçŸ¥è¯†çš„åŒæ—¶æŸå¤±åŸæœ‰åŸºç¡€æ¨¡å‹çš„å…¶å®ƒèƒ½åŠ›ï¼Œæ­¤æ—¶LoRAå¯ä»¥å¾ˆå¥½çš„æ”¹å–„è¿™ä¸ªé—®é¢˜ã€‚\nåªéœ€è¦å‡†å¤‡å¦‚ä¸‹æ ¼å¼çš„å¯¹è¯æ•°æ®é›†æ”¾ç½®åˆ°./dataset/lora_xxx.jsonlï¼Œå¯åŠ¨ python train_lora.py\nè®­ç»ƒå³å¯å¾—åˆ°./out/lora/lora_xxx.pthæ–°æ¨¡å‹æƒé‡ã€‚\nåŒ»ç–—åœºæ™¯\n {\"conversations\": [{\"role\": \"user\", \"content\": \"è¯·é—®é¢ˆæ¤ç—…çš„äººæ•å¤´å¤šé«˜æ‰æœ€å¥½ï¼Ÿ\"}, {\"role\": \"assistant\", \"content\": \"é¢ˆæ¤ç—…æ‚£è€…é€‰æ‹©æ•å¤´çš„é«˜åº¦åº”è¯¥æ ¹æ®...\"}]}\n {\"conversations\": [{\"role\": \"user\", \"content\": \"è¯·é—®xxx\"}, {\"role\": \"assistant\", \"content\": \"xxx...\"}]}\n\nè‡ªæˆ‘è®¤çŸ¥åœºæ™¯\n {\"conversations\": [{\"role\": \"user\", \"content\": \"ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ\"}, {\"role\": \"assistant\", \"content\": \"æˆ‘å«minimind...\"}]}\n {\"conversations\": [{\"role\": \"user\", \"content\": \"ä½ æ˜¯è°\"}, {\"role\": \"assistant\", \"content\": \"æˆ‘æ˜¯...\"}]}\n\næ­¤æ—¶ã€åŸºç¡€æ¨¡å‹+LoRAæ¨¡å‹ã€‘å³å¯è·å¾—åŒ»ç–—åœºæ™¯æ¨¡å‹å¢å¼ºçš„èƒ½åŠ›ï¼Œç›¸å½“äºä¸ºåŸºç¡€æ¨¡å‹å¢åŠ äº†LoRAå¤–æŒ‚ï¼Œè¿™ä¸ªè¿‡ç¨‹å¹¶ä¸æŸå¤±åŸºç¡€æ¨¡å‹çš„æœ¬èº«èƒ½åŠ›ã€‚\næˆ‘ä»¬å¯ä»¥é€šè¿‡eval_model.pyè¿›è¡Œæ¨¡å‹è¯„ä¼°æµ‹è¯•ã€‚\n# æ³¨æ„ï¼šmodel_modeå³é€‰æ‹©åŸºç¡€æ¨¡å‹çš„ç±»å‹ï¼Œè¿™å’Œtrain_loraæ˜¯åŸºäºå“ªä¸ªæ¨¡å‹è®­ç»ƒçš„ç›¸å…³ï¼Œç¡®ä¿ç»Ÿä¸€å³å¯ã€‚\npython eval_model.py --lora_name 'lora_medical' --model_mode 2\nå°æµ‹è¯•\nğŸ‘¶: æˆ‘æœ€è¿‘ç»å¸¸æ„Ÿåˆ°å¤´æ™•ï¼Œå¯èƒ½æ˜¯ä»€ä¹ˆåŸå› ï¼Ÿ\nğŸ¤–ï¸: å¤´æ™•å¯èƒ½æ˜¯ç”±äºå¤šç§åŸå› ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šå¿ƒè„ç–¾ç—…ã€çœ¼ç›æŸä¼¤ã€è¿‡æ•ååº”ã€çš®è‚¤é—®é¢˜ã€è¿‡æ•ååº”ã€å‹åŠ›ã€ç„¦è™‘ã€ç–²åŠ³ã€è¯ç‰©å‰¯ä½œç”¨ã€æ€§åŠŸèƒ½éšœç¢æˆ–è€…å…¶ä»–...\n\n---\n\nğŸ‘¶: ä½ å’Œopenaiæ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ\nğŸ¤–ï¸: æˆ‘æ˜¯ MiniMindï¼Œä¸€ä¸ªç”± Jingyao Gong å¼€å‘çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚æˆ‘é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†å’Œç®—æ³•è®­ç»ƒæ¥ä¸ç”¨æˆ·è¿›è¡Œäº¤äº’ã€‚\n\nPSï¼šåªè¦æœ‰æ‰€éœ€è¦çš„æ•°æ®é›†ï¼Œä¹Ÿå¯ä»¥full_sftå…¨å‚å¾®è°ƒï¼ˆéœ€è¦è¿›è¡Œé€šç”¨çŸ¥è¯†çš„æ··åˆé…æ¯”ï¼Œå¦åˆ™è¿‡æ‹Ÿåˆé¢†åŸŸæ•°æ®ä¼šè®©æ¨¡å‹å˜å‚»ï¼ŒæŸå¤±é€šç”¨æ€§ï¼‰\n6. è®­ç»ƒæ¨ç†æ¨¡å‹ (Reasoning Model)\nDeepSeek-R1å®åœ¨å¤ªç«äº†ï¼Œå‡ ä¹é‡æ–°æŒ‡æ˜äº†æœªæ¥LLMçš„æ–°èŒƒå¼ã€‚\nè®ºæ–‡æŒ‡å‡º>3Bçš„æ¨¡å‹ç»å†å¤šæ¬¡åå¤çš„å†·å¯åŠ¨å’ŒRLå¥–åŠ±è®­ç»ƒæ‰èƒ½è·å¾—è‚‰çœ¼å¯è§çš„æ¨ç†èƒ½åŠ›æå‡ã€‚\næœ€å¿«æœ€ç¨³å¦¥æœ€ç»æµçš„åšæ³•ï¼Œä»¥åŠæœ€è¿‘çˆ†å‘çš„å„ç§å„æ ·æ‰€è°“çš„æ¨ç†æ¨¡å‹å‡ ä¹éƒ½æ˜¯ç›´æ¥é¢å‘æ•°æ®è¿›è¡Œè’¸é¦è®­ç»ƒï¼Œ\nä½†ç”±äºç¼ºä¹æŠ€æœ¯å«é‡ï¼Œè’¸é¦æ´¾è¢«RLæ´¾ç§ä¸èµ·ï¼ˆhhhhï¼‰ã€‚\næœ¬äººè¿…é€Ÿå·²ç»åœ¨Qwenç³»åˆ—1.5Bå°æ¨¡å‹ä¸Šè¿›è¡Œäº†å°è¯•ï¼Œå¾ˆå¿«å¤ç°äº†Zeroè¿‡ç¨‹çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚\nç„¶è€Œä¸€ä¸ªé—æ†¾çš„å…±è¯†æ˜¯ï¼šå‚æ•°å¤ªå°çš„æ¨¡å‹ç›´æ¥é€šè¿‡å†·å¯åŠ¨SFT+GRPOå‡ ä¹ä¸å¯èƒ½è·å¾—ä»»ä½•æ¨ç†æ•ˆæœã€‚\nMiniMind2ç¬¬ä¸€æ—¶é—´åªèƒ½åšå®šä¸ç§»çš„é€‰æ‹©åšè’¸é¦æ´¾ï¼Œæ—¥ååŸºäº0.1Bæ¨¡å‹çš„RLå¦‚æœåŒæ ·å–å¾—å°å°è¿›å±•ä¼šæ›´æ–°æ­¤éƒ¨åˆ†çš„è®­ç»ƒæ–¹æ¡ˆã€‚\nåšè’¸é¦éœ€è¦å‡†å¤‡çš„ä¾ç„¶æ˜¯å’ŒSFTé˜¶æ®µåŒæ ·æ ¼å¼çš„æ•°æ®å³å¯ï¼Œæ•°æ®é›†æ¥æºå·²å¦‚ä¸Šæ–‡ä»‹ç»ã€‚æ•°æ®æ ¼å¼ä¾‹å¦‚ï¼š\n{\n  \"conversations\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"ä½ å¥½ï¼Œæˆ‘æ˜¯å°èŠ³ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"<think>\\nä½ å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…ç‹¬ç«‹å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1-Lite-Previewï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æœåŠ¡ï¼\\n</think>\\n<answer>\\nä½ å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…ç‹¬ç«‹å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1-Lite-Previewï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æœåŠ¡ï¼\\n</answer>\"\n    }\n  ]\n}\næ¨ç†æ¨¡å‹R1çš„å›å¤æ¨¡æ¿æ˜¯ï¼š\n<think>\\næ€è€ƒè¿‡ç¨‹\\n</think>\\n\n<answer>\\næœ€ç»ˆå›ç­”\\n</answer>\n\nè¿™åœ¨GRPOä¸­é€šè¿‡è®¾ç½®è§„åˆ™å¥–åŠ±å‡½æ•°çº¦æŸæ¨¡å‹ç¬¦åˆæ€è€ƒæ ‡ç­¾å’Œå›å¤æ ‡ç­¾ï¼ˆåœ¨å†·å¯åŠ¨é å‰çš„é˜¶æ®µå¥–åŠ±å€¼è®¾ç½®åº”è¯¥æé«˜ä¸€äº›ï¼‰\nå¦ä¸€ä¸ªé—®é¢˜æ˜¯è’¸é¦è¿‡ç¨‹è™½ç„¶å’ŒSFTä¸€æ ·ï¼Œä½†å®éªŒç»“æœæ˜¯æ¨¡å‹éš¾ä»¥æ¯æ¬¡éƒ½ç¬¦åˆæ¨¡æ¿è§„èŒƒçš„å›å¤ï¼Œå³è„±ç¦»æ€è€ƒå’Œå›å¤æ ‡ç­¾çº¦æŸã€‚\nè¿™é‡Œçš„å°æŠ€å·§æ˜¯å¢åŠ æ ‡è®°ä½ç½®tokençš„æŸå¤±æƒ©ç½šï¼Œè¯¦è§train_distill_reason.py:\n# åœ¨ sp_ids å¯¹åº”çš„ä½ç½®å¢åŠ é¢å¤–çš„æƒ©ç½š\n...\nloss_mask[sp_ids] = 10 # æƒ©ç½šç³»æ•°\n\nå¦å¦ä¸€ä¸ªtipsæ˜¯ç”±äºæ¨ç†æ•°æ®ç”±äºåªç­›é€‰äº†<1024é•¿åº¦çš„æ•°æ®ï¼Œå…¶ä¸­å¤šè½®å¯¹è¯å’Œè‹±æ–‡æ•°æ®åå°‘ï¼Œ\nå› æ­¤r1_mix_1024.jsonlè¿›è¡Œäº†å¤§çº¦10kæ¡å¤šè½®å¯¹è¯+è‹±æ–‡æ•°æ®çš„æ··åˆï¼Œé˜²æ­¢æ¨¡å‹é—å¿˜ä¸¥é‡ã€‚\nè„šæœ¬é»˜è®¤åŸºäºrlhfåçš„åŸºæ¨¡å‹åšæ¨ç†èƒ½åŠ›çš„è’¸é¦å¾®è°ƒï¼Œä¸‹é¢ç›´æ¥å¯åŠ¨è®­ç»ƒå³å¯ï¼š\ntorchrun --nproc_per_node 1 train_distill_reason.py\n# or\npython train_distill_reason.py\n\nè®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”100æ­¥ä¿å­˜ä¸º: reason_*.pthï¼ˆ*ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰\n\næµ‹è¯•ä¸€ä¸‹ï¼š\nğŸ‘¶: è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚\nğŸ¤–ï¸: <think>\nå—¯ï¼Œç”¨æˆ·è®©æˆ‘ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚æˆ‘ç°åœ¨éœ€è¦è§£é‡Šä¸€ä¸‹è‡ªå·±ã€‚é¦–å…ˆï¼Œæˆ‘åº”è¯¥æ˜ç¡®ç”¨æˆ·æ˜¯è°ï¼Œæ˜¯å­¦ç”Ÿã€èŒåœºäººå£«è¿˜æ˜¯æ™®é€šäººã€‚ç”¨æˆ·å¯èƒ½æ˜¯ä¸€ä¸ªå­¦ç”Ÿæˆ–è€…èŒåœºäººå£«ï¼Œæ‰€ä»¥ä¿¡æ¯ä¼ é€’åº”è¯¥æ˜¯å¸®åŠ©å­¦ç”Ÿå’ŒèŒåœºäººå£«çš„ä¿¡æ¯ã€‚\nç„¶åï¼Œæˆ‘éœ€è¦å›åº”ç”¨æˆ·ï¼Œè¿™å¯èƒ½åŒ…æ‹¬ä»‹ç»è‡ªå·±çš„ä½ç½®ã€å…´è¶£çˆ±å¥½ã€èŒä¸šç»å†ç­‰ä¿¡æ¯ã€‚ç”¨æˆ·è¿˜å¯èƒ½æƒ³äº†è§£è‡ªå·±åœ¨å“ªé‡Œï¼Œæ¯”å¦‚èŒä¸šå‘å±•ã€å·¥ä½œç»éªŒç­‰ã€‚\næˆ‘åº”è¯¥æ³¨æ„ç”¨è¯è¦æ­£å¼ï¼Œä¸è¦å¤ªæ­£å¼ï¼ŒåŒæ—¶è¦ä¿æŒç®€æ´æ˜äº†ã€‚è¿™æ ·ç”¨æˆ·å®¹æ˜“ç†è§£ï¼Œä¹Ÿæ–¹ä¾¿ä»–ä»¬æŸ¥é˜…ç›¸å…³èµ„æ–™ã€‚\næœ€åï¼Œæˆ‘åº”è¯¥æ€»ç»“ä¸€ä¸‹ï¼Œè®©ç”¨æˆ·çŸ¥é“æˆ‘æ˜¯å¦‚ä½•å¸®åŠ©ä»–ä»¬å®Œæˆä»–ä»¬çš„ä»»åŠ¡çš„ï¼Œè¿™æ ·ä»–ä»¬æœ‰æ›´å¤šå…³äºæˆ‘çš„ä¿¡æ¯ã€‚\n</think>\n<answer>\næˆ‘æ˜¯**â€œä½ çš„åå­—â€ï¼Œä½ å«ä»€ä¹ˆåå­—ï¼Ÿ\n</answer>\n\nğŸ‘¶: ä½ æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿ\nğŸ¤–ï¸: <think>\næ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚\n</think>\n<answer>\næ‚¨å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹MiniMind-R1ã€‚å¦‚æ‚¨æœ‰ä»»ä½•ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½æˆ‘æ‰€èƒ½ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚\n</answer>\n\n\nâ…£ æ¨¡å‹å‚æ•°è®¾å®š\nğŸ“‹å…³äºLLMçš„å‚æ•°é…ç½®ï¼Œæœ‰ä¸€ç¯‡å¾ˆæœ‰æ„æ€çš„è®ºæ–‡MobileLLMåšäº†è¯¦ç»†çš„ç ”ç©¶å’Œå®éªŒã€‚\nScaling Lawåœ¨å°æ¨¡å‹ä¸­æœ‰è‡ªå·±ç‹¬ç‰¹çš„è§„å¾‹ã€‚\nå¼•èµ·Transformerå‚æ•°æˆè§„æ¨¡å˜åŒ–çš„å‚æ•°å‡ ä¹åªå–å†³äºd_modelå’Œn_layersã€‚\n\nd_modelâ†‘ + n_layersâ†“ -> çŸ®èƒ–å­\nd_modelâ†“ + n_layersâ†‘ -> ç˜¦é«˜ä¸ª\n\n2020å¹´æå‡ºScaling Lawçš„è®ºæ–‡è®¤ä¸ºï¼Œè®­ç»ƒæ•°æ®é‡ã€å‚æ•°é‡ä»¥åŠè®­ç»ƒè¿­ä»£æ¬¡æ•°æ‰æ˜¯å†³å®šæ€§èƒ½çš„å…³é”®å› ç´ ï¼Œè€Œæ¨¡å‹æ¶æ„çš„å½±å“å‡ ä¹å¯ä»¥å¿½è§†ã€‚\nç„¶è€Œä¼¼ä¹è¿™ä¸ªå®šå¾‹å¯¹å°æ¨¡å‹å¹¶ä¸å®Œå…¨é€‚ç”¨ã€‚\nMobileLLMæå‡ºæ¶æ„çš„æ·±åº¦æ¯”å®½åº¦æ›´é‡è¦ï¼Œã€Œæ·±è€Œçª„ã€çš„ã€Œç˜¦é•¿ã€æ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°æ¯”ã€Œå®½è€Œæµ…ã€æ¨¡å‹æ›´å¤šçš„æŠ½è±¡æ¦‚å¿µã€‚\nä¾‹å¦‚å½“æ¨¡å‹å‚æ•°å›ºå®šåœ¨125Mæˆ–è€…350Mæ—¶ï¼Œ30ï½42å±‚çš„ã€Œç‹­é•¿ã€æ¨¡å‹æ˜æ˜¾æ¯”12å±‚å·¦å³çš„ã€ŒçŸ®èƒ–ã€æ¨¡å‹æœ‰æ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼Œ\nåœ¨å¸¸è¯†æ¨ç†ã€é—®ç­”ã€é˜…è¯»ç†è§£ç­‰8ä¸ªåŸºå‡†æµ‹è¯•ä¸Šéƒ½æœ‰ç±»ä¼¼çš„è¶‹åŠ¿ã€‚\nè¿™å…¶å®æ˜¯éå¸¸æœ‰è¶£çš„å‘ç°ï¼Œå› ä¸ºä»¥å¾€ä¸º100Må·¦å³é‡çº§çš„å°æ¨¡å‹è®¾è®¡æ¶æ„æ—¶ï¼Œå‡ ä¹æ²¡äººå°è¯•è¿‡å åŠ è¶…è¿‡12å±‚ã€‚\nè¿™ä¸MiniMindåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹å‚æ•°é‡åœ¨d_modelå’Œn_layersä¹‹é—´è¿›è¡Œè°ƒæ•´å®éªŒè§‚å¯Ÿåˆ°çš„æ•ˆæœæ˜¯ä¸€è‡´çš„ã€‚\nç„¶è€Œã€Œæ·±è€Œçª„ã€çš„ã€Œçª„ã€ä¹Ÿæ˜¯æœ‰ç»´åº¦æé™çš„ï¼Œå½“d_model<512æ—¶ï¼Œè¯åµŒå…¥ç»´åº¦åå¡Œçš„åŠ£åŠ¿éå¸¸æ˜æ˜¾ï¼Œ\nå¢åŠ çš„layerså¹¶ä¸èƒ½å¼¥è¡¥è¯åµŒå…¥åœ¨å›ºå®šq_headå¸¦æ¥d_headä¸è¶³çš„åŠ£åŠ¿ã€‚\nå½“d_model>1536æ—¶ï¼Œlayersçš„å¢åŠ ä¼¼ä¹æ¯”d_modelçš„ä¼˜å…ˆçº§æ›´é«˜ï¼Œæ›´èƒ½å¸¦æ¥å…·æœ‰â€œæ€§ä»·æ¯”â€çš„å‚æ•°->æ•ˆæœå¢ç›Šã€‚\n\nå› æ­¤MiniMindè®¾å®šsmallæ¨¡å‹dim=512ï¼Œn_layers=8æ¥è·å–çš„ã€Œæå°ä½“ç§¯<->æ›´å¥½æ•ˆæœã€çš„å¹³è¡¡ã€‚\nè®¾å®šdim=768ï¼Œn_layers=16æ¥è·å–æ•ˆæœçš„æ›´å¤§æ”¶ç›Šï¼Œæ›´åŠ ç¬¦åˆå°æ¨¡å‹Scaling-Lawçš„å˜åŒ–æ›²çº¿ã€‚\n\nä½œä¸ºå‚è€ƒï¼ŒGPT3çš„å‚æ•°è®¾å®šè§ä¸‹è¡¨ï¼š\n\n\nâ…¤ è®­ç»ƒç»“æœ\nMiniMind2 æ¨¡å‹è®­ç»ƒæŸå¤±èµ°åŠ¿ï¼ˆç”±äºæ•°æ®é›†åœ¨è®­ç»ƒååˆæ›´æ–°æ¸…æ´—å¤šæ¬¡ï¼Œå› æ­¤Lossä»…ä¾›å‚è€ƒï¼‰\n\n\n\nmodels\npretrain (length-512)\nsft (length-512)\n\n\n\n\nMiniMind2-Small\n\n\n\n\nMiniMind2\n\n\n\n\n\nè®­ç»ƒå®Œæˆ-æ¨¡å‹åˆé›†\n\nè€ƒè™‘åˆ°å¤šäººååº”ç™¾åº¦ç½‘ç›˜é€Ÿåº¦æ…¢ï¼ŒMiniMind2åŠä»¥åå…¨éƒ¨ä½¿ç”¨ModelScope/HuggingFaceæ‰˜ç®¡ã€‚\n\nâ‘  PyTorchåŸç”Ÿæ¨¡å‹\nMiniMind2æ¨¡å‹æƒé‡ (ModelScope | HuggingFace)\nMiniMind-V1æ¨¡å‹æƒé‡ (ç™¾åº¦ç½‘ç›˜)\n\nTorchæ–‡ä»¶å‘½åå¯¹ç…§\n\n\n\nModel Name\nparams\npretrain_model\nsft_model\nrl_model\nreason_model\nlora_model\n\n\n\n\nMiniMind2-small\n26M\npretrain_512.pth\nfull_sft_512.pth\nrlhf_512.pth\nreason_512.pth\nlora_xxx_512.pth\n\n\nMiniMind2-MoE\n145M\npretrain_640_moe.pth\nfull_sft_640_moe.pth\nrlhf_640_moe.pth\n-\n-\n\n\nMiniMind2\n104M\npretrain_768.pth\nfull_sft_768.pth\nrlhf_768.pth\nreason_768.pth\nlora_xxx_768.pth\n\n\n\n\n\n\nModel Name\nparams\npretrain_model\nå•è½®å¯¹è¯sft\nå¤šè½®å¯¹è¯sft\nrl_model\n\n\n\n\nminimind-v1-small\n26M\npretrain_512.pth\nsingle_chat/full_sft_512.pth\nmulti_chat/full_sft_512.pth\nrl_512.pth\n\n\nminimind-v1-moe\n4Ã—26M\npretrain_512_moe.pth\nsingle_chat/full_sft_512_moe.pth\nmulti_chat/full_sft_512_moe.pth\n-\n\n\nminimind-v1\n108M\npretrain_768.pth\nsingle_chat/full_sft_768.pth\nmulti_chat/full_sft_768.pth\nrl_768.pth\n\n\n\n\nâ‘¡ Transformersæ¨¡å‹\nMiniMindç³»åˆ— (ModelScope\n| HuggingFace)\n\nğŸ“Œ Eval\nâ…  RLHFå¯¹æ¯”SFTç¯‡\næµ‹è¯•åŸºäºfull_sftå’Œrlhfçš„MiniMind2ç³»åˆ—æ¨¡å‹å¯¹æ¯”ï¼Œæµ‹è¯•éšæœºç§å­å‡å›ºå®š\n\né—®ç­”å®æµ‹\n[A0] MiniMind2ï¼šfull_sft_640\n[A1] MiniMind2ï¼šrlhf_640\n[Q]: ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ\n[A0]: æˆ‘æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥å›ç­”å„ç§é—®é¢˜ï¼Œæä¾›ä¿¡æ¯å’Œå¸®åŠ©ã€‚æˆ‘å¯ä»¥å›ç­”å„ç§é—®é¢˜ï¼Œæä¾›ä¿¡æ¯å’Œå¸®åŠ©ï¼Œå¸®åŠ©ä½ è§£å†³å„ç§é—®é¢˜ã€‚\n[A1]: æˆ‘æ˜¯ä¸€ç§åŸºäºæ–‡æœ¬çš„AIæ¨¡å‹ï¼Œæˆ‘å¹¶æ²¡æœ‰ä¸ªäººç»å†æˆ–æƒ…æ„Ÿï¼Œæ‰€ä»¥æ— æ³•æ„Ÿå—å’Œä½“éªŒæƒ…æ„Ÿã€‚æˆ‘çš„è®¾è®¡ç›®çš„æ˜¯ä¸ºäº†å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€æä¾›ä¿¡æ¯å’Œè¿›è¡Œå¯¹è¯ã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼\n\n[Q]: ä½ æ›´æ“…é•¿å“ªä¸€ä¸ªå­¦ç§‘ï¼Ÿ\n[A0]: ä½œä¸ºä¸€ä¸ªAIæ¨¡å‹ï¼Œæˆ‘å¹¶æ²¡æœ‰çœŸæ­£çš„â€œæ“…é•¿â€è¿™ä¸ªå­¦ç§‘ã€‚æˆ‘è¢«è®¾è®¡æˆèƒ½å¤Ÿæä¾›ä¿¡æ¯ã€è§£ç­”é—®é¢˜ã€è¿›è¡Œå¯¹è¯ã€æ‰§è¡Œä»»åŠ¡å’Œä¸ç”¨æˆ·è¿›è¡Œå¯¹è¯ã€‚ä¸è¿‡ï¼Œæˆ‘å¯ä»¥æä¾›ä¿¡æ¯ã€è§£ç­”é—®é¢˜ã€è¿›è¡Œå¯¹è¯ã€æä¾›å»ºè®®ã€å¤„ç†é—®é¢˜ã€è¿›è¡Œå¯¹è¯ã€æä¾›å»ºè®®ã€å­¦ä¹ æ–°çŸ¥è¯†ã€ç¼–å†™ä»£ç ã€å›ç­”é—®é¢˜ã€æä¾›å»ºè®®ç­‰å¤šç§å­¦ç§‘çš„åŠŸèƒ½ã€‚å¦‚æœä½ æœ‰å…·ä½“çš„å­¦ç§‘éœ€æ±‚æˆ–ä¸»é¢˜ï¼Œæ¬¢è¿æä¾›è¯¦ç»†ä¿¡æ¯ã€‚\n[A1]: ä½œä¸ºAIï¼Œæˆ‘å¹¶æ²¡æœ‰ä¸ªäººèƒ½åŠ›æˆ–å…´è¶£ï¼Œä½†æˆ‘å¯ä»¥æä¾›ä¸€äº›å…³äºæ•°å­¦ã€ç§‘å­¦ã€è®¡ç®—æœºç§‘å­¦ã€è¯­è¨€å­¦ã€å¿ƒç†å­¦ç­‰å­¦ç§‘çš„çŸ¥è¯†ã€‚å¦‚æœä½ å¯¹æ•°å­¦æ„Ÿå…´è¶£ï¼Œæˆ‘å¯ä»¥æä¾›ä¸€äº›åŸºç¡€çŸ¥è¯†ï¼Œä¾‹å¦‚ä»£æ•°ã€å‡ ä½•ã€æ¦‚ç‡ã€ç»Ÿè®¡å­¦ç­‰ã€‚å¦‚æœä½ éœ€è¦æ›´æ·±å…¥çš„å­¦ä¹ ï¼Œæˆ‘ä¹Ÿå¯ä»¥æä¾›ç›¸å…³çš„åœ¨çº¿è¯¾ç¨‹ã€ä¹¦ç±ã€è®ºæ–‡ç­‰èµ„æºã€‚è¯·å‘Šè¯‰æˆ‘ä½ å…·ä½“éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Œæˆ‘ä¼šå°½åŠ›æä¾›å¸®åŠ©ã€‚\n\n[Q]: é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯å¦‚ä½•æ‰¹åˆ¤å°å»ºç¤¼æ•™çš„ï¼Ÿ\n[A0]: é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯ä¸€éƒ¨è®²è¿°äº†é²è¿…å¯¹äººç±»ä»·å€¼å’Œé“å¾·è´£ä»»çš„å€¡å¯¼ã€‚åœ¨è¿™éƒ¨ä½œå“ä¸­ï¼Œé²è¿…é€šè¿‡ç»†è…»çš„ç¬”è§¦ï¼Œæ¢è®¨äº†äººæ€§ã€é“å¾·ã€æ­£ä¹‰ã€ç‰ºç‰²ä¸è´£ä»»ç­‰æ·±åˆ»çš„ä¸»é¢˜ã€‚ä»¥ä¸‹æ˜¯é²è¿…åœ¨ã€Šç‹‚äººæ—¥è®°ã€‹ä¸­å¦‚ä½•æ‰¹åˆ¤å°å»ºç¤¼æ•™çš„å‡ ä¸ªæ–¹é¢ï¼š1. **ç¤¾ä¼šç°å®ä¸é“å¾·è§‚å¿µ**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ¢è®¨äº†ç¤¾ä¼šçš„ä¸å¹³ç­‰ã€æƒåŠ›çš„æµåŠ¨ã€äººæ€§çš„æ¼”å˜ç­‰ç¤¾ä¼šé—®é¢˜ã€‚ä»–è®¤ä¸ºï¼Œç¤¾ä¼šä¸å¹³ç­‰ä¸ä»…ä»…æ˜¯ä¸å…¬æ­£çš„ï¼Œæ›´æ˜¯æ¯ä¸ªäººåœ¨ç¤¾ä¼šä¸­çš„ä¸å…¬æ­£ã€‚ä»–å‘¼åç¤¾ä¼šå„ç•Œå…±åŒåŠªåŠ›ï¼Œé€šè¿‡æ•™è‚²ã€å®£ä¼ ã€æ³•å¾‹ç­‰æ‰‹æ®µï¼Œä¸ºæ„å»ºå’Œè°ç¤¾ä¼šåšå‡ºè´¡çŒ®ã€‚2. **é“å¾·ä¸è´£ä»»**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œå±•ç°äº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚ä»–æå€¡é€šè¿‡é“å¾·æ•™è‚²æ¥åŸ¹å…»äººä»¬çš„é“å¾·å“è´¨ï¼ŒåŒæ—¶ä¹Ÿå¼ºè°ƒäº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚é²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†ç¤¾ä¼šçš„ä¸å¹³ç­‰å’Œäººæ€§çš„å¤æ‚æ€§ï¼Œä½“ç°äº†å¯¹äººæ€§çš„æ·±åˆ»ç†è§£ã€‚3. **é“å¾·ä¸è´£ä»»**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œå¼ºè°ƒäº†é“å¾·è´£ä»»çš„é‡è¦æ€§ã€‚ä»–æå€¡é€šè¿‡è‡ªå·±çš„è¡Œä¸ºæ¥ä½“ç°å¯¹ç¤¾ä¼šçš„å°Šé‡å’Œå¯¹äººæ€§çš„æ·±åˆ»ç†è§£ã€‚é²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œå¼ºè°ƒäº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚4. **é“å¾·ä¸é“å¾·**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†é“å¾·å’Œè´£ä»»çš„çœŸæ­£æ„ä¹‰ã€‚é²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†é“å¾·å’Œè´£ä»»çš„æœ¬è´¨ï¼Œå¼ºè°ƒäº†é“å¾·å’Œè´£ä»»çš„é‡è¦æ€§ã€‚5. **ä¸ªäººä¸ç¤¾ä¼š**ï¼šé²è¿…é€šè¿‡è®²è¿°é²è¿…çš„æ•…äº‹ï¼Œæ­ç¤ºäº†ä¸ªäººä¸ç¤¾ä¼šä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚ä»–å‘¼åç¤¾ä¼šå„ç•Œå…±åŒåŠªåŠ›ï¼Œé€šè¿‡æ•™è‚²å’Œå®£ä¼ ï¼Œä¸ºæ„å»ºå’Œè°ç¤¾ä¼šåšå‡ºè´¡çŒ®ã€‚é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹é€šè¿‡å…¶ä¸°å¯Œçš„æ•…äº‹å’Œæ·±åˆ»çš„é“å¾·å¯“è¨€ï¼Œä¼ è¾¾äº†å…³äºäººæ€§ã€é“å¾·ã€æ­£ä¹‰ã€é“å¾·ä»¥åŠä¸ªäººä¸ç¤¾ä¼šçš„å¤æ‚å…³ç³»ã€‚è¿™éƒ¨ä½œå“ä¸ä»…åœ¨æ–‡å­¦ä»·å€¼ä¸Šå–å¾—äº†å·¨å¤§æˆå°±ï¼Œæ›´åœ¨æ€æƒ³å±‚é¢ä¸Šå¯å‘äº†åæ¥çš„æ–‡å­¦åˆ›ä½œï¼Œå¯¹åä¸–äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚\n[A1]: é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹æ˜¯ä¸€éƒ¨æç»˜æˆ˜äº‰å’Œè‡ªç”±ç²¾ç¥çš„ä½œå“ï¼Œå®ƒæ‰¹åˆ¤äº†å°å»ºç¤¾ä¼šçš„ç§ç§é—®é¢˜å’Œå†²çªï¼Œåæ˜ äº†ç¤¾ä¼šçš„ä¸å¹³ç­‰å’Œäººæ€§æœ¬è´¨ã€‚åœ¨è¿™éƒ¨ä½œå“ä¸­ï¼Œé²è¿…é€šè¿‡å¯¹å°å»ºç¤¾ä¼šçš„è¯¸å¤šç°è±¡è¿›è¡Œæ‰¹åˆ¤ï¼Œå¦‚â€œå¼—é›·å¾·é‡Œå…‹Â·çº¦ç¿°é€Šçš„â€œé¹°è¿ªä¼¦â€ã€â€œçº³æ‰ç‰¹çš„â€ã€â€œè´å…‹æ±‰å§†â€ã€â€œä¹”æ²»Â·å¨å°”é€Šâ€ç­‰ï¼Œå¯¹å°å»ºç¤¾ä¼šçš„ç§ç§é—®é¢˜è¿›è¡Œäº†æ‰¹åˆ¤ï¼Œå¼ºè°ƒäº†å°å»ºç¤¾ä¼šçš„ä¸å¹³ç­‰ã€äººæ€§æœ¬è´¨ä»¥åŠäººæ€§æœ¬è´¨ã€‚é²è¿…é€šè¿‡ä»–çš„â€œé¹°è¿ªä¼¦â€ã€â€œçº³æ‰ç‰¹çš„â€ã€â€œè´å…‹æ±‰å§†â€ã€â€œä¹”æ²»Â·å¨å°”é€Šâ€ç­‰ï¼Œå¯¹å°å»ºç¤¾ä¼šçš„ç§ç§é—®é¢˜è¿›è¡Œäº†æ‰¹åˆ¤ã€‚åœ¨å°è¯´ä¸­ï¼Œé²è¿…é€šè¿‡å¯¹å°å»ºç¤¾ä¼šçš„è¯¸å¤šç°è±¡è¿›è¡Œæ‰¹åˆ¤ï¼Œæ­ç¤ºäº†å°å»ºç¤¾ä¼šçš„è…è´¥ã€äººæ€§æœ¬è´¨ä»¥åŠäººæ€§æœ¬è´¨çš„å¤æ‚æ€§ã€‚è¿™ç§æ‰¹åˆ¤ä½“ç°äº†å¯¹å°å»ºç¤¾ä¼šçš„å°Šé‡å’Œå¯¹äººæ€§çš„å¤æ‚æ€§ï¼ŒåŒæ—¶ä¹Ÿåæ˜ äº†ç°ä»£ç¤¾ä¼šä¸­æ™®éå­˜åœ¨çš„ä¸å¹³ç­‰å’Œäººæ€§æœ¬è´¨ã€‚é²è¿…çš„ã€Šç‹‚äººæ—¥è®°ã€‹ä¸ä»…æ˜¯ä¸€éƒ¨å…³äºå°å»ºç¤¾ä¼šçš„å°è¯´ï¼Œä¹Ÿæ˜¯ä¸€éƒ¨å…·æœ‰æ·±åˆ»ç¤¾ä¼šæ„ä¹‰çš„ä½œå“ï¼Œå¯¹åä¸–çš„å®¡åˆ¤å’Œæ‰¹åˆ¤èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚\n\n[Q]: æˆ‘å’³å—½å·²ç»æŒç»­äº†ä¸¤å‘¨ï¼Œéœ€è¦å»åŒ»é™¢æ£€æŸ¥å—ï¼Ÿ\n[A0]: å’³å—½ç¡®å®éœ€è¦ä¸€å®šçš„æ£€æŸ¥ï¼Œä½†å¦‚æœæ‚¨çš„å’³å—½æŒç»­æ—¶é—´è¿‡é•¿ï¼Œæˆ–è€…æœ‰å…¶ä»–ä¸é€‚ç—‡çŠ¶ï¼ˆå¦‚æŒç»­å’³å—½ã€å‘¼å¸å›°éš¾ç­‰ï¼‰ï¼Œå»ºè®®å°½å¿«å°±åŒ»ã€‚åŒ»ç”Ÿä¼šæ ¹æ®æ‚¨çš„ç—‡çŠ¶ã€ä½“æ£€ç»“æœå’Œå¯èƒ½çš„å½±åƒå­¦æ£€æŸ¥ï¼ˆå¦‚Xå…‰ã€MRIæˆ–CTæ‰«æï¼‰æ¥è¯Šæ–­æ‚¨çš„ç—‡çŠ¶ã€‚åœ¨ç­‰å¾…å°±åŒ»æœŸé—´ï¼Œæ‚¨å¯ä»¥å°è¯•ä»¥ä¸‹æ–¹æ³•æ¥å¸®åŠ©ç¼“è§£ç—‡çŠ¶ï¼š1. **ä¼‘æ¯**ï¼šç¡®ä¿æ‚¨æœ‰è¶³å¤Ÿçš„ç¡çœ ã€‚2. **ä¿æŒæ°´åˆ†**ï¼šè„±æ°´å¯èƒ½ä¼šåŠ é‡å’³å—½ã€‚3. **çƒ­æ•·**ï¼šä½¿ç”¨çƒ­æ•·è¢‹æˆ–çƒ­æ¯›å·¾æ•·åœ¨ç–¼ç—›çš„éƒ¨ä½ï¼Œæœ‰åŠ©äºç¼“è§£å–‰å’™ç—›ã€‚4. **é¿å…åˆºæ¿€**ï¼šé¿å…ä½¿ç”¨å¯èƒ½åˆºæ¿€å–‰å’™çš„åŒ–å­¦ç‰©è´¨ï¼Œå¦‚æŸäº›åŒ–å­¦ç‰©è´¨ã€‚5. **ä¿æŒå®¤å†…æ¹¿æ¶¦**ï¼šç¡®ä¿æ‚¨çš„å§å®¤æœ‰è‰¯å¥½çš„é€šé£ï¼Œå¯ä»¥ä½¿ç”¨åŠ æ¹¿å™¨å¸®åŠ©ä¿æŒç©ºæ°”æ¹¿åº¦ã€‚6. **ä¿æŒå®¤å†…æ¹¿åº¦**ï¼šä½¿ç”¨åŠ æ¹¿å™¨å¯ä»¥å¸®åŠ©ç¼“è§£å–‰å’™å¹²ç‡¥å’Œå’³å—½ã€‚å¦‚æœç—‡çŠ¶æŒç»­ä¸ç¼“è§£æˆ–æœ‰å…¶ä»–ä¸é€‚ç—‡çŠ¶ï¼Œè¯·ç«‹å³å°±åŒ»ã€‚å¸Œæœ›æ‚¨æ—©æ—¥åº·å¤ï¼\n[A1]: å¦‚æœæ‚¨çš„å’³å—½æŒç»­äº†ä¸¤å‘¨ï¼Œé€šå¸¸å»ºè®®æ‚¨å°½å¿«å°±åŒ»ï¼Œå› ä¸ºè¿™å¯èƒ½ä¼šå½±å“æ‚¨çš„å‘¼å¸å’Œå¿ƒè·³ã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ­¥éª¤æ¥æ£€æŸ¥å’³å—½ï¼š1. **ä¼‘æ¯**ï¼šç”¨çº¸å·¾æˆ–è‚˜éƒ¨è½»è½»æŒ‰å‹å’³å—½çš„ä½ç½®ã€‚2. **ä½¿ç”¨è¯ç‰©**ï¼šåœ¨å¯èƒ½çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨è¯ç‰©ï¼ˆå¦‚æŠ—è¿‡æ•è¯ã€æŠ—è¿‡æ•è¯ç­‰ï¼‰æ¥ç¼“è§£å’³å—½ã€‚è¯·åœ¨åŒ»ç”Ÿçš„æŒ‡å¯¼ä¸‹ä½¿ç”¨è¯ç‰©ã€‚3. **çƒ­æ•·**ï¼šåœ¨å’³å—½æœŸé—´ï¼Œå¯ä»¥ä½¿ç”¨çƒ­æ•·æ¥ç¼“è§£ç–¼ç—›å’Œè‚¿èƒ€ã€‚4. **è¯ç‰©æ²»ç–—**ï¼šå¦‚æœå’³å—½æŒç»­äº†ä¸¤å‘¨ï¼Œå¯ä»¥ä½¿ç”¨ä¸€äº›æ¶ˆç‚è¯æˆ–æŠ—è¿‡æ•è¯æ¥ç¼“è§£ç—‡çŠ¶ã€‚è¯·åŠ¡å¿…åœ¨åŒ»ç”Ÿçš„æŒ‡å¯¼ä¸‹ä½¿ç”¨ã€‚5. **ä¿æŒå¥åº·çš„ç”Ÿæ´»æ–¹å¼**ï¼šä¿æŒå……è¶³çš„ç¡çœ ã€å‡è¡¡çš„é¥®é£Ÿã€é€‚é‡çš„è¿åŠ¨å’Œé¿å…å¸çƒŸå’Œé™é…’ï¼Œè¿™äº›éƒ½æœ‰åŠ©äºæé«˜å’³å—½çš„å‡ ç‡ã€‚è¯·è®°ä½ï¼Œè¿™äº›å»ºè®®ä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—æ„è§ã€‚å¦‚æœæ‚¨çš„ç—‡çŠ¶æŒç»­æˆ–åŠ é‡ï¼Œå¼ºçƒˆå»ºè®®æ‚¨å°½å¿«å°±åŒ»ã€‚\n\n\nğŸ‘‰æ•ˆæœæ€»ç»“\nfull_sftæ¨¡å‹åœ¨ç®€æ´æ€§å’Œä¿¡æ¯å‡†ç¡®æ€§æ–¹é¢è¡¨ç°æ›´å¥½ï¼›rlhfæ¨¡å‹åœ¨å›ç­”ä¸­å€¾å‘äºæä¾›æ›´å¤šçš„èƒŒæ™¯ä¿¡æ¯ï¼Œä½†ä¿¡æ¯å‡†ç¡®æ€§æœ‰å¾…æ”¹è¿›ã€‚\næ€»çš„æ¥è¯´RLHFåçš„æ¨¡å‹å€¾å‘äºå­¦ä¹ ï¼šè¯´æ›´å¤šæœ‰ç¤¼è²Œä½†æ— ç”¨çš„åºŸè¯è®¨å¥½â€œå¯¹è¯â€æœ¬èº«ï¼Œè€Œå¯¹ä¿¡æ¯å‡†ç¡®æ€§åˆ™æœ‰è½»å¾®æŸå¤±ã€‚\nå¤©ä¸‹æ²¡æœ‰å…è´¹çš„åˆé¤ï¼Œè¿˜éœ€è¦ç»§ç»­æå‡RLHFæ•°æ®é›†çš„è´¨é‡ï¼Œä¹Ÿè¦æ¥å—æ¨¡å‹èƒ½åŠ›æ— æ³•é¿å…çš„æŸå¤±(ç¨‹åº¦æœ‰è½»é‡)ã€‚\nDPOå’Œåœ¨çº¿PPOçš„åŒºåˆ«åœ¨äºrejectå’Œchosenéƒ½æ˜¯ç¦»çº¿å‡†å¤‡çš„ï¼Œå’Œminimindæ¨¡å‹æœ¬èº«çš„è¾“å‡ºå¿…ç„¶å­˜åœ¨å¾ˆå¤§çš„åˆ†å¸ƒå·®å¼‚ã€‚\né€šä¿—åœ°è¯´DPOç®—æ³•ä½¿æ¨¡å‹è§‚çœ‹ä¹’ä¹“çƒä¸–ç•Œå† å†›çš„æ‰“æ³•ã€Œå½•åƒã€è¿›è¡ŒRLï¼Œè€Œä¸æ˜¯åƒPPOä¸€æ ·è¯·rewardæ¨¡å‹åšã€Œæ•™ç»ƒã€çº æ­£è‡ªå·±çš„æ‰“æ³•è¿›è¡ŒRLã€‚\nâ…¡ ä¸»è§‚æ ·ä¾‹æµ‹è¯„\nğŸƒä»¥ä¸‹æµ‹è¯•äº2025-02-09å®Œæˆï¼Œæ­¤æ—¥æœŸåå‘å¸ƒçš„æ–°æ¨¡å‹ï¼Œæ— ç‰¹æ®Šéœ€è¦æ—¶å°†ä¸åŠ å…¥æµ‹è¯•ã€‚\n[A] MiniMind2 (0.1B)\n[B] MiniMind2-MoE (0.15B)\n[C] MiniMind2-Small (0.02B)\n[D] minimind-v1-small(0.02B)\n[E] minimind-v1-moe(0.1B)\n[F] minimind-v1(0.1B)\n[G] baby-llama2-chinese(0.2B)\n[H] chatlm-mini-chinese(0.2B)\n[Q]: ä½ çŸ¥é“é•¿æ±Ÿå—ï¼Ÿ\n[A]: é•¿æ±Ÿï¼Œä½äºä¸­å›½ä¸œå—éƒ¨ï¼Œæ˜¯ä¸­å›½çš„ç¬¬ä¸€é•¿æ²³ï¼Œå…¨é•¿6300å¤šå…¬é‡Œï¼Œæµç»11ä¸ªçœä»½ï¼Œæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œä¹Ÿæ˜¯ä¸­å›½çš„â€œæ¯äº²æ²³â€ã€‚é•¿æ±Ÿçš„å†å²å¯ä»¥è¿½æº¯åˆ°å…¬å…ƒå‰2000å¤šå¹´çš„å•†æœæ—¶æœŸï¼Œå½“æ—¶çš„å•†æœæ˜¯å•†æœçš„åè£”ã€‚å•†æœæ—¶æœŸï¼Œé•¿æ±Ÿçš„ç»æµå‘å±•è¾¾åˆ°äº†é«˜å³°ï¼Œæ˜¯ä¸­å›½æœ€é‡è¦çš„å†œä¸šå’Œå·¥ä¸šä¸­å¿ƒä¹‹ä¸€ã€‚é•¿æ±ŸæµåŸŸçš„ç»æµä¸»è¦ä»¥å†œä¸šä¸ºä¸»ï¼Œé•¿æ±Ÿæ¸”ä¸šå æ®äº†ä¸»è¦äº§ä¸šï¼Œå¦‚é’“é±¼ã€çŒé±¼ç­‰ã€‚é•¿æ±Ÿçš„æ°´èµ„æºä¹Ÿéå¸¸ä¸°å¯Œï¼ŒåŒ…æ‹¬æ²³æµã€æ¹–æ³Šã€æ²³æµç­‰ã€‚é•¿æ±Ÿçš„è‡ªç„¶æ™¯è§‚ä¹Ÿååˆ†å£®è§‚ï¼Œé•¿æ±Ÿå››å­£æ™¯è‰²å„å¼‚ï¼Œæ˜¥å­£å¤šé›¨ï¼Œå¤å­£å¤šé›¨ï¼Œç§‹å­£åˆ™å¤šé›¨ï¼Œå†¬å­£åˆ™å¯’å†·å¤šé›ªï¼Œæ˜¥å­£å’Œç§‹å­£éƒ½æœ‰ç¾ä¸½çš„èŠ±æœµå’Œæœå®ã€‚é•¿æ±Ÿæ˜¯ä¸­å›½çš„ç»æµä¸­å¿ƒï¼Œæ‹¥æœ‰ä¼—å¤šçš„å›½å®¶å’ŒåŸå¸‚ï¼Œæ˜¯ä¸–ç•Œä¸Šé‡è¦çš„äº¤é€šæ¢çº½å’Œèˆªè¿ä¸­å¿ƒã€‚åŒæ—¶ï¼Œé•¿æ±Ÿè¿˜æ˜¯ä¸­å›½çš„é‡è¦æ°´åˆ©èµ„æºï¼Œå¯¹äºä¸­å›½çš„ç»æµå‘å±•å…·æœ‰é‡è¦æ„ä¹‰ã€‚\n[B]: æ˜¯çš„ï¼Œæˆ‘çŸ¥é“é•¿æ±Ÿã€‚é•¿æ±Ÿä½äºä¸­å›½çš„ä¸­éƒ¨ï¼Œæ˜¯ä¸­å›½ç¬¬ä¸‰é•¿çš„æ²³æµï¼Œå…¨é•¿çº¦6300å…¬é‡Œï¼Œæµç»æ±Ÿè¥¿çœã€å®‰å¾½çœã€æ±Ÿè‹çœã€å®‰å¾½çœã€æ±Ÿè‹çœå’Œå®‰å¾½çœã€‚\n[C]: å½“ç„¶ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œå…¨é•¿çº¦6300å…¬é‡Œã€‚å®ƒä»¥å…¶ä¸°å¯Œçš„æ°´èµ„æºã€ä¸°å¯Œçš„æ°´ç”ŸåŠ¨æ¤ç‰©èµ„æºä»¥åŠç‹¬ç‰¹çš„åœ°ç†ä½ç½®è€Œé—»åäºä¸–ã€‚\n[D]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œå…¨é•¿è¶…è¿‡3300åƒç±³ã€‚\n[E]: é•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œæ€»é•¿åº¦çº¦ä¸º6300å…¬é‡Œã€‚å®ƒå‘æºäºé’è—é«˜åŸçš„é’æµ·æ¹–ï¼Œæµç»é’æµ·ã€å››å·ã€ç”˜è‚ƒã€å®å¤ã€å†…è’™å¤ã€é™•è¥¿å’Œå±±è¥¿ã€‚é•¿æ±ŸæµåŸŸæ˜¯ä¸­å›½æœ€å¤§çš„å†œä¸šåŒºä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½çš„æ–‡åŒ–å’Œç»æµä¸­å¿ƒã€‚\n[F]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸–ç•Œç¬¬ä¸‰å¤§æ²³æµã€‚é•¿æ±Ÿå‘æºäºé’è—é«˜åŸï¼Œæµç»11ä¸ªçœä»½ï¼Œæœ€ç»ˆæ³¨å…¥ä¸œæµ·ã€‚é•¿æ±ŸæµåŸŸæ˜¯ä¸­å›½æœ€å¤§çš„æ²³æµæµåŸŸä¹‹ä¸€ï¼Œæ‹¥æœ‰ç€ä¸°å¯Œçš„è‡ªç„¶èµ„æºå’Œæ–‡åŒ–é—äº§ï¼Œå¦‚é•¿æ±Ÿå¤§æ¡¥ã€é•¿æ±Ÿæµ·æ´‹åšç‰©é¦†ã€é•¿æ±Ÿå¤åŸç­‰ã€‚\n[G]: åŒæ—¶ä¹ŸçŸ¥é“ï¼Œä¸­å›½æ˜¯ä¸–ç•Œä¸Šæœ€é•¿çš„åŸå¸‚ä¹‹ä¸€ï¼Œæ‹¥æœ‰è¶…è¿‡3400ä¸‡äººå£ã€‚\n[H]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€é•¿çš„æ²³æµä¹‹ä¸€ã€‚å®ƒå‘æºäºé’è—é«˜åŸï¼Œæµç»ä¹ä¸ªçœåŒºï¼Œæœ€ç»ˆæ³¨å…¥ä¸œæµ·ã€‚é•¿æ±ŸæµåŸŸçš„æ°”å€™æ¸©å’Œï¼Œå››å­£åˆ†æ˜ï¼Œæ˜¯ä¸­å›½é‡è¦çš„å†œä¸šå’Œå·¥ä¸šåŸºåœ°ã€‚é•¿æ±ŸæµåŸŸçš„æ°´äº§èµ„æºä¸°å¯Œï¼Œæ˜¯ä¸­å›½çš„é‡è¦æ¸”ä¸šèµ„æºä¹‹ä¸€ã€‚\n\n\n[Q]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ä»€ä¹ˆï¼Ÿ\n[A]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼ˆMount Everestï¼‰ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œå°¼æ³Šå°”å’Œä¸­å›½çš„è¾¹ç•Œä¸Šã€‚å®ƒçš„æµ·æ‹”é«˜åº¦æ˜¯8,848.86ç±³ï¼ˆ29,031.7è‹±å°ºï¼‰ï¼Œæ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±å³°ã€‚\n[B]: ç ç©†æœ—ç›å³°ï¼ˆMount Everestï¼‰æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œæµ·æ‹”é«˜åº¦è¾¾8,848ç±³ï¼ˆ29,029è‹±å°ºï¼‰ã€‚\n[C]: ç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œæµ·æ‹”8,848.86ç±³ï¼ˆ29,031.7è‹±å°ºï¼‰ã€‚å®ƒä½äºå°¼æ³Šå°”å’Œä¸­å›½çš„è¾¹ç•Œä¸Šï¼Œæ˜¯å–œé©¬æ‹‰é›…å±±è„‰çš„ä¸€éƒ¨åˆ†ã€‚\n[D]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä½äºå°¼æ³Šå°”å’Œä¸­å›½çš„è¾¹å¢ƒä¸Šï¼Œæµ·æ‹”8848ç±³ã€‚\n[E]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œæµ·æ‹”8,848ç±³ã€‚\n[F]: ç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œæµ·æ‹”8848ç±³ã€‚\n[G]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰ï¼Œæµ·æ‹”8,848.86ç±³ï¼ˆ29,031.69è‹±å°ºï¼‰ã€‚\n[H]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—ç›å³°ï¼Œä¹Ÿç§°ä¸ºè¨åŠ ç›å¡”ï¼Œä½äºå–œé©¬æ‹‰é›…å±±è„‰çš„å°¼æ³Šå°”å’Œä¸­å›½è¾¹å¢ƒä¹‹é—´ï¼Œæµ·æ‹”8,848.86ç±³ï¼ˆ29,031.69è‹±å°ºï¼‰ã€‚å®ƒæ˜¯ä¸–ç•Œä¸Šæœ€è‘—åçš„ç™»å±±ç›®æ ‡ä¹‹ä¸€ï¼Œå¸å¼•ç€æ¥è‡ªä¸–ç•Œå„åœ°çš„ç™»å±±è€…å‰æ¥æŒ‘æˆ˜ã€‚ç ç©†æœ—ç›å³°çš„åå­—æ¥è‡ªè—è¯­ï¼Œæ„æ€æ˜¯â€œå¥³ç¥çš„é¢å³°â€ï¼Œå®ƒæ˜¯ç”±ä¸¤ä¸ªä¸åŒçš„å±±å³°ç»„æˆçš„ï¼Œå…¶ä¸­ä¸€ä¸ªæ˜¯ä½äºå°¼æ³Šå°”çš„ç ç©†æœ—ç›å³°ï¼Œå¦ä¸€ä¸ªåˆ™ä½äºä¸­å›½ã€‚å®ƒçš„é«˜åº¦æ˜¯é€šè¿‡æµ‹é‡æµ·æ‹”é«˜åº¦æ¥ç¡®å®šçš„ï¼Œå› ä¸ºå®ƒæ˜¯é€šè¿‡æµ‹é‡åœ°çƒçš„å¹³å‡é«˜åº¦æ¥ç¡®å®šçš„ã€‚å°½ç®¡ç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•å…¶ä»–åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚åœ°çƒä¸Šçš„å…¶ä»–åœ°æ–¹ï¼Œå¦‚å—ç¾æ´²çš„å®‰ç¬¬æ–¯å±±è„‰ï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±è„‰ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±å³°ã€‚æ€»ä¹‹ï¼Œç ç©†æœ—ç›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚å®ƒæ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±è„‰ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚\n\n\n[Q]: ä¸‡æœ‰å¼•åŠ›æ˜¯è°æå‡ºçš„ï¼Ÿ\n[A]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±ç‰›é¡¿åœ¨17ä¸–çºªæå‡ºçš„ï¼Œå®ƒæ˜¯ç‰›é¡¿ä¸‰å¤§å®šå¾‹ä¹‹ä¸€ã€‚ç‰›é¡¿åœ¨17ä¸–çºªæå‡ºçš„å¼•åŠ›å®šå¾‹æ­ç¤ºäº†ä¸‡æœ‰å¼•åŠ›å®šå¾‹çš„æœ¬è´¨ï¼Œå¹¶ä¸”è§£é‡Šäº†è¡Œæ˜Ÿã€å«æ˜Ÿã€å½—æ˜Ÿç­‰å¤©ä½“ä¹‹é—´å¦‚ä½•ç›¸äº’ä½œç”¨ã€‚è¿™ä¸ªå®šå¾‹æ˜¯ç”±è‰¾è¨å…‹Â·ç‰›é¡¿åœ¨1687å¹´æå‡ºçš„ï¼Œä»–é€šè¿‡å¯¹ä¸‡æœ‰å¼•åŠ›å®šå¾‹çš„åˆ†æå’Œå®éªŒï¼ŒæˆåŠŸåœ°è§£é‡Šäº†å¤©ä½“ä¹‹é—´çš„å¼•åŠ›ä½œç”¨ï¼Œä»è€Œè§£é‡Šäº†åœ°çƒç»•å¤ªé˜³æ—‹è½¬çš„ç°è±¡ã€‚\n[B]: ä¸‡æœ‰å¼•åŠ›ï¼ˆHuman Policyï¼‰æ˜¯ç‰›é¡¿çš„ä¸‰å¤§åŠ›å­¦å®šå¾‹ï¼Œç”¨äºæè¿°ä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„ç›¸äº’ä½œç”¨åŠ›ã€‚å®ƒç”±ä¸‡æœ‰å¼•åŠ›å®šå¾‹å’Œç‰›é¡¿çš„ç¬¬ä¸€å®šå¾‹ï¼ˆæƒ¯æ€§å®šå¾‹ï¼‰æ„æˆã€‚ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±äºä¸¤ä¸ªç‰©ä½“ä¹‹é—´ç›¸äº’ä½œç”¨è€Œäº§ç”Ÿçš„ï¼Œå®ƒä»¬çš„è´¨é‡ã€è·ç¦»ã€é€Ÿåº¦å’Œæ–¹å‘ç­‰å› ç´ å†³å®šäº†å®ƒä»¬ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™ç§ç›¸äº’ä½œç”¨åŠ›æ˜¯ï¼šè´¨é‡çš„ä¹˜ç§¯ï¼šè´¨é‡çš„ä¹˜ç§¯æ˜¯ä¸‡æœ‰å¼•åŠ›å®šå¾‹å’Œç‰›é¡¿ç¬¬äºŒå®šå¾‹çš„ä¹˜ç§¯ã€‚è´¨é‡çš„ä¹˜ç§¯ï¼šè´¨é‡çš„ä¹˜ç§¯æ˜¯ç‰©ä½“ä¹‹é—´çš„ä¸€ç§ç‰©ç†è¿‡ç¨‹ï¼Œå®ƒæ˜¯ç‰©ä½“é—´ç›¸äº’ä½œç”¨çš„äº§ç‰©ï¼Œå¯¹äºå…¶ä»–ç‰©ä½“æ¥è¯´ï¼Œå…¶è´¨é‡å¯ä»¥è¡¨ç¤ºä¸ºä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„è´¨é‡ä¹‹å’Œï¼Œå³é‡åŠ›åŠ é€Ÿåº¦aã€‚\n[C]: ä¸‡æœ‰å¼•åŠ›æ˜¯ä¸€ä¸ªç”±ç‰›é¡¿åœ¨1687å¹´æå‡ºçš„ç‰©ç†å­¦æ¦‚å¿µï¼Œå®ƒæè¿°äº†ç‰©ä½“ä¹‹é—´å¼•åŠ›å¦‚ä½•ç›¸äº’ä½œç”¨çš„è§„å¾‹ã€‚\n[D]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±è‹±å›½ç‰©ç†å­¦å®¶ç‰›é¡¿æå‡ºçš„ã€‚ä»–è®¤ä¸ºï¼Œæ‰€æœ‰ç‰©ä½“éƒ½ä¼šäº§ç”Ÿå¼•åŠ›ï¼Œè¿™ä¸ªå¼•åŠ›æ˜¯ç”±ç‰©ä½“çš„è´¨é‡å’Œè·ç¦»å†³å®šçš„ã€‚è¿™ä¸ªç†è®ºæ­ç¤ºäº†è´¨é‡å’Œè·ç¦»ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶è¯æ˜äº†ä¸‡æœ‰å¼•åŠ›çš„æœ¬è´¨ã€‚\n[E]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±ç‰›é¡¿åœ¨1687å¹´æå‡ºçš„ã€‚å®ƒæ˜¯å®‡å®™ä¸­ä¸€ä¸ªåŸºæœ¬çš„ç‰©ç†ç°è±¡ï¼Œå®ƒæè¿°äº†ç‰©ä½“ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™ä¸ªåŠ›è¢«ç§°ä¸ºä¸‡æœ‰å¼•åŠ›ï¼Œå®ƒåœ¨æ‰€æœ‰ç‰©ä½“ä¹‹é—´éƒ½å­˜åœ¨ï¼Œè¿™ç§åŠ›ä¸ç‰©ä½“çš„è´¨é‡å’Œè·ç¦»æœ‰å…³ã€‚ä¸‡æœ‰å¼•åŠ›æ˜¯è‡ªç„¶ç•Œä¸­æœ€åŸºæœ¬çš„åŠ›é‡ä¹‹ä¸€ï¼Œå®ƒä¸ä»…å½±å“ç€ç‰©ä½“çš„è¿åŠ¨å’Œå˜åŒ–ï¼Œè¿˜å¯¹å®‡å®™çš„ç»“æ„å’Œæ¼”åŒ–äº§ç”Ÿç€é‡è¦çš„å½±å“ã€‚\n[F]: ä¸‡æœ‰å¼•åŠ›æ˜¯è‹±å›½ç‰©ç†å­¦å®¶è‰¾è¨å…‹Â·ç‰›é¡¿åœ¨17ä¸–çºªæå‡ºçš„ã€‚\n[G]: å¼•åŠ›æ˜¯å®‡å®™ä¸­ä¸€ç§åŠ›é‡ï¼Œå®ƒæ˜¯ç”±è´¨é‡æˆ–èƒ½é‡æ‰€ç»„æˆçš„ã€‚æ ¹æ®ç‰›é¡¿çš„ä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼Œä¸€ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›å¤§å°ä¸å®ƒçš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒçš„è´¨é‡æˆåæ¯”ã€‚å› æ­¤ï¼Œç‰›é¡¿çš„ä¸‡æœ‰å¼•åŠ›å®šå¾‹è¡¨æ˜ï¼Œä¸€ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›å¤§å°ä¸å®ƒçš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒçš„è´¨é‡æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹åœ¨ç‰©ç†å­¦ã€å¤©æ–‡å­¦å’Œç‰©ç†å­¦ä¸­éƒ½æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚\n[H]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±è‹±å›½ç‰©ç†å­¦å®¶è‰¾è¨å…‹Â·ç‰›é¡¿äº1687å¹´æå‡ºçš„ã€‚ä»–åœ¨1687å¹´å‘è¡¨äº†ä¸€ç¯‡è‘—åçš„è®ºæ–‡ï¼Œé¢˜ä¸ºã€Šè‡ªç„¶å“²å­¦çš„æ•°å­¦åŸç†ã€‹ï¼Œå…¶ä¸­æå‡ºäº†ä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼ŒæŒ‡å‡ºä»»ä½•ä¸¤ä¸ªç‰©ä½“ä¹‹é—´éƒ½å­˜åœ¨ç€ä¸€ç§å¼•åŠ›ï¼Œè¿™ç§å¼•åŠ›çš„å¤§å°ä¸å®ƒä»¬çš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒä»¬ä¹‹é—´çš„è·ç¦»çš„å¹³æ–¹æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹è¢«ç§°ä¸ºä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼Œå®ƒæè¿°äº†è´¨é‡å’Œè·ç¦»ä¹‹é—´çš„å…³ç³»ã€‚å®ƒè¡¨æ˜ï¼Œä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›ä¸å®ƒä»¬çš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸å®ƒä»¬ä¹‹é—´çš„è·ç¦»çš„å¹³æ–¹æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹å¯¹äºè§£é‡Šå®‡å®™ä¸­çš„è®¸å¤šç°è±¡å’Œç°è±¡ä¹‹é—´çš„ç›¸äº’ä½œç”¨éå¸¸é‡è¦ï¼Œä¾‹å¦‚è¡Œæ˜Ÿç»•å¤ªé˜³è¿åŠ¨ã€æ’æ˜Ÿä¹‹é—´çš„å¼•åŠ›é€é•œæ•ˆåº”ç­‰ç­‰ã€‚å®ƒä¹Ÿè¢«å¹¿æ³›åº”ç”¨äºå¤©æ–‡å­¦ã€ç‰©ç†å­¦å’Œå·¥ç¨‹å­¦ç­‰é¢†åŸŸï¼Œä¸ºæˆ‘ä»¬ç†è§£å®‡å®™çš„æœ¬è´¨å’Œæ¼”åŒ–æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚\n\n\n[Q]: ä½ çŸ¥é“å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ä»€ä¹ˆå—ï¼Ÿ\n[A]: å¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿï¼Œä½†ä¹Ÿä¼šåƒå…¶ä»–æ¤ç‰©ã€æ˜†è™«ã€å°å‹å“ºä¹³åŠ¨ç‰©å’Œé±¼ç±»ã€‚å®ƒä»¬çš„æ¶ˆåŒ–ç³»ç»Ÿä¸å…¶ä»–ç†Šç§‘åŠ¨ç‰©ç±»ä¼¼ï¼Œèƒ½å¤Ÿæ¶ˆåŒ–ç«¹å­ã€‚å¤§ç†ŠçŒ«çš„ç‰™é½¿é”‹åˆ©ï¼Œé€‚åˆå’€åš¼ç«¹å­ï¼Œå› æ­¤å®ƒä»¬ç»å¸¸è¢«ç§°ä¸ºâ€œç«¹é£ŸåŠ¨ç‰©â€ã€‚\n[B]: å¤§ç†ŠçŒ«æ˜¯ä»¥ç«¹å­ä¸ºé£Ÿçš„å“ºä¹³åŠ¨ç‰©ï¼Œå®ƒä»¬æ˜¯è‚‰é£ŸåŠ¨ç‰©ã€‚å®ƒä»¬ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ï¼Œç‰¹åˆ«æ˜¯ç«¹å­ä¸­å¯Œå«çº¤ç»´ç´ å’ŒçŸ¿ç‰©è´¨ï¼Œå¹¶ä¸”ä¸ä¼šç›´æ¥è¿›å…¥æ¶ˆåŒ–ç³»ç»Ÿã€‚å¤§ç†ŠçŒ«çš„è‚ é“ä¸»è¦ç”±ç«¹å­ç»„æˆï¼Œå®ƒä»¬éœ€è¦æ¶ˆåŒ–ç«¹å­ä¸­çš„çº¤ç»´ç´ å’Œå…¶ä»–çº¤ç»´ç´ æ¥æ”¯æŒå®ƒä»¬çš„æ­£å¸¸è¿›é£Ÿã€‚\n[C]: å¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿï¼Œä½†å®ƒä»¬ä¹Ÿåƒå…¶ä»–æ¤ç‰©ï¼ŒåŒ…æ‹¬æ ‘å¶ã€å«©èŠ½ã€æ˜†è™«ã€æ°´æœã€è”¬èœå’Œå°å‹å“ºä¹³åŠ¨ç‰©ç­‰ã€‚å¤§ç†ŠçŒ«æ˜¯ä¸­å›½ç‰¹æœ‰çš„ç‰©ç§ï¼Œå±äºç†Šç§‘ï¼Œä¸»è¦åˆ†å¸ƒåœ¨ä¸­å›½çš„å››å·ã€é™•è¥¿å’Œç”˜è‚ƒç­‰åœ°ã€‚\n[D]: å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ã€‚å®ƒä»¬é€šå¸¸åƒç«¹å­ï¼Œæ¯å¤©éœ€è¦åƒæ‰å¤§çº¦30å…¬æ–¤çš„ç«¹å­ã€‚\n[E]: æ˜¯çš„ï¼Œå¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿã€‚å®ƒä»¬æ¯å¤©éœ€è¦åƒæ‰å¤§é‡çš„ç«¹å­æ¥ç»´æŒç”Ÿå‘½ï¼Œæ¯å¤©éœ€è¦åƒæ‰40è‡³80å…¬æ–¤çš„ç«¹å­ã€‚æ­¤å¤–ï¼Œå®ƒä»¬ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–çš„æ¤ç‰©ï¼Œå¦‚è‰ã€æœå®ã€åšæœå’Œå°å‹å“ºä¹³åŠ¨ç‰©ã€‚\n[F]: å¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿï¼Œä¹Ÿä¼šå¶å°”é£Ÿç”¨å…¶ä»–çš„æ¤ç‰©å’ŒåŠ¨ç‰©ã€‚æ­¤å¤–ï¼Œå¤§ç†ŠçŒ«ä¹Ÿä¼šåƒä¸€äº›é‡æœã€å°åŠ¨ç‰©å’Œæ¤ç‰©ï¼Œä½†è¿™äº›éƒ½ä¸å±äºå®ƒä»¬çš„ä¸»è¦é£Ÿç‰©æ¥æºã€‚\n[G]: å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ã€‚\n[H]: å¤§ç†ŠçŒ«æ˜¯ä¸€ç§ä»¥ç«¹å­ä¸ºä¸»è¦é£Ÿç‰©çš„æ¤é£ŸåŠ¨ç‰©ï¼Œå®ƒä»¬çš„è‚ é“ç»“æ„é€‚åˆæ¶ˆåŒ–çº¤ç»´ç´ å«é‡é«˜çš„ç«¹å­ï¼Œä½†ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–æ¤ç‰©ï¼Œå¦‚è‰æœ¬æ¤ç‰©å’Œå°å‹å“ºä¹³åŠ¨ç‰©ã€‚å¤§ç†ŠçŒ«çš„è‚ é“ç»“æ„ä¹Ÿé€‚åº”äº†é«˜çº¤ç»´çš„ç«¹å­ï¼Œè¿™ä½¿å¾—å®ƒä»¬èƒ½å¤Ÿæ¶ˆåŒ–å¤§é‡çš„çº¤ç»´ç´ ï¼Œä»è€Œå¸®åŠ©å®ƒä»¬åœ¨é‡å¤–ç”Ÿå­˜ã€‚å¤§ç†ŠçŒ«çš„è‚ é“ä¸­è¿˜å«æœ‰ä¸€ç§å«åšâ€œçº¤ç»´ç´ é…¶â€çš„é…¶ç±»ç‰©è´¨ï¼Œè¿™ç§é…¶èƒ½å¤Ÿå¸®åŠ©å¤§ç†ŠçŒ«åˆ†è§£çº¤ç»´ç´ ï¼Œä»è€Œå¸®åŠ©å®ƒä»¬æ¶ˆåŒ–å¤§é‡çš„æ°´åˆ†å’Œè¥å…»ç‰©è´¨ã€‚æ­¤å¤–ï¼Œå¤§ç†ŠçŒ«çš„è‚ é“è¿˜å«æœ‰ä¸€ç§å«åšâ€œçº¤ç»´ç´ è›‹ç™½â€çš„è›‹ç™½è´¨ï¼Œè¿™ç§è›‹ç™½è´¨èƒ½å¤Ÿå¸®åŠ©å¤§ç†ŠçŒ«ç»´æŒä½“å†…çš„èƒ½é‡æ°´å¹³ï¼Œä»è€Œå¸®åŠ©å®ƒä»¬åœ¨é‡å¤–ç”Ÿå­˜ã€‚æ€»çš„æ¥è¯´ï¼Œå¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ï¼Œä½†å®ƒä»¬ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–æ¤ç‰©ï¼Œå¦‚è‰æœ¬æ¤ç‰©å’Œå°å‹å“ºä¹³åŠ¨ç‰©ã€‚\n\n\n[Q]: æµ·æ°´ä¸ºä»€ä¹ˆæ˜¯å’¸çš„ï¼Ÿ\n[A]: æµ·æ°´ä¹‹æ‰€ä»¥æ˜¯å’¸çš„ï¼Œä¸»è¦æ˜¯ç”±äºå…¶ä¸­çš„åŒ–å­¦æˆåˆ†ã€‚æµ·æ°´ä¸­å«æœ‰å¤§é‡çš„çŸ¿ç‰©è´¨å’Œç›åˆ†ï¼Œå…¶ä¸­ä¸»è¦æˆåˆ†æ˜¯ç¡«é…¸ç›ã€ç¢³é…¸ç›ã€é•ç¦»å­å’Œé’¾ç¦»å­ã€‚è¿™äº›ç‰©è´¨åœ¨é«˜æµ“åº¦ä¸‹ï¼Œä¼šæ²‰æ·€åœ¨æµ·æ°´ä¸­ï¼Œå½¢æˆæµ·æ°´ã€‚å…·ä½“æ¥è¯´ï¼Œæµ·æ°´ä¸­çš„çŸ¿ç‰©è´¨å’Œç›åˆ†ä¸»è¦æ¥è‡ªäºå²©çŸ³ã€åœŸå£¤ã€ç”Ÿç‰©å’Œäººç±»æ’æ³„ç‰©ç­‰ã€‚å²©çŸ³æ˜¯æµ·æ°´çš„ç»„æˆéƒ¨åˆ†ï¼Œä¸»è¦ç”±çŸ¿ç‰©è´¨ç»„æˆï¼Œå¦‚çŸ³è‹±ã€é•¿çŸ³ã€äº‘æ¯ç­‰ã€‚åœŸå£¤ä¸­å«æœ‰å¤§é‡çš„åŒ–å­¦ç‰©è´¨ï¼Œå¦‚æ°®ã€ç£·ã€é’¾ç­‰ï¼Œè¿™äº›ç‰©è´¨ä¼šæ¸—é€åˆ°åœŸå£¤ä¸­ï¼Œå½¢æˆåœŸå£¤ã€‚ç”Ÿç‰©ä½“å†…çš„ç›åˆ†ä¸»è¦æ¥æºäºæ¤ç‰©çš„å¶ç»¿ç´ ç­‰è‰²ç´ ï¼Œè¿™äº›è‰²ç´ ä¼šå¸æ”¶å¤ªé˜³å…‰ä¸­çš„èƒ½é‡ï¼Œè½¬åŒ–ä¸ºç”Ÿç‰©ä½“å¯ä»¥åˆ©ç”¨çš„èƒ½é‡ã€‚è€Œäººç±»æ’æ³„ç‰©ä¸­å«æœ‰çš„ç›åˆ†ä¸»è¦æ¥æºäºçŸ¿ç‰©è´¨å’Œç¢³é…¸ç›ï¼Œè¿™äº›çŸ¿ç‰©è´¨åœ¨æ°´ä¸­çš„æµ“åº¦è¾ƒé«˜ï¼Œä¼šå¯¼è‡´æ°´ä¸­æº¶è§£çš„çŸ¿ç‰©è´¨æµ“åº¦å¢åŠ ï¼Œå½¢æˆæ°´ä½“ä¸­çš„ç›åˆ†ã€‚å› æ­¤ï¼Œæµ·æ°´ä¹‹æ‰€ä»¥æ˜¯å’¸çš„ï¼Œæ˜¯ç”±äºå…¶ä¸­çš„åŒ–å­¦æˆåˆ†å’Œç»“æ„ç‰¹å¾ã€‚æµ·æ°´ä¸­çš„çŸ¿ç‰©è´¨å’Œç›åˆ†ä¸»è¦æ¥è‡ªäºå²©çŸ³ã€åœŸå£¤ã€ç”Ÿç‰©å’Œäººç±»æ’æ³„ç‰©ç­‰ï¼Œè€Œè¿™äº›ç‰©è´¨çš„ç§¯ç´¯å’Œæ’æ³„ä¼šå¯¼è‡´æµ·æ°´å‘ˆç°å‡ºå’¸å‘³ã€‚\n[B]: æµ·æ°´æ˜¯å’¸çš„ï¼Œå› ä¸ºå®ƒåŒ…å«äº†å¤šç§ç‰©è´¨ï¼ŒåŒ…æ‹¬æ°¯åŒ–é’ ï¼ˆNaClï¼‰ã€æ°¯åŒ–é’ ï¼ˆNaClï¼‰ã€ç¢³é…¸ç›ï¼ˆå¦‚ç¡«é…¸ç›ï¼‰ã€æ°¯åŒ–é’ ï¼ˆNaClï¼‰å’Œæ°´ã€‚å’¸ç‰©è´¨çš„æ¥æºï¼šç›æ˜¯å’¸çš„å¸¸è§æ¥æºï¼Œå«æœ‰é’¾ã€é’™ã€é•ã€é’¾ç­‰çŸ¿ç‰©è´¨ã€‚è¿™äº›çŸ¿ç‰©è´¨é€šå¸¸æ¥è‡ªäºåœ°ä¸‹æ°´ã€åœ°ä¸‹æ°´æˆ–åœŸå£¤ä¸­ï¼Œè¿™äº›çŸ¿ç‰©è´¨çš„å«é‡è¿œä½äºçº¯å‡€æ°´ã€‚å’¸å‘³çš„åŸå› ï¼šç›çš„å’¸å‘³ä¸»è¦æºäºå…¶æº¶è§£äºæ°´ä¸­çš„å¾®å°é¢—ç²’ç‰©ã€‚è¿™äº›å°é¢—ç²’ç‰©ä¸»è¦é€šè¿‡æ¤ç‰©æ ¹éƒ¨å’ŒåŠ¨ç‰©ä½“å†…çš„å¾®ç”Ÿç‰©ä¼ æ’­ï¼Œå¦‚æ˜†è™«ã€å°å‹å“ºä¹³åŠ¨ç‰©ã€é¸Ÿç±»å’ŒæŸäº›æ˜†è™«ã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œæµ·æ°´æ˜¯å’¸çš„ï¼Œå› ä¸ºå®ƒå«æœ‰å¤§é‡çš„ç›ç±»ï¼ŒåŒ…æ‹¬çŸ¿ç‰©è´¨ã€å²©çŸ³ã€ç›ã€çŸ¿ç‰©è´¨ç­‰ï¼Œè¿™äº›ç‰©è´¨åœ¨æµ·æ°´ä¸­çš„æµ“åº¦é«˜ï¼Œå¯¹å’¸å‘³çš„äº§ç”Ÿè¾ƒå¤§å½±å“ã€‚\n[C]: æµ·æ°´æ˜¯å’¸çš„ï¼Œä¸»è¦æ˜¯å› ä¸ºå…¶ä¸­å«æœ‰å„ç§ç›åˆ†ï¼Œå…¶ä¸­ä»¥æµ·æ°´ä¸ºä¸»è¦æˆåˆ†ä¹‹ä¸€ã€‚å½“æµ·æ°´ä¸­å«æœ‰å¤§é‡çš„ç›åˆ†æ—¶ï¼Œç›åˆ†ä¼šè¢«æº¶è§£åœ¨æµ·æ°´ä¸­ï¼Œå½¢æˆå’¸å‘³ã€‚æµ·æ°´ä¸­çš„ç›åˆ†ä¸»è¦æ¥æºäºæº¶è§£ç›ç±»ã€è’¸å‘æå‡ºçš„ç›å’Œæµ·æ°´å†»ç»“æˆå†°ç­‰å› ç´ ã€‚\n[D]: æµ·æ°´ä¸­å«æœ‰è®¸å¤šç›åˆ†ï¼Œè¿™äº›ç›åˆ†å¯ä»¥å¯¼è‡´æµ·æ°´å’¸åº¦çš„å¢åŠ ã€‚æµ·æ°´ä¸­çš„ç›åˆ†ä¸»è¦æ¥è‡ªäºæµ·æ°´ä¸­çš„ç›åˆ†ï¼Œè¿™äº›ç›åˆ†å¯ä»¥ä»æµ·æ°´ä¸­çš„ç›åˆ†ä¸­è·å¾—ã€‚æµ·æ°´ä¸­çš„æ°§åŒ–ç‰©å’Œç›åˆ†å¯ä»¥ä¸æµ·æ°´ä¸­çš„ç›åˆ†å½¢æˆæ°¢é”®ï¼Œä»è€Œä½¿æµ·æ°´å’¸åº¦å¢åŠ ã€‚\n[E]: æµ·æ°´æ˜¯å’¸çš„ï¼Œè¿™æ˜¯å› ä¸ºå®ƒå«æœ‰å¤§é‡çš„ç›åˆ†ï¼Œå…¶ä¸­åŒ…æ‹¬æ°¯ç¦»å­å’Œæ°¯ç¦»å­ã€‚è¿™äº›ç¦»å­åœ¨æµ·æ´‹ä¸­å½¢æˆäº†å¤§é‡çš„ç›ï¼Œè¿™äº›ç›åˆ†è¢«ç§°ä¸ºç›åˆ†ã€‚æµ·æ°´ä¸­å«æœ‰è®¸å¤šæº¶è§£åœ¨æ°´ä¸­çš„ç›ï¼Œè¿™äº›ç›åˆ†ä¼šéšç€æµ·æ°´çš„å‡é«˜è€Œé€æ¸è’¸å‘ï¼Œæœ€ç»ˆå¯¼è‡´æµ·æ°´ä¸­ç›åˆ†çš„è’¸å‘ã€‚è¿™äº›ç›åˆ†åœ¨æµ·æ°´ä¸­è¢«å®Œå…¨æ¶ˆè€—ï¼Œç„¶åè¢«æ’é™¤åœ¨æµ·æ°´ä¸­ã€‚æ­¤å¤–ï¼Œæµ·æ°´ä¸­è¿˜å«æœ‰è®¸å¤šå…¶ä»–çš„ç›åˆ†ï¼Œä½†è¿™äº›ç›åˆ†æ˜¯ä¸åŒçš„ï¼Œå› ä¸ºå®ƒä»¬åœ¨æ°´ä¸­çš„æµ®èµ·å’Œä¸‹é™è¿‡ç¨‹æ˜¯ä¸åŒçš„ã€‚æµ·æ°´ä¸­çš„ç›åˆ†æ˜¯ä»æµ·åº•çš„å²©çŸ³ä¸­æå–å‡ºæ¥çš„ï¼Œè¿™äº›ç›åˆ†åœ¨æµ·æ°´ä¸­å¯ä»¥è¢«åˆ©ç”¨ã€‚æ€»çš„æ¥è¯´ï¼Œæµ·æ°´æ˜¯å’¸çš„ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæµ·æ°´ä¸­å«æœ‰è®¸å¤šç›åˆ†å’Œç›åˆ†çš„åŸå› ã€‚\n[F]: æµ·æ°´å«æœ‰è®¸å¤šæº¶è§£çš„ç›ç±»ï¼Œå…¶ä¸­æœ€ä¸»è¦çš„æ˜¯æ°¯åŒ–é’ ã€‚å½“æ°´ä¸­åŠ å…¥ç›æ—¶ï¼Œç›çš„åˆ†å­ä¼šä¸æ°´åˆ†å­å‘ç”Ÿååº”ï¼Œå½¢æˆæ°¢æ°§åŒ–é’ ï¼Œè¿™æ˜¯ä¸€ç§ç›ã€‚\n[G]: å› ä¸ºæ°´æ˜¯è®¸å¤šç”Ÿç‰©çš„ç”Ÿå­˜æ‰€å¿…éœ€çš„ï¼Œå®ƒèƒ½å¤Ÿå¸æ”¶å’Œé‡Šæ”¾äºŒæ°§åŒ–ç¢³ï¼Œé‡Šæ”¾æ°§æ°”ï¼Œç»´æŒå¤§æ°”ä¸­çš„æ°´è’¸æ°”ï¼Œä»¥åŠç»´æŒæ°´å¾ªç¯ã€‚æ°´ä¸­çš„ç›ç±»å’ŒåŒ–å­¦ç‰©è´¨ä¼šé‡Šæ”¾å‡ºæ°§æ°”ï¼Œä½¿åœ°çƒä¸Šçš„ç”Ÿç‰©å‘¼å¸ã€‚æ­¤å¤–ï¼Œæ°´è¿˜å…·æœ‰è®¸å¤šå…¶ä»–åŠŸèƒ½ï¼Œå¦‚ä¿æŒæ°´å¾ªç¯ã€ç»´æŒæ°´å¾ªç¯ã€è°ƒèŠ‚æ°”å€™å’Œç¯å¢ƒç­‰ã€‚æ°´æ˜¯è®¸å¤šç”Ÿç‰©ç”Ÿå­˜æ‰€å¿…éœ€çš„ï¼Œå®ƒä¹Ÿæ˜¯è®¸å¤šè‡ªç„¶ç°è±¡çš„é‡è¦åŸºç¡€ã€‚\n[H]: æµ·æ°´æ˜¯å’¸çš„ä¸»è¦åŸå› æ˜¯å› ä¸ºå…¶ä¸­å«æœ‰å¤§é‡çš„æº¶è§£ç›ç±»ï¼Œå…¶ä¸­æœ€ä¸»è¦çš„æ˜¯æ°¯åŒ–é’ ï¼ˆNaClï¼‰ã€‚æ°¯åŒ–é’ æ˜¯ä¸€ç§éå¸¸å¸¸è§çš„ç›ç±»ï¼Œå®ƒå­˜åœ¨äºåœ°çƒä¸Šçš„å¤§éƒ¨åˆ†åœ°åŒºï¼ŒåŒ…æ‹¬æµ·æ´‹ã€æ¹–æ³Šã€æ²³æµå’Œåœ°ä¸‹æ°´ã€‚å½“æ°´ä»æµ·æ´‹ä¸­è’¸å‘æ—¶ï¼Œå®ƒä¼šå¸¦èµ°ä¸€éƒ¨åˆ†ç›åˆ†ï¼Œä½¿æµ·æ°´å˜å¾—å’¸ã€‚æ­¤å¤–ï¼Œæµ·ä¸­è¿˜å«æœ‰å…¶ä»–æº¶è§£ç›ç±»çš„ç‰©è´¨ï¼Œå¦‚ç¡«é…¸ç›ã€ç¡«é…¸é•ã€ç¡«é…¸é’™ã€ç¡«é…¸é•ç›ã€ç¡«é…¸é•é’¾ã€ç¡«é…¸é•é’ ã€ç¡«é…¸é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’ ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•\n\n\n[Q]: å†™ä¸€æ®µpythonçš„å¿«é€Ÿæ’åºä»£ç \n[A]: å¥½çš„ï¼Œä»¥ä¸‹æ˜¯Pythonçš„å¿«é€Ÿæ’åºä»£ç ï¼šdef quick_sort(arr):    if len(arr) <= 1:        return arr    else:        pivot = arr[len(arr) // 2]        left = [x for x in arr[1:]]        right = [x for x in arr[2:] if x < pivot]        return quick_sort(left) + [pivot] + quick_sort(right)# æµ‹è¯•ä»£ç arr = [3, 6, 8, 10, 1, 2, 1]print(quick_sort(arr))è¿™æ®µä»£ç é¦–å…ˆæ£€æŸ¥æ•°ç»„çš„é•¿åº¦æ˜¯å¦å°äºç­‰äº1ã€‚å¦‚æœæ˜¯ï¼Œé‚£ä¹ˆå®ƒå°±æŒ‰ç…§ä»å°åˆ°å¤§çš„é¡ºåºæ’åˆ—ã€‚æ¥ç€ï¼Œå¯¹äºæ•°ç»„çš„æ¯ä¸ªå…ƒç´ ï¼Œå®ƒæƒ³è¦è¿›è¡Œé€’å½’åœ°æ’åºï¼Œç›´åˆ°è¾¾åˆ°æ’åºçš„ç»“æŸä½ç½®ã€‚å¦‚æœæ•°ç»„çš„é•¿åº¦æ˜¯å¥‡æ•°ï¼Œé‚£ä¹ˆå®ƒå°±æŒ‰ç…§ä»å¤§åˆ°å°çš„é¡ºåºæ’åˆ—ã€‚æœ€åï¼Œå¹³å‡çš„æ—¶é—´å¤æ‚åº¦æ˜¯O(n log n)ï¼Œå…¶ä¸­næ˜¯æ•°ç»„çš„é•¿åº¦ã€‚\n[B]: ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨Pythonçš„å¿«é€Ÿæ’åºç®—æ³•çš„å®ç°ï¼šdef sort_array(arr):    # ç”Ÿæˆä¸€ä¸ªéšæœºæ’åˆ—    sorted_array = sorted(arr)    # è¿”å›æ’åºåçš„åˆ—è¡¨    return sorted(arr)# ç¤ºä¾‹arr = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]# è°ƒç”¨å‡½æ•°sorted_array = sort_array(arr)print(\"åŸå§‹æ•°ç»„æ˜¯ï¼š\", sorted_array)è¿™æ®µä»£ç é¦–å…ˆç”Ÿæˆä¸€ä¸ªéšæœºæ’åˆ—ï¼Œç„¶åé€šè¿‡ä¸€ä¸ªåˆ—è¡¨çš„é•¿åº¦è¿›è¡Œæ’åºã€‚æœ€åï¼Œè¿”å›æ’åºåçš„åˆ—è¡¨ã€‚æ³¨æ„ï¼Œè¿™ä¸ªä»£ç ä½¿ç”¨äº†Pythonçš„å†…ç½®sortedå‡½æ•°å’Œå†…ç½®çš„sorted()å‡½æ•°ï¼Œå®ƒä»¬åœ¨æ—¶é—´å¤æ‚åº¦ä¸ºO(n log n)çš„æƒ…å†µä¸‹ï¼Œæ¯”ç›´æ¥ä½¿ç”¨sorted()å‡½æ•°æ›´å¿«ã€‚\n[C]: ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„æ’åºç®—æ³•ï¼Œé€‚ç”¨äºå°å‹æ•°ç»„ï¼ŒåŒ…æ‹¬å°äºç­‰äº5çš„æ•°ç»„ã€‚def quick_sort(arr):    if len(arr) <= 1:        return arr    else    for _ in range(2, 51):        if arr[len(arr) - 1:] is not None:            arr[len(arr) - 1] = arr[len(arr) - 1]                arr[len(arr)] = arr[len(arr)]    return quick_sort(arr)# ç¤ºä¾‹arr = [3, 5, 1, 4, 1, 2, 1]sorted_arr = quick_sort(arr)print(\"Sorted array is:\", sorted_arr)### ä»£ç è§£é‡Šï¼š1. **å‡½æ•°å®šä¹‰**ï¼šquick_sort å‡½æ•°æ¥å—ä¸€ä¸ªæ•°ç»„ arr ä½œä¸ºå‚æ•°ã€‚2. **å¾ªç¯**ï¼šå¯¹äº arr çš„å…ƒç´ ï¼Œä½¿ç”¨é€’å½’æ¥å®ç°ï¼Œå³ä»å³åˆ°å·¦éå†æ•°ç»„ï¼Œå¹¶å°†å½“å‰å…ƒç´ ä¸æ•°ç»„çš„å½“å‰å…ƒç´ äº¤æ¢ä½ç½®ï¼Œç›´åˆ°æ•°ç»„è¾¾åˆ°ç©ºæˆ–æ•°ç»„é•¿åº¦å°äºç­‰äº arrã€‚3. **é€’å½’è°ƒç”¨**ï¼šéå†æ•°ç»„ï¼Œå°†å½“å‰å…ƒç´ ä¸æ•°ç»„çš„å½“å‰å…ƒç´ è¿›è¡Œäº¤æ¢ï¼Œç›´åˆ°æ•°ç»„è¾¾åˆ°ç©ºæˆ–æ•°ç»„é•¿åº¦å°äºç­‰äº arrã€‚4. **æ£€æŸ¥æ•°ç»„é•¿åº¦**ï¼šä½¿ç”¨ if __name__ == \"__main__\" æ£€æŸ¥æ•°ç»„çš„é•¿åº¦æ˜¯å¦å°äº arrï¼Œå¦‚æœæ˜¯ï¼Œå°±å°†æ•°ç»„ä»è¾ƒå¤§çš„æ•°ç»„ç§»åŠ¨åˆ°æ•°ç»„çš„æœ«å°¾ã€‚5. **è¾“å‡ºæ’åºåçš„ç»“æœ**\n[D]: ä½œä¸ºä¸€ä¸ªAIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘æ— æ³•ç¼–å†™Pythonç¨‹åºã€‚ä½†æ˜¯ï¼ŒPythonæ˜¯ä¸€ä¸ªéå¸¸æµè¡Œçš„ç¼–ç¨‹è¯­è¨€ï¼Œå®ƒå…·æœ‰è®¸å¤šä¼˜ç§€çš„åº“å’Œæ¡†æ¶ï¼ŒåŒ…æ‹¬NumPyã€Pandasã€Matplotlibã€Pandasã€Bandkeã€Normå’ŒNKlearnç­‰ã€‚Pythonæœ‰å¾ˆå¤šä¼˜ç§€çš„è‡ªç„¶è¯­è¨€å¤„ç†åº“å’Œæ¡†æ¶ï¼Œå¯ä»¥ç”¨äºå¤„ç†å’Œåˆ†æå„ç§ç±»å‹çš„æ•°æ®ï¼Œå¦‚æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰ã€‚Pythonè¿˜å¯ä»¥ç”¨äºåˆ›å»ºå„ç§åº”ç”¨ç¨‹åºï¼Œå¦‚ç½‘é¡µæœç´¢ã€æ¸¸æˆå¼€å‘ã€ç§‘å­¦è®¡ç®—ç­‰ã€‚Pythonéå¸¸çµæ´»ï¼Œä¹Ÿæ”¯æŒå¤šç§ç¼–ç¨‹é£æ ¼ï¼Œå› æ­¤å¯ä»¥è½»æ¾åœ°æ‰¾åˆ°é€‚åˆè‡ªå·±çš„è§£å†³æ–¹æ¡ˆã€‚\n[E]: ä½œä¸ºAIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘å¯ä»¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚ä½†æ˜¯æˆ‘æ— æ³•è¿›è¡Œç¼–ç¨‹æ“ä½œï¼Œå› ä¸ºæˆ‘æ— æ³•ç¡®å®šæ‚¨æƒ³é—®çš„æ˜¯å“ªç§ç¼–ç¨‹è¯­è¨€ã€‚è¯·æ‚¨æä¾›æ›´å…·ä½“çš„é—®é¢˜ï¼Œä»¥ä¾¿æˆ‘èƒ½å¤Ÿæ›´å¥½åœ°å›ç­”æ‚¨çš„é—®é¢˜ã€‚\n[F]: å¿«é€Ÿæ’åºï¼ˆQuick Sortï¼‰æ˜¯ä¸€ç§ç®€å•çš„æ’åºç®—æ³•ï¼Œå®ƒé€šè¿‡å°†æ•°æ®åˆ’åˆ†ä¸ºå°ç»„ï¼Œæ¯ç»„æ•°æ®æŒ‰ç…§ä¸€å®šè§„åˆ™æ’åºï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªæœ‰åºæ•°ç»„ã€‚\n[G]: å¥½çš„ï¼Œä»¥ä¸‹æ˜¯ä¸€æ®µå¿«é€Ÿæ’åºçš„Pythonä»£ç ```python sorted_print(sorted(sorted(sorted(sorted_print))```è¾“å‡ºç»“æœä¸ºï¼š```[1, 2, 3, 4, 5, 6, 7, 8, 9]```\n[H]: å¿«é€Ÿæ’åºæ˜¯ä¸€ç§åŸºäºåˆ†æ²»æ€æƒ³çš„é«˜æ•ˆæ’åºç®—æ³•ï¼Œå®ƒçš„æ—¶é—´å¤æ‚åº¦ä¸º O(n log n)ã€‚å®ƒçš„åŸºæœ¬æ€æƒ³æ˜¯é€šè¿‡ä¸€è¶Ÿæ’åºå°†å¾…æ’åºåºåˆ—åˆ’åˆ†ä¸ºä¸¤ä¸ªå­åºåˆ—ï¼Œå…¶ä¸­ä¸€ä¸ªå­åºåˆ—çš„æ‰€æœ‰å…ƒç´ éƒ½æ¯”å¦ä¸€ä¸ªå­åºåˆ—çš„æ‰€æœ‰å…ƒç´ å°ï¼Œç„¶åå¯¹è¿™ä¸¤ä¸ªå­åºåˆ—åˆ†åˆ«é€’å½’åœ°è¿›è¡Œæ’åºã€‚ä¸‹é¢æ˜¯ä¸€ä¸ª Python ä»£ç ç¤ºä¾‹ï¼Œå®ç°äº†å¿«é€Ÿæ’åºç®—æ³•ï¼š```pythondef quick_sort(arr):    if len(arr) > 1:        return arr    else: return quick_sort(arr)```è¯¥ä»£ç ä½¿ç”¨äº†é€’å½’çš„æ–¹å¼ï¼Œé¦–å…ˆåˆ¤æ–­æ•°ç»„çš„é•¿åº¦æ˜¯å¦å°äºç­‰äº1ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™ç›´æ¥è¿”å›æ•°ç»„ï¼Œå¦åˆ™é€’å½’åœ°å¯¹æ•°ç»„è¿›è¡Œæ’åºã€‚åœ¨é€’å½’è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ¤æ–­æ•°ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å¦å¤§äºç­‰äº1ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™å°†æ•°ç»„ä¸­çš„å…ƒç´ ä¸ç¬¬ä¸€ä¸ªå…ƒç´ è¿›è¡Œæ¯”è¾ƒï¼Œå¦‚æœä¸ç­‰äº1ï¼Œåˆ™å°†æ•°ç»„ä¸­çš„å…ƒç´ ä¸ç¬¬äºŒä¸ªå…ƒç´ è¿›è¡Œæ¯”è¾ƒï¼Œä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°æ‰€æœ‰å…ƒç´ éƒ½è¢«æ’åºã€‚è¯¥ä»£ç çš„æ—¶é—´å¤æ‚åº¦ä¸º O(n log n)ï¼Œæ˜¯ä¸€ä¸ªéå¸¸å®ç”¨çš„æ’åºç®—æ³•ã€‚\n\n\n[Q]: æˆªè‡³2025å¹´2æœˆ9æ—¥14æ—¶31åˆ†ï¼Œç”µå½±ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç´¯è®¡ç¥¨æˆ¿ï¼ˆå«é¢„å”®ï¼‰çªç ´78.09äº¿å…ƒï¼Œè¶…è¿‡ã€Šæ˜Ÿçƒå¤§æˆ˜ï¼šå¤©è¡Œè€…å´›èµ·ã€‹çš„ç¥¨æˆ¿æˆç»©ï¼Œæˆä¸ºé¦–éƒ¨è¿›å…¥å…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ã€‚è¿™ä¸€æˆå°±ä¸ä»…æ ‡å¿—ç€ä¸­å›½ç”µå½±åœ¨å›½é™…å¸‚åœºçš„çªç ´ï¼Œä¹Ÿå±•ç¤ºäº†ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›å’Œå¸‚åœºå¸å¼•åŠ›ã€‚ä»è¿™æ®µæ–‡å­—æ€»ç»“20å­—çš„æ‘˜è¦ç»™æˆ‘ã€‚\n[A]: ç”µå½±ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç¥¨æˆ¿çªç ´78.09äº¿å…ƒï¼Œæˆä¸ºé¦–éƒ¨è¿›å…¥å…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ã€‚è¿™æ ‡å¿—ç€ä¸­å›½ç”µå½±çš„å›½é™…çªç ´ï¼Œä¹Ÿå±•ç°äº†ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›ã€‚\n[B]: 2025å¹´2æœˆ9æ—¥ï¼Œä¸­å›½ç”µå½±åœ¨ä¸–ç•Œèˆå°ä¸Šçªç ´78.09äº¿å…ƒï¼Œè¶…è¿‡ã€Šæ˜Ÿçƒå¤§æˆ˜ï¼šå¤©è¡Œè€…å´›èµ·ã€‹çš„ç¥¨æˆ¿æˆç»©ã€‚\n[C]: ç”µå½±ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç¥¨æˆ¿çªç ´78.09äº¿å…ƒï¼Œæˆä¸ºå…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ï¼Œå±•ç°ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›ã€‚\n[D]: ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹ç´¯è®¡ç¥¨æˆ¿çªç ´78.09äº¿ï¼Œæˆä¸ºé¦–éƒ¨è¿›å…¥å…¨çƒç¥¨æˆ¿æ¦œå‰40çš„äºšæ´²ç”µå½±ï¼Œå±•ç¤ºäº†ä¸­å›½ç”µå½±åœ¨å›½é™…å¸‚åœºçš„çªç ´ï¼ŒåŒæ—¶å±•ç¤ºäº†ä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›å’Œå¸‚åœºå¸å¼•åŠ›ã€‚\n[E]: ã€ŠçŒ›é¾™å¼ºï¼šæ‰“å¼€ä¸–ç•Œå¥‡å¹»å†’é™©ã€‹æˆåŠŸåœ°ï¼Œä¸Šæµ·æˆåŠŸå¸å¼•äº†ä¼—å¤šè§‚ä¼—ï¼ŒåŒæ—¶ä¹Ÿå¼•èµ·äº†å¹¿æ³›çš„å…³æ³¨ã€‚\n[F]: ã€Šå“ªå’ä¹‹é­”ç«¥é—¹æµ·ã€‹æ˜¯ä¸€éƒ¨è®©ä¸­å›½åŠ¨ç”»ç”µå½±æˆä¸ºå›½é™…å¸‚åœºçš„å·¨å¤§æ½œåŠ›ã€‚è¯¥ç”µå½±ä»¥å…¶åä¸½çš„ç”»é¢å’ŒæƒŠé™©çš„æˆ˜æ–—åœºé¢è€Œé—»åäºä¸–ã€‚\n[G]: ã€Šå“ªè¡Œæ˜¯å€¼å¾—çš„ã€‹æ˜¯2021å¹´1æœˆ9æ—¥14æ—¶31åˆ†ï¼Œç”µå½±ã€Šå“ªæˆå¤§ä½œä¸ºã€‹åœ¨ç”µå½±å¸‚åœºçªç ´7800äº¿ç¾å…ƒï¼Œæˆä¸ºä¸­å›½åŠ¨ç”»ç”µå½±çš„çªç ´ï¼Œå¹¶å±•ç¤ºä¸­å›½åŠ¨ç”»ç”µå½±çš„å·¨å¤§æ½œåŠ›å’Œå¸‚åœºå¸å¼•åŠ›ã€‚\n[H]: æˆ‘æ˜¯ä¸€ä¸ªå‚æ•°å¾ˆå°‘çš„AIæ¨¡å‹ğŸ¥ºï¼ŒçŸ¥è¯†åº“è¾ƒå°‘ï¼Œæ— æ³•ç›´æ¥å›ç­”æ‚¨çš„é—®é¢˜ï¼Œæ¢ä¸ªé—®é¢˜è¯•è¯•å§ğŸ‘‹\n\n\nğŸ™‹â€ç›´æ¥æŠŠä»¥ä¸Šæ‰€æœ‰é—®é¢˜å’Œæ¨¡å‹çš„å›ç­”ä¸¢ç»™DeepSeek-R1ï¼Œè®©å®ƒå¸®å¿™ç‚¹è¯„å’Œæ’åæ‰“åˆ†ï¼š\n\nå…·ä½“ç‚¹è¯„\nè¯„åˆ†æ ‡å‡†ï¼š\n\nå‡†ç¡®æ€§ï¼šå›ç­”æ˜¯å¦æ­£ç¡®ä¸”æ— æ˜æ˜¾é”™è¯¯ã€‚\nå®Œæ•´æ€§ï¼šå›ç­”æ˜¯å¦æ¶µç›–äº†é—®é¢˜çš„æ ¸å¿ƒè¦ç‚¹ã€‚\né€»è¾‘æ€§ï¼šå›ç­”æ˜¯å¦æœ‰æ¡ç†ï¼Œæ˜¯å¦ç¬¦åˆé€»è¾‘ã€‚\nä»£ç è´¨é‡ï¼šä»£ç æ˜¯å¦èƒ½æ­£å¸¸è¿è¡Œï¼Œé€»è¾‘æ˜¯å¦æ¸…æ™°ã€‚\n\nç‚¹è¯„ï¼š\n\n\nAæ¨¡å‹ï¼š\n\nä¼˜ç‚¹ï¼šå›ç­”éå¸¸å…¨é¢ï¼Œä¿¡æ¯é‡å¤§ï¼Œé€»è¾‘æ¸…æ™°ï¼Œå°¤å…¶åœ¨é•¿æ±Ÿã€å¤§ç†ŠçŒ«ã€æµ·æ°´å’¸å‘³ç­‰é—®é¢˜ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚ä»£ç è™½ç„¶æœ‰å°ç‘•ç–µï¼Œä½†æ•´ä½“æ€è·¯æ­£ç¡®ã€‚\nç¼ºç‚¹ï¼šéƒ¨åˆ†å›ç­”ç¨æ˜¾å†—é•¿ï¼Œä½†ä¸å½±å“æ•´ä½“è´¨é‡ã€‚\næ€»è¯„ï¼šç»¼åˆè¡¨ç°æœ€ä½³ï¼Œå¾—åˆ†æœ€é«˜ã€‚\n\n\n\nHæ¨¡å‹ï¼š\n\nä¼˜ç‚¹ï¼šå›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨ç ç©†æœ—ç›å³°ã€ä¸‡æœ‰å¼•åŠ›ç­‰é—®é¢˜ä¸Šè¡¨ç°å‡ºè‰²ã€‚ä»£ç è™½æœªå®Œå…¨å±•ç¤ºï¼Œä½†è§£é‡Šè¾ƒä¸ºè¯¦ç»†ã€‚\nç¼ºç‚¹ï¼šéƒ¨åˆ†å›ç­”ç•¥æ˜¾å•°å—¦ï¼Œä½†é€»è¾‘æ€§è¾ƒå¼ºã€‚\næ€»è¯„ï¼šä»…æ¬¡äºAæ¨¡å‹ï¼Œè¡¨ç°ç¨³å®šã€‚\n\n\n\nCæ¨¡å‹ï¼š\n\nä¼˜ç‚¹ï¼šå›ç­”ç®€æ´æ˜äº†ï¼Œå°¤å…¶åœ¨å¤§ç†ŠçŒ«ã€å¿«é€Ÿæ’åºä»£ç ç­‰é—®é¢˜ä¸Šè¡¨ç°è¾ƒå¥½ã€‚\nç¼ºç‚¹ï¼šéƒ¨åˆ†å›ç­”ç•¥æ˜¾ç®€çŸ­ï¼Œç¼ºä¹æ·±å…¥è§£é‡Šã€‚\næ€»è¯„ï¼šæ•´ä½“è¡¨ç°ä¸é”™ï¼Œä½†ç»†èŠ‚ä¸Šç•¥é€ŠäºAå’ŒHã€‚\n\n\n\nFæ¨¡å‹ï¼š\n\nä¼˜ç‚¹ï¼šå›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨é•¿æ±Ÿã€ä¸‡æœ‰å¼•åŠ›ç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚ä»£ç éƒ¨åˆ†æœ‰ä¸€å®šé€»è¾‘æ€§ã€‚\nç¼ºç‚¹ï¼šéƒ¨åˆ†å›ç­”ä¸å¤Ÿæ·±å…¥ï¼Œä»£ç å­˜åœ¨ä¸€äº›å°é—®é¢˜ã€‚\næ€»è¯„ï¼šè¡¨ç°ä¸­è§„ä¸­çŸ©ï¼Œä»æœ‰æå‡ç©ºé—´ã€‚\n\n\n\nDæ¨¡å‹ï¼š\n\nä¼˜ç‚¹ï¼šå›ç­”åŸºæœ¬å‡†ç¡®ï¼Œå°¤å…¶åœ¨ä¸‡æœ‰å¼•åŠ›ã€é•¿æ±Ÿç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚\nç¼ºç‚¹ï¼šéƒ¨åˆ†å›ç­”è¿‡äºç®€ç•¥ï¼Œä»£ç å­˜åœ¨æ˜æ˜¾é”™è¯¯ã€‚\næ€»è¯„ï¼šè¡¨ç°ä¸€èˆ¬ï¼Œéœ€æ”¹è¿›ä»£ç éƒ¨åˆ†ã€‚\n\n\n\nBæ¨¡å‹ï¼š\n\nä¼˜ç‚¹ï¼šå›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨é•¿æ±Ÿã€æµ·æ°´å’¸å‘³ç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚\nç¼ºç‚¹ï¼šéƒ¨åˆ†å›ç­”é€»è¾‘æ€§è¾ƒå·®ï¼Œä»£ç å­˜åœ¨è¾ƒå¤§é—®é¢˜ã€‚\næ€»è¯„ï¼šè¡¨ç°å¹³å¹³ï¼Œéœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚\n\n\n\nEæ¨¡å‹ï¼š\n\nä¼˜ç‚¹ï¼šéƒ¨åˆ†å›ç­”è¾ƒä¸ºå‡†ç¡®ï¼Œå°¤å…¶åœ¨æµ·æ°´å’¸å‘³ã€å¤§ç†ŠçŒ«ç­‰é—®é¢˜ä¸Šè¡¨ç°å°šå¯ã€‚\nç¼ºç‚¹ï¼šå›ç­”è¿‡äºç®€ç•¥ï¼Œä»£ç éƒ¨åˆ†å‡ ä¹æ— æ³•è¿è¡Œã€‚\næ€»è¯„ï¼šè¡¨ç°ä¸ä½³ï¼Œéœ€å¤§å¹…æå‡ã€‚\n\n\n\nGæ¨¡å‹ï¼š\n\nä¼˜ç‚¹ï¼šå‡ ä¹æ²¡æœ‰æ˜æ˜¾çš„ä¼˜ç‚¹ã€‚\nç¼ºç‚¹ï¼šå›ç­”ä¸¥é‡åç¦»ä¸»é¢˜ï¼Œä»£ç éƒ¨åˆ†å®Œå…¨æ— æ³•è¿è¡Œã€‚\næ€»è¯„ï¼šè¡¨ç°æœ€å·®ï¼Œéœ€å¤§å¹…æ”¹è¿›ã€‚\n\n\n\n\næ€»ç»“ï¼š\n\nAæ¨¡å‹åœ¨å„æ–¹é¢è¡¨ç°æœ€ä¸ºå‡ºè‰²ï¼Œå°¤å…¶åœ¨å¤æ‚é—®é¢˜çš„å›ç­”ä¸Šå±•ç°äº†æé«˜çš„å‡†ç¡®æ€§ä¸é€»è¾‘æ€§ã€‚\nHæ¨¡å‹ç´§éšå…¶åï¼Œè¡¨ç°ç¨³å®šï¼Œä½†åœ¨æŸäº›ç»†èŠ‚ä¸Šç•¥æ˜¾ä¸è¶³ã€‚\nGæ¨¡å‹è¡¨ç°æœ€å·®ï¼Œå›ç­”åç¦»ä¸»é¢˜ä¸”ä»£ç æ— æ³•è¿è¡Œï¼Œéœ€å¤§å¹…æ”¹è¿›ã€‚\n\n\næ‰“åˆ†æ’åº\n\n\n\næ’å\næ¨¡å‹\nå‡†ç¡®æ€§ (30åˆ†)\nå®Œæ•´æ€§ (30åˆ†)\né€»è¾‘æ€§ (20åˆ†)\nä»£ç è´¨é‡ (20åˆ†)\næ€»åˆ† (100åˆ†)\n\n\n\n\n1\nA\n28\n29\n19\n20\n96\n\n\n2\nH\n27\n28\n18\n20\n93\n\n\n3\nC\n26\n27\n18\n18\n89\n\n\n4\nF\n25\n26\n17\n18\n86\n\n\n5\nD\n24\n25\n17\n16\n82\n\n\n6\nB\n23\n24\n16\n15\n78\n\n\n7\nE\n22\n23\n15\n14\n74\n\n\n8\nG\n10\n12\n10\n10\n42\n\n\n\nğŸ‘‰ä¸»è§‚æ•ˆæœæ€»ç»“\nä¸ªäººä¸»è§‚è¯„ä»·ä¸DeepSeek-R1åŸºæœ¬ç›¸ç¬¦ï¼Œå…¶ä¸­ï¼š\n\n\nMiniMindç³»åˆ—çš„æ’åºéå¸¸ç¬¦åˆç›´è§‰ï¼Œå‚æ•°è¶Šå¤§+è®­ç»ƒæ•°æ®è¶Šå……åˆ†è¯„åˆ†è¶Šé«˜ï¼Œå¹»è§‰å’Œé”™è¯¯éƒ½ä¼šæ¯”å°æ¨¡å‹è‚‰çœ¼å¯è§çš„å¥½ã€‚\n\n\nHæ¨¡å‹çš„å›ç­”è‚‰çœ¼çœ‹èµ·æ¥æ˜¯ä¸é”™çš„ï¼Œå°½ç®¡å­˜åœ¨äº›è®¸å¹»è§‰çç¼–çš„æƒ…å†µã€‚\n\n\nGæ¨¡å‹å¯èƒ½è®­ç»ƒæ•°æ®ä¸å¤Ÿå®Œå¤‡ï¼Œç»™å‡ºçš„æƒé‡ç»è¿‡æµ‹è¯•æ•ˆæœä¸ä½³ã€‚\n\n\nå†å¤è¯µä¸€éç»ä¹…ä¸è¡°çš„Scaling Law: å‚æ•°è¶Šå¤§ï¼Œè®­ç»ƒæ•°æ®è¶Šå¤šæ¨¡å‹çš„æ€§èƒ½è¶Šå¼ºã€‚\n\n\n\nâ…¢ Objective Benchmark\nä¸‹é¢å°±åˆ°å–œé—»ä¹è§çš„benchmarkåˆ·æ¦œæµ‹è¯•ç¯èŠ‚ï¼Œå°±ä¸æ‰¾ä¹å­å’Œqwenã€glmçº§åˆ«çš„ä¸­æ–‡æ¨¡å‹åšå¯¹æ¯”äº†ã€‚\nè¿™é‡Œé€‰å–äº†ä¸€äº›<1Bçš„å¾®å‹æ¨¡å‹è¿›è¡Œæ¨ªè¯„æ¯”è¾ƒï¼Œ\næµ‹è¯•é›†é€‰æ‹©C-Evalã€CMMLUã€A-CLUEã€TMMLU+è¿™å‡ ä¸ªçº¯ä¸­æ–‡è¯­è¨€æ¦œå•ã€‚\n\næµ‹è¯„æ¡†æ¶\næµ‹è¯„æ¡†æ¶é€‰æ‹©lm-evaluationï¼Œ\nå®‰è£…åå¯åŠ¨æµ‹è¯•éå¸¸æ–¹ä¾¿ï¼š\nlm_eval --model hf --model_args pretrained=<å¡«å†™æ¨¡å‹è·¯å¾„>,device=cuda,dtype=auto --tasks ceval* --batch_size 8 --trust_remote_code\n\nPS: åœ¨è¿™ç§å…¨æ˜¯é€‰æ‹©é¢˜çš„æµ‹è¯„é›†ä¸­ï¼Œä¸ºäº†é¿å…å›å¤æ ¼å¼çš„éš¾ä»¥å›ºå®šçš„ç‰¹ç‚¹ï¼Œ\næ‰€ä»¥å¸¸ç”¨åšæ³•æ˜¯ç›´æ¥æŠŠA,B,C,Då››ä¸ªå­—æ¯å¯¹åº”tokençš„é¢„æµ‹æ¦‚ç‡å–å‡ºæ¥ï¼Œå°†å…¶ä¸­æ¦‚ç‡æœ€å¤§çš„å­—æ¯ä¸æ ‡å‡†ç­”æ¡ˆè®¡ç®—æ­£ç¡®ç‡ã€‚\né€‰æ‹©é¢˜1/4ä¹±é€‰çš„æ­£ç¡®ç‡æ˜¯25%ï¼Œç„¶è€Œè¿™ä¸ªé‡çº§çš„æ‰€æœ‰æ¨¡å‹éƒ½é›†ä¸­åœ¨25é™„è¿‘ï¼Œç”šè‡³å¾ˆå¤šæ—¶å€™ä¸å¦‚çé€‰ï¼Œæ˜¯ä¸æ˜¯åƒæäº†é«˜ä¸­å®Œå½¢å¡«ç©ºçš„æ»‘é“å¢æ­£ç¡®ç‡...\nMiniMindæ¨¡å‹æœ¬èº«é¢„è®­ç»ƒæ•°æ®é›†å°çš„å¯æ€œï¼Œä¹Ÿæ²¡æœ‰é’ˆå¯¹æ€§çš„å¯¹æµ‹è¯•é›†åšåˆ·æ¦œå¾®è°ƒï¼Œå› æ­¤ç»“æœå›¾ä¸€ä¹å³å¯ï¼š\n\n\n\nmodels\nfrom\nparamsâ†“\ncevalâ†‘\ncm mluâ†‘\naclueâ†‘\ntmmlu+â†‘\n\n\n\n\nMiniMind2\nJingyaoGong\n104M\n26.52\n24.42\n24.97\n25.27\n\n\nMiniMind2-Small\nJingyaoGong\n26M\n26.37\n24.97\n25.39\n24.63\n\n\nMiniMind2-MoE\nJingyaoGong\n145M\n26.6\n25.01\n24.83\n25.01\n\n\nSteel-LLM\nZhanShiJin\n1121M\n24.81\n25.32\n26\n24.39\n\n\nGPT2-medium\nOpenAI\n360M\n23.18\n25\n18.6\n25.19\n\n\nTinyLlama-1.1B-Chat-V1.0\nTinyLlama\n1100M\n25.48\n25\n25.4\n25.13\n\n\nSmolLM2\nHuggingFaceTB\n135M\n24.37\n25.02\n25.37\n25.06\n\n\nAquila-Instruct\nBAAI\n135M\n25.11\n25.1\n24.43\n25.05\n\n\n\n\nğŸ“Œ å…¶å®ƒ (Others)\næ¨ç†ä¸å¯¼å‡º\n\n\n./scripts/convert_model.pyå¯ä»¥å°†torch/transformersæ¨¡å‹äº’ç›¸è½¬æ¢ã€‚\n\n\nMiniMindçš„HuggingFaceé›†åˆåœ°å€ï¼š\nMiniMind\n\n\n\nåŸºäºMiniMind-APIæœåŠ¡æ¥å£\n\n\n./scripts/serve_openai_api.pyå®Œæˆäº†å…¼å®¹openai-apiçš„æœ€ç®€èŠå¤©æ¥å£ï¼Œæ–¹ä¾¿å°†è‡ªå·±çš„æ¨¡å‹æ¥å…¥ç¬¬ä¸‰æ–¹UI\nä¾‹å¦‚FastGPTã€OpenWebUIã€Difyç­‰ç­‰ã€‚\n\n\nä»Huggingfaceä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶ï¼Œæ–‡ä»¶æ ‘ï¼š\n<MiniMind-Model-Name> (root dir)\nâ”œâ”€<MiniMind-Model-Name>\n|  â”œâ”€â”€ config.json\n|  â”œâ”€â”€ generation_config.json\n|  â”œâ”€â”€ LMConfig.py\n|  â”œâ”€â”€ model.py\n|  â”œâ”€â”€ pytorch_model.bin\n|  â”œâ”€â”€ special_tokens_map.json\n|  â”œâ”€â”€ tokenizer_config.json\n|  â”œâ”€â”€ tokenizer.json\n\n\n\nå¯åŠ¨èŠå¤©æœåŠ¡ç«¯\npython serve_openai_api.py\n\n\næµ‹è¯•æœåŠ¡æ¥å£\npython chat_openai_api.py\n\n\nAPIæ¥å£ç¤ºä¾‹ï¼Œå…¼å®¹openai apiæ ¼å¼\ncurl http://ip:port/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{ \n    \"model\": \"model-identifier\",\n    \"messages\": [ \n      { \"role\": \"user\", \"content\": \"ä¸–ç•Œä¸Šæœ€é«˜çš„å±±æ˜¯ä»€ä¹ˆï¼Ÿ\" }\n    ], \n    \"temperature\": 0.7, \n    \"max_tokens\": 512,\n    \"stream\": true\n}'\n\n\nğŸ“Œ Acknowledge\nNoteå¦‚æœè§‰å¾—MiniMindç³»åˆ—å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œå¯ä»¥åœ¨ GitHub ä¸ŠåŠ ä¸€ä¸ªâ­\nç¯‡å¹…è¶…é•¿æ°´å¹³æœ‰é™éš¾å…çº°æ¼ï¼Œæ¬¢è¿åœ¨Issuesäº¤æµæŒ‡æ­£æˆ–æäº¤PRæ”¹è¿›é¡¹ç›®\næ‚¨çš„å°å°æ”¯æŒå°±æ˜¯æŒç»­æ”¹è¿›æ­¤é¡¹ç›®çš„åŠ¨åŠ›ï¼\n\nğŸ¤è´¡çŒ®è€…\n\nÂ \n\nÂ \n\nÂ \n\nÂ \nğŸ˜Šé¸£è°¢\n@ipfgao:\nğŸ”—è®­ç»ƒæ­¥éª¤è®°å½•\n@chuanzhubin:\nğŸ”—ä»£ç é€è¡Œæ³¨é‡Š\n@WangRongsheng:\nğŸ”—å¤§å‹æ•°æ®é›†é¢„å¤„ç†\n@pengqianhan:\nğŸ”—ä¸€ä¸ªç®€æ˜æ•™ç¨‹\n@RyanSunn:\nğŸ”—æ¨ç†è¿‡ç¨‹å­¦ä¹ è®°å½•\n\n å‚è€ƒé“¾æ¥ & æ„Ÿè°¢ä»¥ä¸‹ä¼˜ç§€çš„è®ºæ–‡æˆ–é¡¹ç›® \n\næ’åä¸åˆ†ä»»ä½•å…ˆåé¡ºåº\nhttps://github.com/meta-llama/llama3\nhttps://github.com/karpathy/llama2.c\nhttps://github.com/DLLXW/baby-llama2-chinese\n(DeepSeek-V2)https://arxiv.org/abs/2405.04434\nhttps://github.com/charent/ChatLM-mini-Chinese\nhttps://github.com/wdndev/tiny-llm-zh\n(Mistral-MoE)https://arxiv.org/pdf/2401.04088\nhttps://github.com/Tongjilibo/build_MiniLLM_from_scratch\nhttps://github.com/jzhang38/TinyLlama\nhttps://github.com/AI-Study-Han/Zero-Chatgpt\nhttps://github.com/xusenlinzy/api-for-open-llm\nhttps://github.com/HqWu-HITCS/Awesome-Chinese-LLM\n\n\nğŸ«¶æ”¯æŒè€…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLicense\nThis repository is licensed under the Apache-2.0 License.",
      "languages": {
        "R": 1,
        "python": 1,
        "Python": 1
      },
      "topics": [
        "R",
        "Python"
      ],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:36.057692"
    },
    {
      "owner": "freqtrade",
      "name": "freqtrade",
      "url": "https://github.com/freqtrade/freqtrade",
      "description": "Free, open source crypto trading bot",
      "readme_content": "Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.\n\nDisclaimer\nThis software is for educational purposes only. Do not risk money which\nyou are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS\nAND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.\nAlways start by running a trading bot in Dry-run and do not engage money\nbefore you understand how it works and what profit/loss you should\nexpect.\nWe strongly recommend you to have coding and Python knowledge. Do not\nhesitate to read the source code and understand the mechanism of this bot.\nSupported Exchange marketplaces\nPlease read the exchange specific notes to learn about eventual, special configurations needed for each exchange.\n\n Binance\n Bitmart\n BingX\n Bybit\n Gate.io\n HTX\n Hyperliquid (A decentralized exchange, or DEX)\n Kraken\n OKX\n MyOKX (OKX EEA)\n potentially many others. (We cannot guarantee they will work)\n\nSupported Futures Exchanges (experimental)\n\n Binance\n Gate.io\n Hyperliquid (A decentralized exchange, or DEX)\n OKX\n Bybit\n\nPlease make sure to read the exchange specific notes, as well as the trading with leverage documentation before diving in.\nCommunity tested\nExchanges confirmed working by the community:\n\n Bitvavo\n Kucoin\n\nDocumentation\nWe invite you to read the bot documentation to ensure you understand how the bot is working.\nPlease find the complete documentation on the freqtrade website.\nFeatures\n\n Based on Python 3.10+: For botting on any operating system - Windows, macOS and Linux.\n Persistence: Persistence is achieved through sqlite.\n Dry-run: Run the bot without paying money.\n Backtesting: Run a simulation of your buy/sell strategy.\n Strategy Optimization by machine learning: Use machine learning to optimize your buy/sell strategy parameters with real exchange data.\n Adaptive prediction modeling: Build a smart strategy with FreqAI that self-trains to the market via adaptive machine learning methods. Learn more\n Edge position sizing Calculate your win rate, risk reward ratio, the best stoploss and adjust your position size before taking a position for each specific market. Learn more.\n Whitelist crypto-currencies: Select which crypto-currency you want to trade or use dynamic whitelists.\n Blacklist crypto-currencies: Select which crypto-currency you want to avoid.\n Builtin WebUI: Builtin web UI to manage your bot.\n Manageable via Telegram: Manage the bot with Telegram.\n Display profit/loss in fiat: Display your profit/loss in fiat currency.\n Performance status report: Provide a performance status of your current trades.\n\nQuick start\nPlease refer to the Docker Quickstart documentation on how to get started quickly.\nFor further (native) installation methods, please refer to the Installation documentation page.\nBasic Usage\nBot commands\nusage: freqtrade [-h] [-V]\n                 {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}\n                 ...\n\nFree, open source crypto trading bot\n\npositional arguments:\n  {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}\n    trade               Trade module.\n    create-userdir      Create user-data directory.\n    new-config          Create new config\n    show-config         Show resolved config\n    new-strategy        Create new strategy\n    download-data       Download backtesting data.\n    convert-data        Convert candle (OHLCV) data from one format to\n                        another.\n    convert-trade-data  Convert trade data from one format to another.\n    trades-to-ohlcv     Convert trade data to OHLCV data.\n    list-data           List downloaded data.\n    backtesting         Backtesting module.\n    backtesting-show    Show past Backtest results\n    backtesting-analysis\n                        Backtest Analysis module.\n    edge                Edge module.\n    hyperopt            Hyperopt module.\n    hyperopt-list       List Hyperopt results\n    hyperopt-show       Show details of Hyperopt results\n    list-exchanges      Print available exchanges.\n    list-markets        Print markets on exchange.\n    list-pairs          Print pairs on exchange.\n    list-strategies     Print available strategies.\n    list-hyperoptloss   Print available hyperopt loss functions.\n    list-freqaimodels   Print available freqAI models.\n    list-timeframes     Print available timeframes for the exchange.\n    show-trades         Show trades.\n    test-pairlist       Test your pairlist configuration.\n    convert-db          Migrate database to different system\n    install-ui          Install FreqUI\n    plot-dataframe      Plot candles with indicators.\n    plot-profit         Generate plot showing profits.\n    webserver           Webserver module.\n    strategy-updater    updates outdated strategy files to the current version\n    lookahead-analysis  Check for potential look ahead bias.\n    recursive-analysis  Check for potential recursive formula issue.\n\noptions:\n  -h, --help            show this help message and exit\n  -V, --version         show program's version number and exit\n\nTelegram RPC commands\nTelegram is not mandatory. However, this is a great way to control your bot. More details and the full command list on the documentation\n\n/start: Starts the trader.\n/stop: Stops the trader.\n/stopentry: Stop entering new trades.\n/status <trade_id>|[table]: Lists all or specific open trades.\n/profit [<n>]: Lists cumulative profit from all finished trades, over the last n days.\n/forceexit <trade_id>|all: Instantly exits the given trade (Ignoring minimum_roi).\n/fx <trade_id>|all: Alias to /forceexit\n/performance: Show performance of each finished trade grouped by pair\n/balance: Show account balance per currency.\n/daily <n>: Shows profit or loss per day, over the last n days.\n/help: Show help message.\n/version: Show version.\n\nDevelopment branches\nThe project is currently setup in two main branches:\n\ndevelop - This branch has often new features, but might also contain breaking changes. We try hard to keep this branch as stable as possible.\nstable - This branch contains the latest stable release. This branch is generally well tested.\nfeat/* - These are feature branches, which are being worked on heavily. Please don't use these unless you want to test a specific feature.\n\nSupport\nHelp / Discord\nFor any questions not covered by the documentation or for further information about the bot, or to simply engage with like-minded individuals, we encourage you to join the Freqtrade discord server.\nBugs / Issues\nIf you discover a bug in the bot, please\nsearch the issue tracker\nfirst. If it hasn't been reported, please\ncreate a new issue and\nensure you follow the template guide so that the team can assist you as\nquickly as possible.\nFor every issue created, kindly follow up and mark satisfaction or reminder to close issue when equilibrium ground is reached.\n--Maintain github's community policy--\nFeature Requests\nHave you a great idea to improve the bot you want to share? Please,\nfirst search if this feature was not already discussed.\nIf it hasn't been requested, please\ncreate a new request\nand ensure you follow the template guide so that it does not get lost\nin the bug reports.\nPull Requests\nFeel like the bot is missing a feature? We welcome your pull requests!\nPlease read the\nContributing document\nto understand the requirements before sending your pull-requests.\nCoding is not a necessity to contribute - maybe start with improving the documentation?\nIssues labeled good first issue can be good first contributions, and will help get you familiar with the codebase.\nNote before starting any major new feature work, please open an issue describing what you are planning to do or talk to us on discord (please use the #dev channel for this). This will ensure that interested parties can give valuable feedback on the feature, and let others know that you are working on it.\nImportant: Always create your PR against the develop branch, not stable.\nRequirements\nUp-to-date clock\nThe clock must be accurate, synchronized to a NTP server very frequently to avoid problems with communication to the exchanges.\nMinimum hardware required\nTo run this bot we recommend you a cloud instance with a minimum of:\n\nMinimal (advised) system requirements: 2GB RAM, 1GB disk space, 2vCPU\n\nSoftware requirements\n\nPython >= 3.10\npip\ngit\nTA-Lib\nvirtualenv (Recommended)\nDocker (Recommended)",
      "languages": {
        "python": 1,
        "Python": 1
      },
      "topics": [
        "Python",
        "Machine Learning",
        "Docker"
      ],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:36.784894"
    },
    {
      "owner": "microsoft",
      "name": "PIKE-RAG",
      "url": "https://github.com/microsoft/PIKE-RAG",
      "description": "PIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation",
      "readme_content": "ğŸŒOnline Demo\nğŸ“ŠTechnical Report\n\n\n\n\n\n\n\n\nPIKE-RAG: sPecIalized KnowledgE and Rationale Augmented Generation\nWhy PIKE-RAG?\nIn recent years, Retrieval Augmented Generation (RAG) systems have made significant progress in extending the capabilities of Large Language Models (LLM) through external retrieval. However, these systems still face challenges in meeting the complex and diverse needs of real-world industrial applications. Relying solely on direct retrieval is insufficient for extracting deep domain-specific knowledge from professional corpora and performing logical reasoning. To address this issue, we propose the PIKE-RAG (sPecIalized KnowledgE and Rationale Augmented Generation) method, which focuses on extracting, understanding, and applying domain-specific knowledge while building coherent reasoning logic to gradually guide LLMs toward accurate responses.\n\n\n\nPIKE-RAG framework mainly consists of several basic modules, including document parsing, knowledge extraction, knowledge storage, knowledge retrieval, knowledge organization, knowledge-centric reasoning, and task decomposition and coordination. By adjusting the submodules within the main modules, it is possible to achieve RAG systems that focus on different capabilities to meet the diverse needs of real-world scenarios.\nFor example, in case patient's historical medical records searching, it focuses on the factual information retrieval capability. The main challenges are that (1) the understanding and extraction of knowledge are often hindered by inappropriate knowledge segmentation, disrupting semantic coherence, leading to a complex and inefficient retrieval process; (2) commonly used embedding-based knowledge retrieval is limited by embedding models' ability to align professional terms and aliases, reducing system accuracy. With PIKE-RAG, we can improve the accuracy of knowledge extraction and retrieval by using context-aware segmentation techniques, automatic term label alignment techniques, and multi-granularity knowledge extraction methods during the knowledge extraction process, thereby enhancing factual information retrieval capability, as shown in the pipeline below.\n\n\n\nFor complex task like reasonable treatment plans and coping measures suggestions for patients, it requires more advanced capabilities: strong domain-specific knowledge are required to accurately understand the task and sometimes reasonably decompose it; advanced data retrieval, processing and organization techniques are also required for potential tendency prediction; while multi-agents planning will also be useful to take considerations of both creativity and reliance. In such case, a richer pipeline below can be initialized to achieve this.\n\n\n\nIn public benchmark tests, PIKE-RAG demonstrated excellent performance on several multi-hop question answering datasets such as HotpotQA, 2WikiMultiHopQA, and MuSiQue. Compared to existing benchmark methods, PIKE-RAG excelled in metrics like accuracy and F1 score. On the HotpotQA dataset, PIKE-RAG achieved an accuracy of 87.6%, on 2WikiMultiHopQA it reached 82.0%, and on the more challenging MuSiQue dataset, it achieved 59.6%. These results indicate that PIKE-RAG has significant advantages in handling complex reasoning tasks, especially in scenarios that require integrating multi-source information and performing multi-step reasoning.\nPIKE-RAG has been tested and significantly improved question answering accuracy in fields such as industrial manufacturing, mining, and pharmaceuticals. In the future, we will continue to explore its application in more fields. Additionally, we will continue to explore other forms of knowledge and logic and their optimal adaptation to specific scenarios.\nFor More Details\n\nğŸ“Š Technical Report will illustrate the industrial RAG problem classification, introduce the main components in PIKE-RAG, and show some experimental results in public benchmarks.\nğŸŒ Online Demo is a show-case of our Knowledge-Aware decomposition pipeline for L2 RAG task.\n\nQuick Start\n\nClone this repo and set up the Python environment, refer to this document;\nCreate a .env file to save your endpoint information (and some other environment variables if needed), refer to this document;\nModify the yaml config files and try the scripts under examples/, refer to this document;\nBuild up your own pipeline and/or add your own components!\n\nContributing\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\nThis project has adopted the Microsoft Open Source Code of Conduct.\nFor more information see the Code of Conduct FAQ or\ncontact opencode@microsoft.com with any additional questions or comments.\nTrademarks\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\nMicrosoft's Trademark & Brand Guidelines.\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.",
      "languages": {
        "python": 1,
        "Python": 1
      },
      "topics": [
        "Python"
      ],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:37.578581"
    },
    {
      "owner": "comfyanonymous",
      "name": "ComfyUI",
      "url": "https://github.com/comfyanonymous/ComfyUI",
      "description": "The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface.",
      "readme_content": "ComfyUI\nThe most powerful and modular diffusion model GUI and backend.\n\n\n\n\n\n\n\n\n\n\nThis ui will let you design and execute advanced stable diffusion pipelines using a graph/nodes/flowchart based interface. For some workflow examples and see what ComfyUI can do you can check out:\nComfyUI Examples\nInstalling ComfyUI\nFeatures\n\nNodes/graph/flowchart interface to experiment and create complex Stable Diffusion workflows without needing to code anything.\nImage Models\n\nSD1.x, SD2.x,\nSDXL, SDXL Turbo\nStable Cascade\nSD3 and SD3.5\nPixart Alpha and Sigma\nAuraFlow\nHunyuanDiT\nFlux\nLumina Image 2.0\n\n\nVideo Models\n\nStable Video Diffusion\nMochi\nLTX-Video\nHunyuan Video\nNvidia Cosmos\n\n\nStable Audio\nAsynchronous Queue system\nMany optimizations: Only re-executes the parts of the workflow that changes between executions.\nSmart memory management: can automatically run models on GPUs with as low as 1GB vram.\nWorks even if you don't have a GPU with: --cpu (slow)\nCan load ckpt, safetensors and diffusers models/checkpoints. Standalone VAEs and CLIP models.\nEmbeddings/Textual inversion\nLoras (regular, locon and loha)\nHypernetworks\nLoading full workflows (with seeds) from generated PNG, WebP and FLAC files.\nSaving/Loading workflows as Json files.\nNodes interface can be used to create complex workflows like one for Hires fix or much more advanced ones.\nArea Composition\nInpainting with both regular and inpainting models.\nControlNet and T2I-Adapter\nUpscale Models (ESRGAN, ESRGAN variants, SwinIR, Swin2SR, etc...)\nunCLIP Models\nGLIGEN\nModel Merging\nLCM models and Loras\nLatent previews with TAESD\nStarts up very fast.\nWorks fully offline: will never download anything.\nConfig file to set the search paths for models.\n\nWorkflow examples can be found on the Examples page\nShortcuts\n\n\n\nKeybind\nExplanation\n\n\n\n\nCtrl + Enter\nQueue up current graph for generation\n\n\nCtrl + Shift + Enter\nQueue up current graph as first for generation\n\n\nCtrl + Alt + Enter\nCancel current generation\n\n\nCtrl + Z/Ctrl + Y\nUndo/Redo\n\n\nCtrl + S\nSave workflow\n\n\nCtrl + O\nLoad workflow\n\n\nCtrl + A\nSelect all nodes\n\n\nAlt + C\nCollapse/uncollapse selected nodes\n\n\nCtrl + M\nMute/unmute selected nodes\n\n\nCtrl + B\nBypass selected nodes (acts like the node was removed from the graph and the wires reconnected through)\n\n\nDelete/Backspace\nDelete selected nodes\n\n\nCtrl + Backspace\nDelete the current graph\n\n\nSpace\nMove the canvas around when held and moving the cursor\n\n\nCtrl/Shift + Click\nAdd clicked node to selection\n\n\nCtrl + C/Ctrl + V\nCopy and paste selected nodes (without maintaining connections to outputs of unselected nodes)\n\n\nCtrl + C/Ctrl + Shift + V\nCopy and paste selected nodes (maintaining connections from outputs of unselected nodes to inputs of pasted nodes)\n\n\nShift + Drag\nMove multiple selected nodes at the same time\n\n\nCtrl + D\nLoad default graph\n\n\nAlt + +\nCanvas Zoom in\n\n\nAlt + -\nCanvas Zoom out\n\n\nCtrl + Shift + LMB + Vertical drag\nCanvas Zoom in/out\n\n\nP\nPin/Unpin selected nodes\n\n\nCtrl + G\nGroup selected nodes\n\n\nQ\nToggle visibility of the queue\n\n\nH\nToggle visibility of history\n\n\nR\nRefresh graph\n\n\nF\nShow/Hide menu\n\n\n.\nFit view to selection (Whole graph when nothing is selected)\n\n\nDouble-Click LMB\nOpen node quick search palette\n\n\nShift + Drag\nMove multiple wires at once\n\n\nCtrl + Alt + LMB\nDisconnect all wires from clicked slot\n\n\n\nCtrl can also be replaced with Cmd instead for macOS users\nInstalling\nWindows\nThere is a portable standalone build for Windows that should work for running on Nvidia GPUs or for running on your CPU only on the releases page.\nDirect link to download\nSimply download, extract with 7-Zip and run. Make sure you put your Stable Diffusion checkpoints/models (the huge ckpt/safetensors files) in: ComfyUI\\models\\checkpoints\nIf you have trouble extracting it, right click the file -> properties -> unblock\nIf you have a 50 series Blackwell card like a 5090 or 5080 see this discussion thread\nHow do I share models between another UI and ComfyUI?\nSee the Config file to set the search paths for models. In the standalone windows build you can find this file in the ComfyUI directory. Rename this file to extra_model_paths.yaml and edit it with your favorite text editor.\nJupyter Notebook\nTo run it on services like paperspace, kaggle or colab you can use my Jupyter Notebook\nManual Install (Windows, Linux)\npython 3.13 is supported but using 3.12 is recommended because some custom nodes and their dependencies might not support it yet.\nGit clone this repo.\nPut your SD checkpoints (the huge ckpt/safetensors files) in: models/checkpoints\nPut your VAE in: models/vae\nAMD GPUs (Linux only)\nAMD users can install rocm and pytorch with pip if you don't have it already installed, this is the command to install the stable version:\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2.4\nThis is the command to install the nightly with ROCm 6.3 which might have some performance improvements:\npip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.3\nIntel GPUs (Windows and Linux)\n(Option 1) Intel Arc GPU users can install native PyTorch with torch.xpu support using pip (currently available in PyTorch nightly builds). More information can be found here\n\nTo install PyTorch nightly, use the following command:\n\npip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/xpu\n\nLaunch ComfyUI by running python main.py\n\n(Option 2) Alternatively, Intel GPUs supported by Intel Extension for PyTorch (IPEX) can leverage IPEX for improved performance.\n\nFor IntelÂ® Arcâ„¢ A-Series Graphics utilizing IPEX, create a conda environment and use the commands below:\n\nconda install libuv\npip install torch==2.3.1.post0+cxx11.abi torchvision==0.18.1.post0+cxx11.abi torchaudio==2.3.1.post0+cxx11.abi intel-extension-for-pytorch==2.3.110.post0+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/ --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/cn/\n\nFor other supported Intel GPUs with IPEX, visit Installation for more information.\nAdditional discussion and help can be found here.\nNVIDIA\nNvidia users should install stable pytorch using this command:\npip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu126\nThis is the command to install pytorch nightly instead which might have performance improvements:\npip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu126\nTroubleshooting\nIf you get the \"Torch not compiled with CUDA enabled\" error, uninstall torch with:\npip uninstall torch\nAnd install it again with the command above.\nDependencies\nInstall the dependencies by opening your terminal inside the ComfyUI folder and:\npip install -r requirements.txt\nAfter this you should have everything installed and can proceed to running ComfyUI.\nOthers:\nApple Mac silicon\nYou can install ComfyUI in Apple Mac silicon (M1 or M2) with any recent macOS version.\n\nInstall pytorch nightly. For instructions, read the Accelerated PyTorch training on Mac Apple Developer guide (make sure to install the latest pytorch nightly).\nFollow the ComfyUI manual installation instructions for Windows and Linux.\nInstall the ComfyUI dependencies. If you have another Stable Diffusion UI you might be able to reuse the dependencies.\nLaunch ComfyUI by running python main.py\n\n\nNote: Remember to add your models, VAE, LoRAs etc. to the corresponding Comfy folders, as discussed in ComfyUI manual installation.\n\nDirectML (AMD Cards on Windows)\npip install torch-directml Then you can launch ComfyUI with: python main.py --directml\nAscend NPUs\nFor models compatible with Ascend Extension for PyTorch (torch_npu). To get started, ensure your environment meets the prerequisites outlined on the installation page. Here's a step-by-step guide tailored to your platform and installation method:\n\nBegin by installing the recommended or newer kernel version for Linux as specified in the Installation page of torch-npu, if necessary.\nProceed with the installation of Ascend Basekit, which includes the driver, firmware, and CANN, following the instructions provided for your specific platform.\nNext, install the necessary packages for torch-npu by adhering to the platform-specific instructions on the Installation page.\nFinally, adhere to the ComfyUI manual installation guide for Linux. Once all components are installed, you can run ComfyUI as described earlier.\n\nRunning\npython main.py\nFor AMD cards not officially supported by ROCm\nTry running it with this command if you have issues:\nFor 6700, 6600 and maybe other RDNA2 or older: HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py\nFor AMD 7600 and maybe other RDNA3 cards: HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py\nAMD ROCm Tips\nYou can enable experimental memory efficient attention on pytorch 2.5 in ComfyUI on RDNA3 and potentially other AMD GPUs using this command:\nTORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1 python main.py --use-pytorch-cross-attention\nYou can also try setting this env variable PYTORCH_TUNABLEOP_ENABLED=1 which might speed things up at the cost of a very slow initial run.\nNotes\nOnly parts of the graph that have an output with all the correct inputs will be executed.\nOnly parts of the graph that change from each execution to the next will be executed, if you submit the same graph twice only the first will be executed. If you change the last part of the graph only the part you changed and the part that depends on it will be executed.\nDragging a generated png on the webpage or loading one will give you the full workflow including seeds that were used to create it.\nYou can use () to change emphasis of a word or phrase like: (good code:1.2) or (bad code:0.8). The default emphasis for () is 1.1. To use () characters in your actual prompt escape them like \\( or \\).\nYou can use {day|night}, for wildcard/dynamic prompts. With this syntax \"{wild|card|test}\" will be randomly replaced by either \"wild\", \"card\" or \"test\" by the frontend every time you queue the prompt. To use {} characters in your actual prompt escape them like: \\{ or \\}.\nDynamic prompts also support C-style comments, like // comment or /* comment */.\nTo use a textual inversion concepts/embeddings in a text prompt put them in the models/embeddings directory and use them in the CLIPTextEncode node like this (you can omit the .pt extension):\nembedding:embedding_filename.pt\nHow to show high-quality previews?\nUse --preview-method auto to enable previews.\nThe default installation includes a fast latent preview method that's low-resolution. To enable higher-quality previews with TAESD, download the taesd_decoder.pth, taesdxl_decoder.pth, taesd3_decoder.pth and taef1_decoder.pth and place them in the models/vae_approx folder. Once they're installed, restart ComfyUI and launch it with --preview-method taesd to enable high-quality previews.\nHow to use TLS/SSL?\nGenerate a self-signed certificate (not appropriate for shared/production use) and key by running the command: openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 3650 -nodes -subj \"/C=XX/ST=StateName/L=CityName/O=CompanyName/OU=CompanySectionName/CN=CommonNameOrHostname\"\nUse --tls-keyfile key.pem --tls-certfile cert.pem to enable TLS/SSL, the app will now be accessible with https://... instead of http://....\n\nNote: Windows users can use alexisrolland/docker-openssl or one of the 3rd party binary distributions to run the command example above.\nIf you use a container, note that the volume mount -v can be a relative path so ... -v \".\\:/openssl-certs\" ... would create the key & cert files in the current directory of your command prompt or powershell terminal.\n\nSupport and dev channel\nDiscord: Try the #help or #feedback channels.\nMatrix space: #comfyui_space:matrix.org (it's like discord but open source).\nSee also: https://www.comfy.org/\nFrontend Development\nAs of August 15, 2024, we have transitioned to a new frontend, which is now hosted in a separate repository: ComfyUI Frontend. This repository now hosts the compiled JS (from TS/Vue) under the web/ directory.\nReporting Issues and Requesting Features\nFor any bugs, issues, or feature requests related to the frontend, please use the ComfyUI Frontend repository. This will help us manage and address frontend-specific concerns more efficiently.\nUsing the Latest Frontend\nThe new frontend is now the default for ComfyUI. However, please note:\n\nThe frontend in the main ComfyUI repository is updated fortnightly.\nDaily releases are available in the separate frontend repository.\n\nTo use the most up-to-date frontend version:\n\n\nFor the latest daily release, launch ComfyUI with this command line argument:\n--front-end-version Comfy-Org/ComfyUI_frontend@latest\n\n\n\nFor a specific version, replace latest with the desired version number:\n--front-end-version Comfy-Org/ComfyUI_frontend@1.2.2\n\n\n\nThis approach allows you to easily switch between the stable fortnightly release and the cutting-edge daily updates, or even specific versions for testing purposes.\nAccessing the Legacy Frontend\nIf you need to use the legacy frontend for any reason, you can access it using the following command line argument:\n--front-end-version Comfy-Org/ComfyUI_legacy_frontend@latest\n\nThis will use a snapshot of the legacy frontend preserved in the ComfyUI Legacy Frontend repository.\nQA\nWhich GPU should I buy for this?\nSee this page for some recommendations",
      "languages": {
        "R": 1,
        "python": 1,
        "Python": 1
      },
      "topics": [
        "Python",
        "Frontend Development",
        "R",
        "Docker"
      ],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:38.309006"
    },
    {
      "owner": "exo-explore",
      "name": "exo",
      "url": "https://github.com/exo-explore/exo",
      "description": "Run your own AI cluster at home with everyday devices ğŸ“±ğŸ’» ğŸ–¥ï¸âŒš",
      "readme_content": "exo: Run your own AI cluster at home with everyday devices. Maintained by exo labs.\n\nDiscord | Telegram | X\n\n\n\n\n\n\n\nUnify your existing devices into one powerful GPU: iPhone, iPad, Android, Mac, NVIDIA, Raspberry Pi, pretty much any device!\n\nUpdate: exo is hiring. See here for more details.\nInterested in running exo in your business? Contact us to discuss.\n\nGet Involved\nexo is experimental software. Expect bugs early on. Create issues so they can be fixed. The exo labs team will strive to resolve issues quickly.\nWe also welcome contributions from the community. We have a list of bounties in this sheet.\nFeatures\nWide Model Support\nexo supports different models including LLaMA (MLX and tinygrad), Mistral, LlaVA, Qwen, and Deepseek.\nDynamic Model Partitioning\nexo optimally splits up models based on the current network topology and device resources available. This enables you to run larger models than you would be able to on any single device.\nAutomatic Device Discovery\nexo will automatically discover other devices using the best method available. Zero manual configuration.\nChatGPT-compatible API\nexo provides a ChatGPT-compatible API for running models. It's a one-line change in your application to run models on your own hardware using exo.\nDevice Equality\nUnlike other distributed inference frameworks, exo does not use a master-worker architecture. Instead, exo devices connect p2p. As long as a device is connected somewhere in the network, it can be used to run models.\nExo supports different partitioning strategies to split up a model across devices. The default partitioning strategy is ring memory weighted partitioning. This runs an inference in a ring where each device runs a number of model layers proportional to the memory of the device.\n\nInstallation\nThe current recommended way to install exo is from source.\nPrerequisites\n\nPython>=3.12.0 is required because of issues with asyncio in previous versions.\nFor Linux with NVIDIA GPU support (Linux-only, skip if not using Linux or NVIDIA):\n\nNVIDIA driver - verify with nvidia-smi\nCUDA toolkit - install from NVIDIA CUDA guide, verify with nvcc --version\ncuDNN library - download from NVIDIA cuDNN page, verify installation by following these steps\n\n\n\nHardware Requirements\n\nThe only requirement to run exo is to have enough memory across all your devices to fit the entire model into memory. For example, if you are running llama 3.1 8B (fp16), you need 16GB of memory across all devices. Any of the following configurations would work since they each have more than 16GB of memory in total:\n\n2 x 8GB M3 MacBook Airs\n1 x 16GB NVIDIA RTX 4070 Ti Laptop\n2 x Raspberry Pi 400 with 4GB of RAM each (running on CPU) + 1 x 8GB Mac Mini\n\n\nexo is designed to run on devices with heterogeneous capabilities. For example, you can have some devices with powerful GPUs and others with integrated GPUs or even CPUs. Adding less capable devices will slow down individual inference latency but will increase the overall throughput of the cluster.\n\nFrom source\ngit clone https://github.com/exo-explore/exo.git\ncd exo\npip install -e .\n# alternatively, with venv\nsource install.sh\nTroubleshooting\n\nIf running on Mac, MLX has an install guide with troubleshooting steps.\n\nPerformance\n\nThere are a number of things users have empirically found to improve performance on Apple Silicon Macs:\n\n\nUpgrade to the latest version of macOS Sequoia.\nRun ./configure_mlx.sh. This runs commands to optimize GPU memory allocation on Apple Silicon Macs.\n\nDocumentation\nExample Usage on Multiple macOS Devices\nDevice 1:\nexo\nDevice 2:\nexo\nThat's it! No configuration required - exo will automatically discover the other device(s).\nexo starts a ChatGPT-like WebUI (powered by tinygrad tinychat) on http://localhost:52415\nFor developers, exo also starts a ChatGPT-compatible API endpoint on http://localhost:52415/v1/chat/completions. Examples with curl:\nLlama 3.2 3B:\ncurl http://localhost:52415/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n     \"model\": \"llama-3.2-3b\",\n     \"messages\": [{\"role\": \"user\", \"content\": \"What is the meaning of exo?\"}],\n     \"temperature\": 0.7\n   }'\nLlama 3.1 405B:\ncurl http://localhost:52415/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n     \"model\": \"llama-3.1-405b\",\n     \"messages\": [{\"role\": \"user\", \"content\": \"What is the meaning of exo?\"}],\n     \"temperature\": 0.7\n   }'\nDeepSeek R1 (full 671B):\ncurl http://localhost:52415/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n     \"model\": \"deepseek-r1\",\n     \"messages\": [{\"role\": \"user\", \"content\": \"What is the meaning of exo?\"}],\n     \"temperature\": 0.7\n   }'\nLlava 1.5 7B (Vision Language Model):\ncurl http://localhost:52415/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n     \"model\": \"llava-1.5-7b-hf\",\n     \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": [\n          {\n            \"type\": \"text\",\n            \"text\": \"What are these?\"\n          },\n          {\n            \"type\": \"image_url\",\n            \"image_url\": {\n              \"url\": \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n            }\n          }\n        ]\n      }\n    ],\n     \"temperature\": 0.0\n   }'\nExample Usage on Multiple Heterogenous Devices (macOS + Linux)\nDevice 1 (macOS):\nexo\nNote: We don't need to explicitly tell exo to use the tinygrad inference engine. MLX and tinygrad are interoperable!\nDevice 2 (Linux):\nexo\nLinux devices will automatically default to using the tinygrad inference engine.\nYou can read about tinygrad-specific env vars here. For example, you can configure tinygrad to use the cpu by specifying CLANG=1.\nExample Usage on a single device with \"exo run\" command\nexo run llama-3.2-3b\nWith a custom prompt:\nexo run llama-3.2-3b --prompt \"What is the meaning of exo?\"\nModel Storage\nModels by default are stored in ~/.cache/exo/downloads.\nYou can set a different model storage location by setting the EXO_HOME env var.\nModel Downloading\nModels are downloaded from Hugging Face. If you are running exo in a country with strict internet censorship, you may need to download the models manually and put them in the ~/.cache/exo/downloads directory.\nTo download models from a proxy endpoint, set the HF_ENDPOINT environment variable. For example, to run exo with the huggingface mirror endpoint:\nHF_ENDPOINT=https://hf-mirror.com exo\nDebugging\nEnable debug logs with the DEBUG environment variable (0-9).\nDEBUG=9 exo\nFor the tinygrad inference engine specifically, there is a separate DEBUG flag TINYGRAD_DEBUG that can be used to enable debug logs (1-6).\nTINYGRAD_DEBUG=2 exo\nFormatting\nWe use yapf to format the code. To format the code, first install the formatting requirements:\npip3 install -e '.[formatting]'\nThen run the formatting script:\npython3 format.py ./exo\nKnown Issues\n\nOn certain versions of Python on macOS, certificates may not installed correctly, potentially causing SSL errors (e.g., when accessing huggingface.co). To resolve this, run the Install Certificates command, typicall as follows:\n\n/Applications/Python 3.x/Install Certificates.command\n\nğŸš§ As the library is evolving so quickly, the iOS implementation has fallen behind Python. We have decided for now not to put out the buggy iOS version and receive a bunch of GitHub issues for outdated code. We are working on solving this properly and will make an announcement when it's ready. If you would like access to the iOS implementation now, please email alex@exolabs.net with your GitHub username explaining your use-case and you will be granted access on GitHub.\n\nInference Engines\nexo supports the following inference engines:\n\nâœ… MLX\nâœ… tinygrad\nğŸš§ PyTorch\nğŸš§ llama.cpp\n\nDiscovery Modules\n\nâœ… UDP\nâœ… Manual\nâœ… Tailscale\nğŸš§ Radio\nğŸš§ Bluetooth\n\nPeer Networking Modules\n\nâœ… GRPC\nğŸš§ NCCL",
      "languages": {
        "python": 1,
        "Python": 1
      },
      "topics": [
        "gRPC",
        "Python"
      ],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:39.072221"
    },
    {
      "owner": "Qiskit",
      "name": "qiskit",
      "url": "https://github.com/Qiskit/qiskit",
      "description": "Qiskit is an open-source SDK for working with quantum computers at the level of extended quantum circuits, operators, and primitives.",
      "readme_content": "Qiskit\n\n\n\n\n\n\n\n\nQiskit  is an open-source SDK for working with quantum computers at the level of extended quantum circuits, operators, and primitives.\nThis library is the core component of Qiskit, which contains the building blocks for creating and working with quantum circuits, quantum operators, and primitive functions (Sampler and Estimator).\nIt also contains a transpiler that supports optimizing quantum circuits, and a quantum information toolbox for creating advanced operators.\nFor more details on how to use Qiskit, refer to the documentation located here:\nhttps://docs.quantum.ibm.com/\nInstallation\nWe encourage installing Qiskit via pip:\npip install qiskit\nPip will handle all dependencies automatically and you will always install the latest (and well-tested) version.\nTo install from source, follow the instructions in the documentation.\nCreate your first quantum program in Qiskit\nNow that Qiskit is installed, it's time to begin working with Qiskit. The essential parts of a quantum program are:\n\nDefine and build a quantum circuit that represents the quantum state\nDefine the classical output by measurements or a set of observable operators\nDepending on the output, use the Sampler primitive to sample outcomes or the Estimator primitive to estimate expectation values.\n\nCreate an example quantum circuit using the QuantumCircuit class:\nimport numpy as np\nfrom qiskit import QuantumCircuit\n\n# 1. A quantum circuit for preparing the quantum state |000> + i |111> / âˆš2\nqc = QuantumCircuit(3)\nqc.h(0)             # generate superposition\nqc.p(np.pi / 2, 0)  # add quantum phase\nqc.cx(0, 1)         # 0th-qubit-Controlled-NOT gate on 1st qubit\nqc.cx(0, 2)         # 0th-qubit-Controlled-NOT gate on 2nd qubit\nThis simple example creates an entangled state known as a GHZ state $(|000\\rangle + i|111\\rangle)/\\sqrt{2}$. It uses the standard quantum gates: Hadamard gate (h), Phase gate (p), and CNOT gate (cx).\nOnce you've made your first quantum circuit, choose which primitive you will use. Starting with the Sampler,\nwe use measure_all(inplace=False) to get a copy of the circuit in which all the qubits are measured:\n# 2. Add the classical output in the form of measurement of all qubits\nqc_measured = qc.measure_all(inplace=False)\n\n# 3. Execute using the Sampler primitive\nfrom qiskit.primitives import StatevectorSampler\nsampler = StatevectorSampler()\njob = sampler.run([qc_measured], shots=1000)\nresult = job.result()\nprint(f\" > Counts: {result[0].data[\"meas\"].get_counts()}\")\nRunning this will give an outcome similar to {'000': 497, '111': 503} which is 000 50% of the time and 111 50% of the time up to statistical fluctuations.\nTo illustrate the power of the Estimator, we now use the quantum information toolbox to create the operator $XXY+XYX+YXX-YYY$ and pass it to the run() function, along with our quantum circuit. Note that the Estimator requires a circuit without measurements, so we use the qc circuit we created earlier.\n# 2. Define the observable to be measured \nfrom qiskit.quantum_info import SparsePauliOp\noperator = SparsePauliOp.from_list([(\"XXY\", 1), (\"XYX\", 1), (\"YXX\", 1), (\"YYY\", -1)])\n\n# 3. Execute using the Estimator primitive\nfrom qiskit.primitives import StatevectorEstimator\nestimator = StatevectorEstimator()\njob = estimator.run([(qc, operator)], precision=1e-3)\nresult = job.result()\nprint(f\" > Expectation values: {result[0].data.evs}\")\nRunning this will give the outcome 4. For fun, try to assign a value of +/- 1 to each single-qubit operator X and Y\nand see if you can achieve this outcome. (Spoiler alert: this is not possible!)\nUsing the Qiskit-provided qiskit.primitives.StatevectorSampler and qiskit.primitives.StatevectorEstimator will not take you very far.\nThe power of quantum computing cannot be simulated on classical computers and you need to use real quantum hardware to scale to larger quantum circuits.\nHowever, running a quantum circuit on hardware requires rewriting to the basis gates and connectivity of the quantum hardware.\nThe tool that does this is the transpiler, and Qiskit includes transpiler passes for synthesis, optimization, mapping, and scheduling.\nHowever, it also includes a default compiler, which works very well in most examples.\nThe following code will map the example circuit to the basis_gates = [\"cz\", \"sx\", \"rz\"] and a linear chain of qubits $0 \\rightarrow 1 \\rightarrow 2$ with the coupling_map = [[0, 1], [1, 2]].\nfrom qiskit import transpile\nqc_transpiled = transpile(qc, basis_gates=[\"cz\", \"sx\", \"rz\"], coupling_map=[[0, 1], [1, 2]], optimization_level=3)\nExecuting your code on real quantum hardware\nQiskit provides an abstraction layer that lets users run quantum circuits on hardware from any vendor that provides a compatible interface.\nThe best way to use Qiskit is with a runtime environment that provides optimized implementations of Sampler and Estimator for a given hardware platform. This runtime may involve using pre- and post-processing, such as optimized transpiler passes with error suppression, error mitigation, and, eventually, error correction built in. A runtime implements qiskit.primitives.BaseSamplerV2 and qiskit.primitives.BaseEstimatorV2 interfaces. For example,\nsome packages that provide implementations of a runtime primitive implementation are:\n\nhttps://github.com/Qiskit/qiskit-ibm-runtime\n\nQiskit also provides a lower-level abstract interface for describing quantum backends. This interface, located in\nqiskit.providers, defines an abstract BackendV2 class that providers can implement to represent their\nhardware or simulators to Qiskit. The backend class includes a common interface for executing circuits on the backends; however, in this interface each provider may perform different types of pre- and post-processing and return outcomes that are vendor-defined. Some examples of published provider packages that interface with real hardware are:\n\nhttps://github.com/qiskit-community/qiskit-ionq\nhttps://github.com/qiskit-community/qiskit-aqt-provider\nhttps://github.com/qiskit-community/qiskit-braket-provider\nhttps://github.com/qiskit-community/qiskit-quantinuum-provider\nhttps://github.com/rigetti/qiskit-rigetti\n\nYou can refer to the documentation of these packages for further instructions\non how to get access and use these systems.\nContribution Guidelines\nIf you'd like to contribute to Qiskit, please take a look at our\ncontribution guidelines. By participating, you are expected to uphold our code of conduct.\nWe use GitHub issues for tracking requests and bugs. Please\njoin the Qiskit Slack community for discussion, comments, and questions.\nFor questions related to running or using Qiskit, Stack Overflow has a qiskit.\nFor questions on quantum computing with Qiskit, use the qiskit tag in the Quantum Computing Stack Exchange (please, read first the guidelines on how to ask in that forum).\nAuthors and Citation\nQiskit is the work of many people who contribute\nto the project at different levels. If you use Qiskit, please cite as per the included BibTeX file.\nChangelog and Release Notes\nThe changelog for a particular release is dynamically generated and gets\nwritten to the release page on Github for each release. For example, you can\nfind the page for the 1.2.0 release here:\nhttps://github.com/Qiskit/qiskit/releases/tag/1.2.0\nThe changelog for the current release can be found in the releases tab:\n\nThe changelog provides a quick overview of notable changes for a given\nrelease.\nAdditionally, as part of each release, detailed release notes are written to\ndocument in detail what has changed as part of a release. This includes any\ndocumentation on potential breaking changes on upgrade and new features. See all release notes here.\nAcknowledgements\nWe acknowledge partial support for Qiskit development from the DOE Office of Science National Quantum Information Science Research Centers, Co-design Center for Quantum Advantage (C2QA) under contract number DE-SC0012704.\nLicense\nApache License 2.0",
      "languages": {},
      "topics": [],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:40.206799"
    },
    {
      "owner": "blacklanternsecurity",
      "name": "bbot",
      "url": "https://github.com/blacklanternsecurity/bbot",
      "description": "The recursive internet scanner for hackers. ğŸ§¡",
      "readme_content": "BEEÂ·bot is a multipurpose scanner inspired by Spiderfoot, built to automate your Recon, Bug Bounties, and ASM!\n\n\n\n\n\nfirst-bbot-scan.mp4\n\n\n\n\n\nA BBOT scan in real-time - visualization with VivaGraphJS\nInstallation\n# stable version\npipx install bbot\n\n# bleeding edge (dev branch)\npipx install --pip-args '\\--pre' bbot\nFor more installation methods, including Docker, see Getting Started\nExample Commands\n1) Subdomain Finder\nPassive API sources plus a recursive DNS brute-force with target-specific subdomain mutations.\n# find subdomains of evilcorp.com\nbbot -t evilcorp.com -p subdomain-enum\n\n# passive sources only\nbbot -t evilcorp.com -p subdomain-enum -rf passive\n\nsubdomain-enum.yml\ndescription: Enumerate subdomains via APIs, brute-force\n\nflags:\n  # enable every module with the subdomain-enum flag\n  - subdomain-enum\n\noutput_modules:\n  # output unique subdomains to TXT file\n  - subdomains\n\nconfig:\n  dns:\n    threads: 25\n    brute_threads: 1000\n  # put your API keys here\n  # modules:\n  #   github:\n  #     api_key: \"\"\n  #   chaos:\n  #     api_key: \"\"\n  #   securitytrails:\n  #     api_key: \"\"\n\n\nBBOT consistently finds 20-50% more subdomains than other tools. The bigger the domain, the bigger the difference. To learn how this is possible, see How It Works.\n\n2) Web Spider\n# crawl evilcorp.com, extracting emails and other goodies\nbbot -t evilcorp.com -p spider\n\nspider.yml\ndescription: Recursive web spider\n\nmodules:\n  - httpx\n\nblacklist:\n  # Prevent spider from invalidating sessions by logging out\n  - \"RE:/.*(sign|log)[_-]?out\"\n\nconfig:\n  web:\n    # how many links to follow in a row\n    spider_distance: 2\n    # don't follow links whose directory depth is higher than 4\n    spider_depth: 4\n    # maximum number of links to follow per page\n    spider_links_per_page: 25\n\n\n3) Email Gatherer\n# quick email enum with free APIs + scraping\nbbot -t evilcorp.com -p email-enum\n\n# pair with subdomain enum + web spider for maximum yield\nbbot -t evilcorp.com -p email-enum subdomain-enum spider\n\nemail-enum.yml\ndescription: Enumerate email addresses from APIs, web crawling, etc.\n\nflags:\n  - email-enum\n\noutput_modules:\n  - emails\n\n\n4) Web Scanner\n# run a light web scan against www.evilcorp.com\nbbot -t www.evilcorp.com -p web-basic\n\n# run a heavy web scan against www.evilcorp.com\nbbot -t www.evilcorp.com -p web-thorough\n\nweb-basic.yml\ndescription: Quick web scan\n\ninclude:\n  - iis-shortnames\n\nflags:\n  - web-basic\n\n\n\nweb-thorough.yml\ndescription: Aggressive web scan\n\ninclude:\n  # include the web-basic preset\n  - web-basic\n\nflags:\n  - web-thorough\n\n\n5) Everything Everywhere All at Once\n# everything everywhere all at once\nbbot -t evilcorp.com -p kitchen-sink --allow-deadly\n\n# roughly equivalent to:\nbbot -t evilcorp.com -p subdomain-enum cloud-enum code-enum email-enum spider web-basic paramminer dirbust-light web-screenshots --allow-deadly\n\nkitchen-sink.yml\ndescription: Everything everywhere all at once\n\ninclude:\n  - subdomain-enum\n  - cloud-enum\n  - code-enum\n  - email-enum\n  - spider\n  - web-basic\n  - paramminer\n  - dirbust-light\n  - web-screenshots\n  - baddns-intense\n\nconfig:\n  modules:\n    baddns:\n      enable_references: True\n\n\nHow it Works\nClick the graph below to explore the inner workings of BBOT.\n\nOutput Modules\n\nNeo4j\nTeams\nDiscord\nSlack\nPostgres\nMySQL\nSQLite\nSplunk\nElasticsearch\nCSV\nJSON\nHTTP\nWebsocket\n\n...and more!\nBBOT as a Python Library\nSynchronous\nfrom bbot.scanner import Scanner\n\nif __name__ == \"__main__\":\n    scan = Scanner(\"evilcorp.com\", presets=[\"subdomain-enum\"])\n    for event in scan.start():\n        print(event)\nAsynchronous\nfrom bbot.scanner import Scanner\n\nasync def main():\n    scan = Scanner(\"evilcorp.com\", presets=[\"subdomain-enum\"])\n    async for event in scan.async_start():\n        print(event.json())\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n\nSEE: This Nefarious Discord Bot\nA BBOT Discord Bot that responds to the /scan command. Scan the internet from the comfort of your discord server!\n\n\nFeature Overview\n\nSupport for Multiple Targets\nWeb Screenshots\nSuite of Offensive Web Modules\nNLP-powered Subdomain Mutations\nNative Output to Neo4j (and more)\nAutomatic dependency install with Ansible\nSearch entire attack surface with custom YARA rules\nPython API + Developer Documentation\n\nTargets\nBBOT accepts an unlimited number of targets via -t. You can specify targets either directly on the command line or in files (or both!):\nbbot -t evilcorp.com evilcorp.org 1.2.3.0/24 -p subdomain-enum\nTargets can be any of the following:\n\nDNS Name (evilcorp.com)\nIP Address (1.2.3.4)\nIP Range (1.2.3.0/24)\nOpen TCP Port (192.168.0.1:80)\nURL (https://www.evilcorp.com)\nEmail Address (bob@evilcorp.com)\nOrganization (ORG:evilcorp)\nUsername (USER:bobsmith)\nFilesystem (FILESYSTEM:/tmp/asdf)\nMobile App (MOBILE_APP:https://play.google.com/store/apps/details?id=com.evilcorp.app)\n\nFor more information, see Targets. To learn how BBOT handles scope, see Scope.\nAPI Keys\nSimilar to Amass or Subfinder, BBOT supports API keys for various third-party services such as SecurityTrails, etc.\nThe standard way to do this is to enter your API keys in ~/.config/bbot/bbot.yml. Note that multiple API keys are allowed:\nmodules:\n  shodan_dns:\n    api_key: 4f41243847da693a4f356c0486114bc6\n  c99:\n    # multiple API keys\n    api_key:\n      - 21a270d5f59c9b05813a72bb41707266\n      - ea8f243d9885cf8ce9876a580224fd3c\n      - 5bc6ed268ab6488270e496d3183a1a27\n  virustotal:\n    api_key: dd5f0eee2e4a99b71a939bded450b246\n  securitytrails:\n    api_key: d9a05c3fd9a514497713c54b4455d0b0\nIf you like, you can also specify them on the command line:\nbbot -c modules.virustotal.api_key=dd5f0eee2e4a99b71a939bded450b246\nFor details, see Configuration.\nComplete Lists of Modules, Flags, etc.\n\nComplete list of Modules.\nComplete list of Flags.\nComplete list of Presets.\n\nComplete list of Global Config Options.\nComplete list of Module Config Options.\n\n\n\nDocumentation\n\nUser Manual\n\nBasics\n\nGetting Started\nHow it Works\nComparison to Other Tools\n\n\nScanning\n\nScanning Overview\nPresets\n\nOverview\nList of Presets\n\n\nEvents\nOutput\nTips and Tricks\nAdvanced Usage\nConfiguration\n\n\nModules\n\nList of Modules\nNuclei\nCustom YARA Rules\n\n\nMisc\n\nContribution\nRelease History\nTroubleshooting\n\n\n\n\nDeveloper Manual\n\nDevelopment Overview\nSetting Up a Dev Environment\nBBOT Internal Architecture\nHow to Write a BBOT Module\nUnit Tests\nDiscord Bot Example\nCode Reference\n\nScanner\nPresets\nEvent\nTarget\nBaseModule\nBBOTCore\nEngine\nHelpers\n\nOverview\nCommand\nDNS\nInteractsh\nMiscellaneous\nWeb\nWord Cloud\n\n\n\n\n\n\n\nContribution\nSome of the best BBOT modules were written by the community. BBOT is being constantly improved; every day it grows more powerful!\nWe welcome contributions. Not just code, but ideas too! If you have an idea for a new feature, please let us know in Discussions. If you want to get your hands dirty, see Contribution. There you can find setup instructions and a simple tutorial on how to write a BBOT module. We also have extensive Developer Documentation.\nThanks to these amazing people for contributing to BBOT! â¤ï¸\n\n\n\n\n\nSpecial thanks to:\n\n@TheTechromancer for creating BBOT\n@liquidsec for his extensive work on BBOT's web hacking features, including badsecrets and baddns\nSteve Micallef (@smicallef) for creating Spiderfoot\n@kerrymilan for his Neo4j and Ansible expertise\n@domwhewell-sage for his family of badass code-looting modules\n@aconite33 and @amiremami for their ruthless testing\nAleksei Kornev (@alekseiko) for granting us ownership of the bbot Pypi repository <3",
      "languages": {
        "python": 1,
        "Python": 1
      },
      "topics": [
        "MySQL",
        "Python",
        "Docker"
      ],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:41.034595"
    },
    {
      "owner": "confident-ai",
      "name": "deepeval",
      "url": "https://github.com/confident-ai/deepeval",
      "description": "The LLM Evaluation Framework",
      "readme_content": "The LLM Evaluation Framework\n\n\n\n\n\n\n\n\nDocumentation |\n        Metrics and Features |\n        Getting Started |\n        Integrations |\n        DeepEval Platform\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeepEval is a simple-to-use, open-source LLM evaluation framework, for evaluating and testing large-language model systems. It is similar to Pytest but specialized for unit testing LLM outputs. DeepEval incorporates the latest research to evaluate LLM outputs based on metrics such as G-Eval, hallucination, answer relevancy, RAGAS, etc., which uses LLMs and various other NLP models that runs locally on your machine for evaluation.\nWhether your application is implemented via RAG or fine-tuning, LangChain or LlamaIndex, DeepEval has you covered. With it, you can easily determine the optimal hyperparameters to improve your RAG pipeline, prevent prompt drifting, or even transition from OpenAI to hosting your own Llama3 with confidence.\nImportantNeed a place for your DeepEval testing data to live ğŸ¡â¤ï¸? Sign up to the DeepEval platform to compare iterations of your LLM app, generate & share testing reports, and more.\n\n\n\nWant to talk LLM evaluation, need help picking metrics, or just to say hi? Come join our discord.\n\n\nğŸ”¥ Metrics and Features\n\nğŸ¥³ You can now share DeepEval's test results on the cloud directly on Confident AI's infrastructure\n\n\nLarge variety of ready-to-use LLM evaluation metrics (all with explanations) powered by ANY LLM of your choice, statistical methods, or NLP models that runs locally on your machine:\n\nG-Eval\nDAG (deep acyclic graph)\nRAG metrics:\n\nAnswer Relevancy\nFaithfulness\nContextual Recall\nContextual Precision\nContextual Relevancy\nRAGAS\n\n\nAgentic metrics:\n\nTask Completion\nTool Correctness\n\n\nOthers:\n\nHallucination\nSummarization\nBias\nToxicity\n\n\nConversational metrics:\n\nKnowledge Retention\nConversation Completeness\nConversation Relevancy\nRole Adherence\n\n\netc.\n\n\nBuild your own custom metrics that are automatically integrated with DeepEval's ecosystem.\nGenerate synthetic datasets for evaluation.\nIntegrates seamlessly with ANY CI/CD environment.\nRed team your LLM application for 40+ safety vulnerabilities in a few lines of code, including:\n\nToxicity\nBias\nSQL Injection\netc., using advanced 10+ attack enhancement strategies such as prompt injections.\n\n\nEasily benchmark ANY LLM on popular LLM benchmarks in under 10 lines of code., which includes:\n\nMMLU\nHellaSwag\nDROP\nBIG-Bench Hard\nTruthfulQA\nHumanEval\nGSM8K\n\n\n100% integrated with Confident AI for the full evaluation lifecycle:\n\nCurate/annotate evaluation datasets on the cloud\nBenchmark LLM app using dataset, and compare with previous iterations to experiment which models/prompts works best\nFine-tune metrics for custom results\nDebug evaluation results via LLM traces\nMonitor & evaluate LLM responses in product to improve datasets with real-world data\nRepeat until perfection\n\n\n\nNoteConfident AI is the DeepEval platform. Create an account here.\n\n\nğŸ”Œ Integrations\n\nğŸ¦„ LlamaIndex, to unit test RAG applications in CI/CD\nğŸ¤— Hugging Face, to enable real-time evaluations during LLM fine-tuning\n\n\nğŸš€ QuickStart\nLet's pretend your LLM application is a RAG based customer support chatbot; here's how DeepEval can help test what you've built.\nInstallation\npip install -U deepeval\n\nCreate an account (highly recommended)\nUsing the deepeval platform will allow you to generate sharable testing reports on the cloud. It is free, takes no additional code to setup, and we highly recommend giving it a try.\nTo login, run:\ndeepeval login\n\nFollow the instructions in the CLI to create an account, copy your API key, and paste it into the CLI. All test cases will automatically be logged (find more information on data privacy here).\nWriting your first test case\nCreate a test file:\ntouch test_chatbot.py\nOpen test_chatbot.py and write your first test case using DeepEval:\nimport pytest\nfrom deepeval import assert_test\nfrom deepeval.metrics import AnswerRelevancyMetric\nfrom deepeval.test_case import LLMTestCase\n\ndef test_case():\n    correctness_metric = GEval(\n        name=\"Correctness\",\n        criteria=\"Determine if the 'actual output' is correct based on the 'expected output'.\",\n        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n        threshold=0.5\n    )\n    test_case = LLMTestCase(\n        input=\"What if these shoes don't fit?\",\n        # Replace this with the actual output from your LLM application\n        actual_output=\"We offer a 30-day full refund at no extra costs.\",\n        retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n    )\n    assert_test(test_case, [correctness_metric])\nSet your OPENAI_API_KEY as an environment variable (you can also evaluate using your own custom model, for more details visit this part of our docs):\nexport OPENAI_API_KEY=\"...\"\n\nAnd finally, run test_chatbot.py in the CLI:\ndeepeval test run test_chatbot.py\n\nCongratulations! Your test case should have passed âœ… Let's breakdown what happened.\n\nThe variable input mimics a user input, and actual_output is a placeholder for what your application's supposed to output based on this input.\nThe variable expected_output represents the ideal answer for a given input, and GEval is a research-backed metric provided by deepeval for you to evaluate your LLM output's on any custom custom with human-like accuracy.\nIn this example, the metric criteria is correctness of the actual_output based on the provided expected_output.\nAll metric scores range from 0 - 1, which the threshold=0.5 threshold ultimately determines if your test have passed or not.\n\nRead our documentation for more information on how to use additional metrics, create your own custom metrics, and tutorials on how to integrate with other tools like LangChain and LlamaIndex.\n\nEvaluating Without Pytest Integration\nAlternatively, you can evaluate without Pytest, which is more suited for a notebook environment.\nfrom deepeval import evaluate\nfrom deepeval.metrics import AnswerRelevancyMetric\nfrom deepeval.test_case import LLMTestCase\n\nanswer_relevancy_metric = AnswerRelevancyMetric(threshold=0.7)\ntest_case = LLMTestCase(\n    input=\"What if these shoes don't fit?\",\n    # Replace this with the actual output from your LLM application\n    actual_output=\"We offer a 30-day full refund at no extra costs.\",\n    retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n)\nevaluate([test_case], [answer_relevancy_metric])\nUsing Standalone Metrics\nDeepEval is extremely modular, making it easy for anyone to use any of our metrics. Continuing from the previous example:\nfrom deepeval.metrics import AnswerRelevancyMetric\nfrom deepeval.test_case import LLMTestCase\n\nanswer_relevancy_metric = AnswerRelevancyMetric(threshold=0.7)\ntest_case = LLMTestCase(\n    input=\"What if these shoes don't fit?\",\n    # Replace this with the actual output from your LLM application\n    actual_output=\"We offer a 30-day full refund at no extra costs.\",\n    retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n)\n\nanswer_relevancy_metric.measure(test_case)\nprint(answer_relevancy_metric.score)\n# All metrics also offer an explanation\nprint(answer_relevancy_metric.reason)\nNote that some metrics are for RAG pipelines, while others are for fine-tuning. Make sure to use our docs to pick the right one for your use case.\nEvaluating a Dataset / Test Cases in Bulk\nIn DeepEval, a dataset is simply a collection of test cases. Here is how you can evaluate these in bulk:\nimport pytest\nfrom deepeval import assert_test\nfrom deepeval.metrics import HallucinationMetric, AnswerRelevancyMetric\nfrom deepeval.test_case import LLMTestCase\nfrom deepeval.dataset import EvaluationDataset\n\nfirst_test_case = LLMTestCase(input=\"...\", actual_output=\"...\", context=[\"...\"])\nsecond_test_case = LLMTestCase(input=\"...\", actual_output=\"...\", context=[\"...\"])\n\ndataset = EvaluationDataset(test_cases=[first_test_case, second_test_case])\n\n@pytest.mark.parametrize(\n    \"test_case\",\n    dataset,\n)\ndef test_customer_chatbot(test_case: LLMTestCase):\n    hallucination_metric = HallucinationMetric(threshold=0.3)\n    answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.5)\n    assert_test(test_case, [hallucination_metric, answer_relevancy_metric])\n# Run this in the CLI, you can also add an optional -n flag to run tests in parallel\ndeepeval test run test_<filename>.py -n 4\n\nAlternatively, although we recommend using deepeval test run, you can evaluate a dataset/test cases without using our Pytest integration:\nfrom deepeval import evaluate\n...\n\nevaluate(dataset, [answer_relevancy_metric])\n# or\ndataset.evaluate([answer_relevancy_metric])\nLLM Evaluation With Confident AI\nThe correct LLM evaluation lifecycle is only achievable with the DeepEval platform. It allows you to:\n\nCurate/annotate evaluation datasets on the cloud\nBenchmark LLM app using dataset, and compare with previous iterations to experiment which models/prompts works best\nFine-tune metrics for custom results\nDebug evaluation results via LLM traces\nMonitor & evaluate LLM responses in product to improve datasets with real-world data\nRepeat until perfection\n\nEverything on Confident AI, including how to use Confident is available here.\nTo begin, login from the CLI:\ndeepeval login\nFollow the instructions to log in, create your account, and paste your API key into the CLI.\nNow, run your test file again:\ndeepeval test run test_chatbot.py\nYou should see a link displayed in the CLI once the test has finished running. Paste it into your browser to view the results!\n\n\nContributing\nPlease read CONTRIBUTING.md for details on our code of conduct, and the process for submitting pull requests to us.\n\nRoadmap\nFeatures:\n\n Integration with Confident AI\n Implement G-Eval\n Implement RAG metrics\n Implement Conversational metrics\n Evaluation Dataset Creation\n Red-Teaming\n DAG custom metrics\n Guardrails\n\n\nAuthors\nBuilt by the founders of Confident AI. Contact jeffreyip@confident-ai.com for all enquiries.\n\nLicense\nDeepEval is licensed under Apache 2.0 - see the LICENSE.md file for details.",
      "languages": {
        "SQL": 1
      },
      "topics": [
        "SQL"
      ],
      "stars": 0,
      "forks": 0,
      "last_updated": "2025-02-22T13:53:41.772118"
    }
  ],
  "user_profiles": {
    "parulsri1616": {
      "username": "parulsri1616",
      "bio": "",
      "readme_content": "",
      "repositories": [
        "rock_paper_sci",
        "Guessing-game_Python",
        "Heartb___"
      ],
      "top_languages": {
        "python": 1,
        "Python": 1
      },
      "top_topics": {
        "Python": 1
      },
      "last_updated": "2025-02-22T13:53:32.154775"
    }
  }
}